[{"title":"Basics of Everscale Blockchain","type":0,"sectionRef":"#","url":"/arch/basics","content":"","keywords":""},{"title":"Blockchain structure​","type":1,"pageTitle":"Basics of Everscale Blockchain","url":"/arch/basics#blockchain-structure","content":"At the moment, blockchain consists of 2 workchains. One of them (-1), a so-called masterchain, is needed for service contracts and validator contracts, another one (0) is for simple users. In the future, it is possible to add more simple workchains (1, 2, etc) to the blockchain. In turn, a workchain is split into shards (so-called shardchains). When the load is low, there are 16 shards. When it increases, shards split and when they decrease they merge. Blockchain is validated by validators. Part of them validate masterchain, others are split into groups and validate shardchains. Periodically, the global set of validators changes with elections. Within one election cycle, shardchain validators rotate as well. "},{"title":"Account (contract)​","type":1,"pageTitle":"Basics of Everscale Blockchain","url":"/arch/basics#account-contract","content":"An account (contract) is identified by its full address consisting of a workchain and ID. Full information about the Account is stored in its state. An account can have some balance, a place for its code, a place for its data and many other fields. It can have 1 owner, many owners and no owners at all. Account ID is calculated during deploy from its initial code and data. In order to learn what Accounts are in detail, please follow this page. "},{"title":"About deploy​","type":1,"pageTitle":"Basics of Everscale Blockchain","url":"/arch/basics#about-deploy","content":"Deploy — placing the code of the account onto the blockchain. You can not deploy an account's code if its balance is empty because deploy is paid out of that money. This is why any deploy operation must begin with sponsoring the account with some tokens. Because the account's ID is unequivocally calculated from code and data, this calculation can be done before the actual deploy. "},{"title":"Address​","type":1,"pageTitle":"Basics of Everscale Blockchain","url":"/arch/basics#address","content":"An Address is calculated from the initial contract's code and data that is attached to the deploy message. When a contract performs SETCODE operation, its address does not change. To calculate the contract address, you need to know its code and its initial data (public key of the owner is also stored in the data). "},{"title":"About digital assets transfers​","type":1,"pageTitle":"Basics of Everscale Blockchain","url":"/arch/basics#about-digital-assets-transfers","content":"Digital assets can be transferred from one account to another only by execution of the account's code. DO NOT transfer digital assets to the addresses where you can not deploy code because it will stay there forever. About fees There are several types of fees for operations with contracts. For example, commission for storage, execution, and message delivery. Please follow this page for Fee calculation details. "},{"title":"About get methods​","type":1,"pageTitle":"Basics of Everscale Blockchain","url":"/arch/basics#about-get-methods","content":"Get method is a method of the contract which doesn't change its state, so it can be executed locally on the client's machine for free. What shard my account is in right now? An account shard is defined by the first bits of its address and the current list of shards. Encode the hex shard prefix to binary format, discard the most right 1. You just got the shard mask. Put this mask on top of the account address, if the bits are equal — the account is in this shard. An account can change its shard depending on the load of the network. So, before calculating an account's shard, check the current list of shards. "},{"title":"Message​","type":1,"pageTitle":"Basics of Everscale Blockchain","url":"/arch/basics#message","content":"All interactions in Everscale are performed via messages. External inbound messages help deploy and call contracts from outside. Internal messages allow contracts to communicate with each other. External outbound messages are the events the contracts produce for the outside world. Use them to implement some off-chain logic — subscribe for these messages and perform some off-chain actions whenever you receive them. For example, a simple value transfer can be initiated with an external inbound message (by developers or a service) or with an internal message from another contract. This message will produce a transaction (read below) and an internal message with value transfer. In order to learn what Messages are in detail, please follow this page. "},{"title":"Transaction​","type":1,"pageTitle":"Basics of Everscale Blockchain","url":"/arch/basics#transaction","content":"A transaction is the result of a contract execution. In general, a transaction is generated with one incoming message (external or internal) and can generate several outcoming messages (external or internal) as a result. The transaction can be successful or aborted. For example, a simple value transfer consists of 2 transactions — Sender's transaction which generated an internal message with a value transfer, and Recipient's transaction where it received the message with value and updated its balance. "},{"title":"BOC (Bag of cells)​","type":1,"pageTitle":"Basics of Everscale Blockchain","url":"/arch/basics#boc-bag-of-cells","content":"It is a universal format for data packaging in Everscale. Every object — account, transaction, message, block is stored in the blockchain database as bocs. By the way, the boc of the block includes bocs of all messages and transactions that were executed in this block inside of it. "},{"title":"TVM​","type":1,"pageTitle":"Basics of Everscale Blockchain","url":"/arch/basics#tvm","content":"Turing-complete virtual machine for contract code execution. It works with data represented in boc format. TVM itself does not calculate any commissions and can be used on the client side for running the get methods of the contracts. TVM is used for debot engine execution on the client side as well. Also, TVM is used by validators together with higher level protocols, such as Transaction Executor, to additionally calculate commissions and perform other necessary checks. In order to learn what TVM is in detail, please follow this link. "},{"title":"Transaction Executor​","type":1,"pageTitle":"Basics of Everscale Blockchain","url":"/arch/basics#transaction-executor","content":"It takes the results of TVM, calculates fees, checks balances and other things. Used by validators to validate blocks. Can also be used on the client side to debug contract execution. In order to learn what Transaction Executor is in detail, please follow this link. In order to understand how Everscale blockchain works please follow this page. "},{"title":"Comparison with other solutions","type":0,"sectionRef":"#","url":"/arch/consensus/comparison","content":"","keywords":""},{"title":"PBFT​","type":1,"pageTitle":"Comparison with other solutions","url":"/arch/consensus/comparison#pbft","content":"Oldest of this family of protocols, first described in 1999 by Miguel Castro and Barbara Liskov [4]. Slot leader is re-elected only if it does not perform well. In comparison, Catchain changes leader each round in determenistic fashion.One round of block voting requires O(n²) messages (where n = number of nodes). Each node sends a message to all other. Catchain uses a special protocol which greatly reduces the number of messages: the outgoing messages are sent to a small number of neighbors (5 is a default number) and then those neighbors resend them further. "},{"title":"Tendermint​","type":1,"pageTitle":"Comparison with other solutions","url":"/arch/consensus/comparison#tendermint","content":"The closest algorithm to Catchain of all discussed in this chapter, described in [3]. As in Catchain, the proposer node is selected in a round-robin fashion each turn.Tendermint requires only local clocks to compute timeouts. This is different from Catchain, which require globally synchronous clocks. This scheme may make Catchain vulnerable to “eclipse” attack: by manipulating NTP messages one may make a node completely out of sync (blockchain will remain correct, but this particular node will not be able to vote and propose its blocks).A gossip message-propagation algorithm is implemented, which allows reducing the number of messages to O(n log n) for each voting. Catchain has Catchain overlay protocol for broadcasting messages, which does a similar thing. "},{"title":"Algorand​","type":1,"pageTitle":"Comparison with other solutions","url":"/arch/consensus/comparison#algorand","content":"A smaller subset of voters is elected at each step (a “committee”). These elections are held according to a determined, but secret procedure (only a user knows that she is selected to participate in the committee, but she may prove it to others). Only these committee members participate in voting; thanks to cryptographic measures in place, it does not compromise security.Requires no synchronous clocks, only the timeout delay should be equal among the nodes.Algorand also uses gossip message-propagation algorithm, like Catchain. The authors claim that each node, participating in voting process, sends exactly one message during each voting stage. "},{"title":"Ouroboros, CBC Casper​","type":1,"pageTitle":"Comparison with other solutions","url":"/arch/consensus/comparison#ouroboros-cbc-casper","content":"These consensus algorithms [5][6] are quite different: they prefer to build multiple block chains, and forks are made easily. At any given moment there is a set of valid chains, and the algorithms guarantee that any valid transaction is present in any of these chains after generation of R blocks (where R depends on configuration and may be rather big). This algorithm type requires a lot fewer synchronization messages, yet it takes more resources to handle multiple parallel chains; also new transactions becomes publicly available much later. "},{"title":"Components","type":0,"sectionRef":"#","url":"/arch/consensus/components","content":"","keywords":""},{"title":"Validator Session Component​","type":1,"pageTitle":"Components","url":"/arch/consensus/components#validator-session-component","content":""},{"title":"Consensus Algorithm Overview​","type":1,"pageTitle":"Components","url":"/arch/consensus/components#consensus-algorithm-overview","content":"To enable block validation, Everscale creates a list of validator nodes. This stage takes a fixed period of time configured in zerostate of blockchain. It is called validator session. This session is carried out in several rounds each aiming at generating a signed block. The list of validators for each validation session is regulated by a specific smart contract that implements the elections logic. Such validation session is established for a number of rounds each of which ends with block committing or round skip. As a result of elections the list of nodes with their respective voting weights is created. The voting weight is in direct proportion to a node stake value, so the larger the stake, the larger its weight. Then the weight is applied in decision making. Validator nodes vote by signing a block candidate with their own private keys. If a block gets at least 2/3 of all the weights (cutoff weight), it automatically wins the particular voting round. Every round has several stages: block candidate generationapprovalvotesigning A round ends once a new signed block appears. To prevent validator conflicts over a new block, each round includes a specific number of fixed-time attempts pre-configured in blockchain zerostate. If no consensus is achieved within the maximum number of attempts, the round is considered failed, the committed block is skipped and will not be written to a blockchain. In general case when validators fail to reach consensus for a few rounds, new validator election can resolve the deadlock. Each validator node stores the validation session state and synchronizes it with other nodes after each modification (i.e. creates a snapshot). Synchronization is implemented through the Catchain protocol by message broadcasting (i.e. increments to the snapshot are made). The details of synchronization are described below in the Сatchain protocol overview. Note that post-modification synchronization is not applied to all nodes, but to neighbor nodes. This subset is non constant and periodically updated, so this allows to minimize traffic between Catchain nodes and to deliver the node state transitively to all of them. The state validity is controlled through signature verification. The state consists of the current round state and of a list of previous round states (history of previous rounds). The round state, in turn, consists of the list of attempts and of signatures of the elected commit candidate block (pre-committed block). Finally, each round attempt includes the following steps: validator nodes exchange block candidates for approval;primary node for the current attempt sends the candidate block for voting to the rest of nodes (based on node priority computed for this attempt);validator nodes exchange votes.  It is noteworthy that to avoid deadlocks during voting and candidate generation, node priority is set depending on the number of nodes, round number, attempt number. So for each attempt priority changes and some validators gain privileges for the attempt. For example: priority to provide candidate blocks from a linked collator (only first validatorSessionOptions::round_candidate can propose a new candidate for approval);priority as ranging criteria for selecting candidates for approval process;priority to choose an approved block for voting (only one node can do it). Also, priority is used to calculate delay in the course of approval process during the round attempt (minimum priority corresponds to smaller delays for approval). Another evident and important point is that decision of each validator is checked by the rest of validators. Validator node public key is used for signature verification. At the start of each validator session each validator receives information about all other validators including: the list of validators pre-created by the smart contract so that nodes could be addressed by indexes during the session;public keys of each validator;validator weights according to their stakes. Each time a validator receives block candidates, approvals or votes from other validator nodes, it checks the signature (and in some cases priority as specified above) to make sure that:the sender is authorized to make the decision;the decision was actually made by the sender. "},{"title":"Consensus Stages​","type":1,"pageTitle":"Components","url":"/arch/consensus/components#consensus-stages","content":"The stages (slots) of a round are following: The stages (slots) of a round are following: Block candidate generation. Each node having block generation priority for the round generates a new block candidate which is requested from collator (see validatorsession::ValidatorSession::Callback::on_generate_slot for details). As soon as the candidate appears, it is sent to other validator nodes (validatorSession.candidate &gt; validatorSession.message.submittedBlock).Block candidates approval. Blocks from the previous stage are collected at each validator node and processed for approval. The approval process is not related to the consensus itself and is aimed at checking that blocks are not corrupted in terms of the bound data (see validatorsession::ValidatorSession::Callback::on_candidate of callback for details). As soon a block is approved, it is signed for approval by each validator. Then the validatorSession.message.approvedBlock message is broadcast with the round number and the ID of the approving node. So, each validator is aware which node has approved the sent block. The block is considered approved by a node when it receives 2/3 of approval messages.Voting attempts. Several block voting attempts are carried out. Each attempt is time limited and validators are supposed to fit into the slot. While votes for the current candidate are still accepted past the attempt deadline, it can cause a situation when two attempts result in different votes for multiple candidates, the case is considered further. The block candidate for voting is selected by the attempt’s main validator node and other nodes are notified by validatorSession.message.voteFor message (see ValidatorSessionRoundState::generate_vote_for for details; the main validator node which proposes the block for the attempt is provided by ValidatorSessionDescriptionImpl::get_vote_for_author method). The block selection involves two aspects: a) the node ranges approved blocks by nodes priority for the current attempt, so in each attempt the list is reordered, and b) the main validator node randomly selects a block for voting from this list. Each validator node processes the above-mentioned message and selects a block to vote for. A validator does not have to vote for the proposed block and is free to select another one. So the proposed block is more of a tip to provide an aim and to accelerate voting. Voting implies two things: a) signing block to mark it is voted by a particular validator node, and b) broadcasting this information in a validatorSession.message.vote message to the rest of validators. As soon as any approved block gets at least 2/3 of total validator weights in the course of voting, it becomes the candidate for signing (pre-commit block). Chances are that votes are received after the attempt end. In this case the late votes are processed simultaneously with the new attempt. Generally, votes for each finished attempt may be accepted past deadline; constituting no logical error, it allows finishing the round faster. And, if any of previous attempts ends up getting 2/3 of total weights or more even past its deadline, it still yields a new pre-commit candidate. In case of a conflict where two attempts propose different pre-commit blocks, the latest prevails. It is noteworthy that for performance reasons, a block vote obtained in one attempt is reused on the rest of attempts automatically.Block committing. As soon as a round attempt yields a pre-committed block, the signing process starts. The validator that gets a pre-committed block in the current round signs it and broadcasts to other validators using a validatorSession_message_commitmessage (see ValidatorSessionImpl::check_sign_slot and related logic in ValidatorSessionImpl::process_blocks for details). All other validators receive the broadcast, check the sender signature and update their state (see ValidatorSessionRoundState::action(…, validatorSession_message_commit for details). At some moment, a particular validator gets not less than 2/3 signatures from other validators (in terms of validator weights). This leads to a) switching to a new round (increasing the round sequence number by 1), and b) committing the signed block to the blockchain (see validatorsession::ValidatorSession::Callback::on_block_committed for details). In case of failure to get a signed block during the configured number of attempts (ValidatorSessionOptions::max_round_attempts), a new round starts and the failed one is marked as skipped (see validatorsession::ValidatorSession::Callback::on_block_skipped). "},{"title":"Validator Session Protocol Messages & Structures​","type":1,"pageTitle":"Components","url":"/arch/consensus/components#validator-session-protocol-messages--structures","content":"Validator session protocol consists of: incoming events: validatorSession.round.Message (which may be one of following sub-types: validatorSession.message.submittedBlock, validatorSession.message.approvedBlock, validatorSession.message.rejectedBlock, validatorSession.message.voteFor, validatorSession.message.vote, validatorSession.message.precommit, validatorSession.message.commit, validatorSession.message.empty), validatorSession.blockUpdate, validatorSession.candidate;required outgoing query validatorSession.downloadCandidate (with validatorSession.candidate as an event in subsequent event);internal structures which may be used in events and queries above. Main flows: Consensus stagesBlock candidate generationRound priority validator proposes block candidates using validatorSession.message.submittedBlock message.Each validator with block-candidate proposal priority can propose block within a limited time slot after the round starts. Blocks proposed outside of the time slot are ignored.Block candidates approvalAfter receiving validatorSession.message.submittedBlock each validator starts checking the block for approval. In case of approval validator generates validatorSession.message.approvedBlock, in case of rejection — validatorSession.message.rejectedBlock.Voting attemptsValidator with a priority to propose block for voting (“vote-for” block) chooses a random block for voting from the list of approved blocks and generates the validatorSession.message.voteFor message.Validator which receives validatorSession.message.voteFor checks if this message is generated by a validator with &quot;vote-for&quot; block proposing priority. If so, uses the proposed &quot;vote-for&quot; block as a priority block for voting.In the first voting attempt validator votes on a block which has been received in a validatorSession.message.voteFor message. This is the fastest way of consensus decision-making. Same voting on a block received in the validatorSession.message.voteFor message is carried out after the max number voting attempts. As a result validatorSession.message.vote is generated with a vote on a specific block.If the attempt is not first and is less than maximum number of voting attempts, a validator chooses a block to vote proposed by another validator with min priority for the round. As a result validatorSession.message.vote is generated with a vote on specific block.If a validator voted on a block in one of previous round attempts, the validator generates validatorSession.message.vote with the same vote.When a validator receives the validatorSession.message.votemessage, it checks whether at least 2/3 of voting weights are received for the block in question. If so, the validator generates validatorSession.message.precommit with a block selected as a candidate for committing.Block committingWhen a validator receives the validatorSession.message.precommit message, it checks whether at least 2/3 of voting weights are received for the precommit block proposed in the validatorSession.message.precommit message. If so, the validatorSession.message.commit message is generated with a block for commit and the relevant validator signature.When a validator receives the validatorSession.message.commit message, it checks whether least 2/3 of voting weights are received to commit the proposed block. If so, block is committed and a new round is started.If during the maximum number of attempts no block is committed, the round marked as skipped and a new round is started.Block candidate downloading To speed up consensus processing there is the validatorSession.downloadCandidate query that can be sent by a validator via broadcast to request a round block-candidate with a specific identifier. A validator makes this query when it has no block candidate for further consensus processing. II. Internal structures: validatorSession.config. This structure is configured in the zerostate and contains consensus configuration parameters shared by all validators. catchain_idle_timeout : double - timeout between consensus iterations calls; each consensus iteration may result with new catchain block generation;catchain_max_deps : int - maximum number of catchain blocks for merging during consensus iteration;round_candidates : int - number of block candidates per round of the Block candidate generation stage;next_candidate_delay : double - delay between block candidate proposing;round_attempt_duration : int - round attempt duration in milliseconds;max_round_attempts : int - maximum number of attempts per round;max_block_size : int - max block size;max_collated_data_size : int - max size of collated data of the block. validatorSession.candidateId : ****is a part of the validatorSession.downloadCandidate query and contains block-candidate hashes. src : int256 - hash of a public key of the validator that generated the block-candidate;root_hash : int256 - block root hash;file_hash : int256 - block file hash;collated_data_file_hash : int256 - block's collated data hash. III. Events: validatorSession.round.Message validatorSession.message.submittedBlock message is related to the Block candidate generation stage. It informs that a validator generated a new block-candidate and submitted it to Catchain. Each validator has a limited time slot for block-candidate generation (and proposing). This slot is computed according to the node priority which depends on round and current time. During the block generation stage there may be up to round_candidatesblock-candidates. A new candidate may be generated if the current consensus round is not finished (new block is not committed) during round_attempt_duration. The message has the following structure:round : int - number of the round when new block-candidate appears;root_hash : int256 - block-candidate root hash;file_hash : int256 - block-candidate file hash;collated_data_file_hash : int256 - block-candidate data hash.Actions: this message has to be generated when a validator generates new block-candidatevalidatorSession.message.approvedBlock message is related to the Block candidate approval stage. It informs that a validator approved the block candidate in a specific round. Each validator chooses a list of blocks for approval sorted by node priority. Only blocks that were not approved before are included in the list. The approval itself is performed by a validator (as opposed to a validator session). The block is approved only from specific time (CandidateDecision::ok_from) computed by a validator. Block approval is initiated immediately after block candidate verification and signing. The message has the following structure:round: int - number of the round when candidate block was approved;candidate : int256 - hash of block-candidate;signature : bytes - validator signature.Actions: this message has to be generated when validator approves one or several block candidates.validatorSession.message.rejectedBlock message is related to Block candidate approval stage. The message informs that validator has checked the block candidate and rejects it. This message is ignored by consensus itself (has no side effects except of logging if the message has been received by a validator). The message has following structure:round: int - number of the round when candidate block has been rejected;candidate : int256 - hash of block-candidate;reason : bytes - rejection reason (validator specific).Actions: this message is generated when block verification is failed. The message is not transitive, and should be sent only if the current validator rejects the block-candidate.validatorSession.message.voteFor message is related to the Voting attempts stage. The message can be sent only by a validator with priority to generate an attempt “vote-for” candidate. The “vote-for” block is selected at random from approved blocks by a validator with a “vote-for” priority for the current attempt.round : int - number of the round;attempt : int - number of an attempt where candidate block will be chosen as &quot;vote-for&quot; block;candidate : int256 - block-candidate hash.Actions: this message has to be generated if:a) node has “vote-for” block generation priority for this attempt;b) node has at least one approved block;c) node has has no precommitted block;d) node sent no validatorSession.message.voteFor during this attempt.validatorSession.message.vote message is related to the Voting attempts stage. The message is sent to inform that a validator votes for a candidate. The message has following structure:round : int - number of the round;attempt : int - number of an attempt where validator voted for candidate block;candidate : int256 - block-candidate hash.A validator votes for block in one of the following case (the logical OR):a) a block was voted in one of previous attempts during the round;b) a block was proposed by a validator with min priority for the round if current attempt is not first one and the maximum number of round attempts was not reached;c) a block was proposed in validatorSession.message.voteFormessage by a validator with &quot;vote-for&quot; generation priority if attempt is the first or the max attempt number is exceeded (opposite to the case (b) above).Actions: this message has to be generated if there is no precommitted block during the current attempt and one of validator voting cases triggered.validatorSession.message.precommit message is related to the Voting attempts stage. The message is sent by each validator to notify that the validator has selected voted block as a precommitted. The precommitted block has to be voted by at lease 2/3 of total validators weight. Note, for some reason telegram’s consensus ignores the case when node precommit block is not equal to candidate for this round and only prints warning to log about such case. The message has the following structure:round : int - number of the round;attempt : int - number of an attempt where validator chose candidate block as a block for precommit;candidate : int256 - block-candidate hash.Actions: this message has to be generated when all conditions below are met:a) node has not sent validatorSession.message.precommit in this attempt;b) there is a block with 2/3 of total validators weight.validatorSession.message.commit message is related to the Block committing stage. This message informs that validator signed the block candidate as a block to be committed for a round. The message has the following structure:round: int - number of the roundcandidate : int256 - block-candidate hash;signature : bytes - signature of the validator.validatorSession.message.empty a special message which is used as a marker to stop generation of messages during synchronization from internal validator state to the list of incremental messages which will be sent to other validators. The message has following structure:round : int - number of the round where synchronizations takes place;attempt : int - number of an attempt where synchronization takes place.Actions: this message has to be generated to indicate there is no additional messages to sync state (in attempt and round). b. validatorSession.blockUpdate message is the root message for validator session blocks update. It is packed to a payload of catchain.block.data.vector. This message is generated after each consensus iteration and has the following structure: ts : long - timestamp for block's update generation (unix time, global);actions : vector validatorSession.round.Message - list of validatorSession.round.Message with incremental updates for consensus state synchronization on other validators;state : int - state hash after action is applied; it is used like a checksum for sanity checks (computed recursively for session state; not a trivial linear hash of the buffer with actions). c. validatorSession.candidate message is sent to Catchain as a broadcast when new candidate block appears (after validator on_generate_slot callback). Also, it may be sent at a start of Catchain execution on each validator for all blocks approved this validator approved as candidates to Catchain (from validator get_blocks_approved_by and get_approved_candidate). This message initiates blocks approval if received in a broadcast and has the following structure: src : int256 - validator which has generated a block-candidate;round : int - number of a round where block-candidate appears;root_hash : int256 - root hash of block-candidate;data : bytes - block-candidate data;collated_data : bytes - block-candidate collated data. IV. Queries: validatorSession.downloadCandidate messages is used as broadcast to request a round block-candidate with a specific identifier. A validator generates it, if it has no block candidate for further consensus processing. Request: round : int - number of the round where block-candidate appears;id : validatorSession.candidateId - block-candidate identifier. Side effect: validatorSession.candidate - block-candidate is sent as an event during the request processing. "},{"title":"Accounts","type":0,"sectionRef":"#","url":"/arch/accounts","content":"","keywords":""},{"title":"Account Structure Definition​","type":1,"pageTitle":"Accounts","url":"/arch/accounts#account-structure-definition","content":"The account structure is defined as follows: struct AccountStuff { addr: MsgAddressInt, storage_stat: StorageInfo, storage: AccountStorage, } type Account = Option&lt;AccountStuff&gt;;  AccountStuff structure fields​ Field\tDescriptionaddr\tAccount address storage_stat\tAccount storage use statistics storage\tAccount smart-contract storage "},{"title":"Account Address​","type":1,"pageTitle":"Accounts","url":"/arch/accounts#account-address","content":"The location of an account on Everscale blockchain is represented as a two-value structure: the workchain number and the account identifier. This structure is called an account address. Hereinafter, we just call it address for greater convenience. Addresses are defined as follows: pub enum MsgAddressInt { AddrStd(MsgAddrStd), AddrVar(MsgAddrVar), } pub struct MsgAddrStd { pub anycast: Option&lt;AnycastInfo&gt;, pub workchain_id: i8, pub address: AccountId, } pub type AccountId = SliceData;  The address may be encoded by one of the two structures: MsgAddrStd or MsgAddrVar. The latter is used to locate accounts in huge blockchains, when the standard 8-bit workchain_id is not enough, and not supported currently. Type SliceData denotes a binary blob encoded in a tree data structure.Type i8 is an 8-bit signed integer. MsgAddrStd structure fields​ Field\tDescriptionanycast\tMulti-shard contracts routing information workchain_id\tWorkchain identifier address\tAccount identifier within the workchain caution Anycast-addresses are planned to be removed shortly. "},{"title":"Account Storage​","type":1,"pageTitle":"Accounts","url":"/arch/accounts#account-storage","content":"Any account on the Everscale blockchain is being charged for occupying space on a regular basis. The fee depends on the size of data being stored, the current prices and when the last charge took place. In some circumstances, an account may also have a debt, called due payment. Most of this information is stored in the StorageInfo structure. pub struct StorageInfo { used: StorageUsed, last_paid: u32, due_payment: Option&lt;Grams&gt;, } pub struct StorageUsed { cells: VarUInteger7, bits: VarUInteger7, public_cells: VarUInteger7, }  StorageInfo structure fields​ Field\tDescriptionused\tBlockchain storage use statistics last_paid\tTime of the latest payment, in Unix Epoch due_payment\tDebt of the account Type Grams denotes a set of natural numbers {0,...,2256}\\{0, ..., 2^{256}\\}{0,...,2256}, equipped with ⊕\\oplus⊕ and ⊖\\ominus⊖ operators, such that: a⊕b=(a+b) mod 2256a \\oplus b = (a + b) \\,\\, \\boldsymbol{mod} \\,\\, 2^{256}a⊕b=(a+b)mod2256 a⊖b=max(a−b,0)a \\ominus b = \\boldsymbol{max}(a - b, 0)a⊖b=max(a−b,0) Here +++ and −-− operators are standard addition and subtraction operators in a set of integers Z\\mathbb{Z}Z. Amount of storage used by the account is encoded with StorageUsed struct. StorageUsed structure fields​ Field\tDescriptioncells\tNumber of cells occupied by the account bits\tNumber of bits occupied by the account public_cells\tField is not used To store the data in a tree-like form, it is encoded as a series of interlinked cells. This data structure also consumes some space and it is accounted for in the cell field. The bits field refers to data size being encoded in the cells. "},{"title":"Account Data​","type":1,"pageTitle":"Accounts","url":"/arch/accounts#account-data","content":"The full account record is represented by several nested data structures: Account storageAccount stateSmart-contract storage called StateInit "},{"title":"Account Storage structure​","type":1,"pageTitle":"Accounts","url":"/arch/accounts#account-storage-structure","content":"The most outer record is the account storage. It contains the account balance and the account state. The account state may contain the smart-contract code and data, described by the structure called StateInit. pub struct AccountStorage { last_trans_lt: u64, balance: CurrencyCollection, state: AccountState, }  AccountStorage fields​ Field\tDescriptionlast_trans_lt\tLast transaction logical time balance\tAmount of cryptocurrency tokens available for the account state\tCurrent account state "},{"title":"Account State​","type":1,"pageTitle":"Accounts","url":"/arch/accounts#account-state","content":"The account state defines the mode of operation for the account, during the message being executed for that account. The Transaction Executor logic varies greatly depending on what the current account state is. The account state may have additional data fields. See the enumeration below. enum AccountState { AccountUninit, AccountActive{ init_code_hash: Option&lt;UInt256&gt;, state_init: StateInit, }, AccountFrozen{ init_code_hash: Option&lt;UInt256&gt;, state_init_hash: UInt256, }, }  The life cycle of an account is depicted on Fig. Let us clarify the fields of enumeration items. For AccountActive, the value stateinit defines the byte-code and data of the associated smart-contract. The field _init_code_hash defines the hash of the field state_init.code that was used at the moment of the account initialization, or at the moment of the account freeze. In Everscale, it is possible to change the smart-contract's code on the fly using the SetCode action. However, the value init_code_hash stays unaffected. The same holds for AccountFrozen. The value of state_init_hash defines the hash of the smart-contract state_init.code at the moment of a freeze. "},{"title":"Smart-Contract Storage (StateInit)​","type":1,"pageTitle":"Accounts","url":"/arch/accounts#smart-contract-storage-stateinit","content":"The byte-code and data of a contract are stored within a structure called StateInit. Its name may seem quite confusing. It could have been named just State. The Init part comes from the fact that this structure is also used for the initialization of an account when it is uninitialized. pub struct StateInit { pub split_depth: Option&lt;Number5&gt;, pub special: Option&lt;TickTock&gt;, pub code: Option&lt;Cell&gt;, pub data: Option&lt;Cell&gt;, pub library: StateInitLib, }  split_depth field was initially devoted to large multi-shard smart-contracts, but currently it is not used. special fields signal the fact that the smart-contract is related to the blockchain system functioning. This is related to the very small amount or contracts residing in the Masterchain, i.e. Elector, Config, Giver, etc. There is a special logic to executing messages destined for those contracts. code and data fields encodes the current byte-code and data of a contract. Here, data denote values of contract's variables. library used to encode the code libraries the contract may refer to from its code. This mechanism is deprecated. "},{"title":"Introduction","type":0,"sectionRef":"#","url":"/arch/consensus/introduction","content":"Introduction This document was created when EverX started to reverse engineer a consensus protocol from publicly released source code of Telegram node as part of EverX Node implementation. We decided to release this document after the author of the protocol, Dr. Nikolai Durov, released a consensus outline 👉 https://test.ton.org/catchain.pdf and we highly recommend everybody read the original. In this research, we wanted to help other engineers and the general public to gain a better understanding of the underlying protocol, to provide more context by comparing it to other protocols and give more details about practical aspects of Catchain. Everscale consensus (dabbed Catchain by its author) is a Proof-of-stake consensus algorithm from a family of Byzantine Fault Tolerant (BFT) algorithms. It includes the consensus algorithm as well as a protocol for message exchange between validator nodes in a network. BFT consensus is based on Byzantine Generals agreement and describes a problem of reaching a consensus in distributed system when each network participant does not have an information about the whole network and may not trust any of its participants. Blockchain consensus is a classical example of BFT problem as none of the block producers can be trusted or reachable at any given moment. Consensus lies at the core of any blockchain as it allows network nodes to agree on the next block in the blockchain without trusting each other. There are generally two classes of POS consensus algorithms. First (CBC Casper, Ouroboros, etc.) when block generation is very easy but forks are allowed with subsequent process of complex agreement on their resolution among the network participants. Catchain belongs to another class — the class of algorithms where block generation agreement is hard but forks are rare or impossible (PBFT, Tendermint, Algorand etc.) From a life-cycle perspective, the Catchain consensus includes the following stages: stake-based validator electionsvalidation session startupseveral block generation rounds Each block generation round has limited time and consists of several attempts. So, if validators fail to agree during all available attempts, the round is skipped and the new block is not committed to the blockchain. In the course of a round, validators exchange messages about block candidates generated by collators, validate these candidates, select vote candidates, vote for them and finally commit the elected block to the blockchain. To prevent consensus monopolization, the algorithm uses a round-robin role transfer from validator to the validator. So each round and each attempt several validators are assigned to generate blocks and one validator is assigned to propose a block for voting. As validators change roles from an attempt to attempt, the consensus mechanism cannot be blocked by a failure to get a decision from the majority of validators. The key idea here is to make sure that 2/3 of validator votes for a particular block are actually cast. The 2/3 cutoff threshold is a theoretical value that allows making sure that the decision via consensus is made. To improve the overall network performance, partial cross-node message synchronization is used. It means that any validator only interacts with a randomly selected subset of validators and uses data obtained from them to make a decision during a validation round. This data also includes aggregated transitive data received from other validators and signed by their signatures.","keywords":""},{"title":"Catchain Overview","type":0,"sectionRef":"#","url":"/arch/consensus/overview","content":"","keywords":""},{"title":"Node Catchain Initialization​","type":1,"pageTitle":"Catchain Overview","url":"/arch/consensus/overview#node-catchain-initialization","content":"Catchain session begins with the creation of the CatchainImpl and the CatChainReceiverImpl objects. The CatChainReceiverImpl configures the ADNL overlay upholding the communication with other validators. Next step is CatChainReceiverImpl restoring previously received blocks from a RocksDB database instance (see CatChainReceiverImpl::read_db_from and CatChainReceiverImpl::read_block_from_db for the details). On top, there is always a block with hash=0 acting as a starter block for downloading block predecessors and dependencies. The central processing loops starts after the database reading stage is complete (see CatChainImpl::on_receiver_started and CatChainImpl::send_process for the details). The consensus algorithm initiates new block candidates generation for further approval — the block transfers to the catchain when a new candidate appears. In case there are no blocks, validator awaits for blocks from other validators on the catchain. "},{"title":"Scheduled Actions​","type":1,"pageTitle":"Catchain Overview","url":"/arch/consensus/overview#scheduled-actions","content":"Each validator sends results of its work only to several neighbors (currently set to 5) minimizing traffic. Neighborhood randomly changes every 60–120 seconds. Every 2–3 seconds, the system randomly picks a validator from the overall validator list for synchronization. This synchronization is bi-directional: The validator-initiator sends a list containing delivered blocks heights (including vector timestamps, according to “Catchain Consensus: An Outline”). The validator expects to either receive absent blocks or a fork event notification in response. In the case of confirmed forking, consensus will blame the validator and discard all messages. Only the current validator can verify forking. Validator compares it’s own block heights list with the received list and sends the difference, if any, to the requester. Such a process optimizes network traffic and reduces the average height of delivered blocks while limiting the count of outgoing response messages to 100.The validator-initiator requests the delivery of all absent dependent blocks generated by a validator-answerer.Invoking consensus algorithm iteration (will be described below). Each synchronization adds information about states of other validators, making the next consensus iteration possible on the validator. "},{"title":"Blocks Processing​","type":1,"pageTitle":"Catchain Overview","url":"/arch/consensus/overview#blocks-processing","content":"There are several types of blocks in the catchain: blocks written to a blockchain;catchain blocks with a state of the particular validator (CatchainReceivedBlock). They are the messages with source validator number identification, consensus algorithm iteration number (height) and consensus increment messages; CatchainReceivedBlock are the temporal sources for consensus blocks creation (CatchainBlock);CatchainBlock blocks built from several CatchainReceivedBlock blocks(CatchainBlock consists of CatchainReceivedBlock blocks states with maximal known height for a validator ). The CatchainReceivedBlock block consists of the following: catchain session identifier (to exclude the case when blocks from the previous catchain session are processed);number of the block origin source validator;block height (it is equal to the consensus algorithm iteration number for a particular validator);fork number (if several forks from the same validator are detected, the chain of blocks is invalidated and the validator is blamed);previous block sent to other validators (outgoing block);dependent blocks received by other validators (incoming blocks); note, that an incoming block cannot depend on two blocks from the same source validator; in general, this is a DAG. The dependent blocks graph allows for: recursively downloading of all blocks required for the full state of the processed block;recursively marking a subgraph of blocks as an invalid if forks are detected from a particular source validator. Each validator contains a list of states of other validators. Each of them stores CatchainReceivedBlock blocks that came from them. Every new incoming CatchainReceivedBlock block is checked regardless of which data channel it came from (directly from the validator or transitively, see CatChainReceiverImpl::validate_block_sync). If the block signature does not match the expected signature of the sender validator, or if the block is invalid, the block is ignored. The validator checks each catchain validator for forks. Only one fork per validator is allowed. In case when the same validator sends two different blocks with the same height, it is marked as a blamed and all CatChainReceivedBlockImpl corresponding to this validator are invalidated. The validator itself ignore till the end of the current catchain session. After the CatChainReceivedBlockImpl block is received, its processing is initiated (see CatChainReceiverImpl::receive_block). Then it is recorded to the database. The processing procedure downloads all dependents for the block and further adding the block to a queue of blocks ready to be run. This download procedure is done each 2-3 seconds by synchronization with other validators which are being asked for absent CatChainReceivedBlockImpl blocks. When any data updates are received (from the database during initialization, when new blocks are received, and while adding new blocks after the work of the consensus algorithm (see CatChainImpl::processing_block)), the CatChainReceivedBlockImpl block execution procedure is launched. Each validator contains state lists for other validators. Each of them stores CatchainReceivedBlock blocks received from others. Every new incoming CatchainReceivedBlock block is checked regardless of which data channel it came from (directly from the validator or transitively, see CatChainReceiverImpl::validate_block_sync). Validator ignores the block if the block signature does not match the expected signature of the sender validator or if the block is invalid. The active validator checks each catchain validator for forks. Only one fork per validator is allowed. In case the same validator sends two different blocks with the same height, catchain marks it as blamed and all CatChainReceivedBlockImpl blocks corresponding to this validator are invalidated. Consensus mechanics then ignore the validator itself until the end of the current catchain session. Receiving the CatChainReceivedBlockImpl block initiates the processing (see CatChainReceiverImpl::receive_block) and creates a database entry. The processing procedure downloads all dependents for the block. At the next step, it adds the block to a queue of blocks ready to be run. The download procedure is done every 2-3 seconds through synchronization with other validators required to provide absent CatChainReceivedBlockImpl blocks. The CatChainReceivedBlockImpl block execution procedure initiates whenever any data updates are received (from the database during initialization, when new blocks are received, and while adding new blocks after the work of the consensus algorithm (see CatChainImpl::processing_block)). Block execution includes: creating a fork from the existing previous block (in this case, blame procedure initialization is possible if the fork already exists);preliminary procedures for processing the block (pre_deliver);processing of the block. Pre-processing of a CatChainReceivedBlockImpl includes checking forks (see CatChainReceivedBlockImpl::pre_deliver). Block processing (see CatChainReceivedBlockImpl::delivery) includes the following: deliver_block — notification that the block is ready for this validator. This notification consists of: Notifying all neighbors about the appearance of a new CatChainReceivedBlockImpl block;Generating a new CatchainBlock block and placing it on the top of the chain from the validator that sent the corresponding CatChainReceivedBlockImpl block. The CatchainBlock block used in the consensus algorithm is a copy (snapshot) of the corresponding CatChainReceivedBlockImpl block excluding the data used for dependencies downloading process; dep_delivered — all dependent CatChainReceivedBlockImpl blocks (outgoing dependency) notification. This places dependents into a queue of blocks ready to be run;block_delivered — internal data update on validator-initiator (CatchainReceivedBlockImpl sender) sent blocks. CatchainBlock blocks received from the validator are the input for the consensus algorithm. Structurally, this block is very similar to the CatChainReceivedBlockImpl block. However, it contains all the data necessary for further processing (unlike CatChainReceivedBlockImpl, where some data may be missing). Catchain stores a list of the CatchainBlock top blocks — one for each validator — and runs the consensus algorithm periodically by the timer at the beginning of work and on-demand (see CatChainImpl::send_process for the details). The consensus iteration identification for each validator is the height of a block that the consensus algorithm generated. Thus, a pair (validator number, block height) uniquely identifies the block for a particular validator. Processing consensus results of one validator on another validator might result in two different blocks with the same height and validator numbers. This will result in fork appearance and identification key will extend to (validator number, block height, fork number). However, since catchain does not allow forks, the source validator where forked block originated will be blamed. So the fork number may be skipped and CatchainBlock may be identified identification may using (validator number, block height). The consensus iteration begins by selecting a random subset from the list of CatchainBlock top blocks (no more than max_dept=4) and passing them to the consensus algorithm described above (see ValidatorSessionImpl::process_blocks). Note that a separate validator sent each such block and there can’t be two blocks from a single validator. These blocks merge within the consensus algorithm, and a new CatchainBlock appears on their basis. Catchain reports this block appearance (see CatchainImpl::processed_block). Adding a new block leads to writing it into the database and creating a CatChainReceivedBlockImpl block from it, further sent to neighbors. "},{"title":"Catchain Protocol Messages & Structures","type":0,"sectionRef":"#","url":"/arch/consensus/messages","content":"","keywords":""},{"title":"Internal structures:​","type":1,"pageTitle":"Catchain Protocol Messages & Structures","url":"/arch/consensus/messages#internal-structures","content":"1.catchain.block.dep src: int - index of validator that generated the block;height : int - height of the block on a validator with index src;data_hash : int256 - block data hash; used in block pre-validation;signature : bytes - signature done by a validator with index src of the block; needed for pre-validation of the block. 2.catchain.block.data This structure describes the block with links to the previous block on the validator and dependent blocks used to generate the current one. For the specified (src, height) there can be only one previous block in a Catchain. If forks are detected, the validator that sent the second block candidate for specified (src, height) is marked as blamed and all its data is discarded. The catchain.block.data structure described below: prev : catchain.block.dep ****- previous block description;deps : vector of catchain.block.dep - list of dependent blocks used to generate this block. 3.catchain.block This structure describes a block with a payload. incarnation : int256 - ID of the Catchain session equal to the hash of the first block used at the start of Catchain session;src : int - index of the validator that generated the block;height : int - height of the block on a validator with index src;data: catchain.block.data - block header with information about the previous block and dependent blocks used to generate the current block. 4.catchain.block.inner.Data This is a variable structure with one of the following subtypes: catchain.block.data.badBlock, catchain.block.data.fork, catchain.block.data.nop, catchain.block.data.vector. This structure is placed immediately after the catchain.block structure and contains the corresponding block payload. catchain.block.data.vectorThis message contains the internal validator session component data represented by a list of messages specific for a validator session. The catchain.block.data.vector structure is used as a container to distribute consensus algorithm data between validators.msgs: vector of bytes - internal validator session data (is used as a buffer of bytes for Catchain component).catchain.block.data.forkThis message contains fork proofs for a specified pair of blocks. When two blocks with different hashes, but the same height are received from a validator with index src, a fork is detected. In this case, the validator in question must be blamed and all incoming data from it must be discarded. All blocks dependent on a detected fork must be discarded.left : catchain.block.Dep - first known block;right: catchain.block.Dep - detected fork block.catchain.block.data.badBlockReserved and is not used at the momentcatchain.block.data.nopReserved and is not used at the moment Events: 1. catchain.blockUpdate This event informs the validator that a specific block is updated. The validator then has to add it to the processing queue, check for forks and check all upstream and downstream block dependencies. Dependency checks may result in one or multiple block status updates. Once fully resolved, a block can be used as a source for state computation of the next consensus iteration. A validator session iteration uses a random subset of fully resolved blocks (blocks having all dependent blocks received and pre-validated by the current validator). This subset contains blocks from different validators for further merging and building a new Catchain block according to the resulting merged state. catchain.blockUpdate has the following structure: block : catchain.block - block description with a mandatory catchain.block.inner.Data payload.signature : bytes - block signature performed by a validator (with validator index block.src); used for block pre-validation. Queries: 1. catchain.getBlock (mandatory) This query is used by the catchain component to request an absent block from another validator. Request:block : int256 - hash of the requested block;Response — catchain.BlockResult (variadic):`catchain.blockResult` sent if the block is foundblock : catchain.block - description of the requested block with catchain.block.inner.Datapayloadcatchain.blockNotFound - sent if the block is not found 2.catchain.getBlocks (optional; not used by Catchain component internally) This query is used to request several blocks from another validator. Request:blocks : vector int256 - the list of requested blocks;Response — catchain.sent:cnt : int - the number of blocks sent back.Side effect:Several `catchain.blockUpdate` events are sent back to the validator-requester before response. 3.catchain.getDifference (mandatory) This is the initial request sent by one validator to another one to receive absent blocks. The validator-requester sends а list of delivered heights to the counter-party and expects to get back blocks that were not delivered (difference). Initially, the validator-requester may send a list of zero heights to the counter-party to initiate synchronization of blocks. Also, the catchain.getDifference request should be regularly made to neighbor validators to synchronize with them. Request:rt : vector int - the list of heights of blocks already delivered to a validator-requester.Response — catchain.Difference (variadic):`catchain.difference` sent when no forks are detected (regular case)sent_upto: vector int - the vector of heights known on a validator-responder; not used in a Catchain component now;catchain.differenceFork - sent when forks are detectedleft : catchain.block.dep - the first known block;right : catchain.block.dep - the detected fork block.Side effect:Several catchain.blockUpdate events sent back to a validator-requester before response catchain.difference. 4.catchain.getBlockHistory (optional, not used by the Catchain component internally) This query is used to obtain blocks used to build a block with a specified reverse height (number of blocks reverse to the specified block). Request:block : int256 - the target block hash;height : long - the number predecessor blocks of the block;stop_if : vector int256 - list of block hashes which should stop search if one of them is detected during the history processing.Response — catchain.sent:cnt : int - the number of blocks sent back. "},{"title":"References​","type":1,"pageTitle":"Catchain Protocol Messages & Structures","url":"/arch/consensus/messages#references","content":"Pease, Marshall; Shostak, Robert; Lamport, Lesli Reaching Agreement in the Presence of Faults, https://dl.acm.org/doi/10.1145/322186.322188Yuval Marcus, Ethan Heilman, Sharon Goldberg. Low-Resource Eclipse Attackson Ethereum’s Peer-to-Peer Network, https://eprint.iacr.org/2018/236.pdfEthan Buchman, Tendermint: Byzantine Fault Tolerance in the Age of Blockchains, https://atrium.lib.uoguelph.ca/xmlui/bitstream/handle/10214/9769/Buchman_Ethan_201606_MAsc.pdfMiguel Castro and Barbara Liskov. Practical Byzantine Fault Tolerance, http://pmg.csail.mit.edu/papers/osdi99.pdfAggelos Kiayias, Alexander Russell, Bernardo David, Roman Oliynykov. Ouroboros: A Provably Secure Proof-of-Stake Blockchain Protocol, https://eprint.iacr.org/2016/889.pdfV. Zamfir, “Casper the friendly ghost: A correct by constructionblockchain consensus protocol,” https://github.com/ethereum/research/blob/master/papers/CasperTFG/CasperTFG.pdfJing Chen, Silvio Micali. Algorand, https://arxiv.org/pdf/1607.01341.pdf "},{"title":"Network Fees","type":0,"sectionRef":"#","url":"/arch/fee-calculation","content":"","keywords":""},{"title":"Fee calculation​","type":1,"pageTitle":"Network Fees","url":"/arch/fee-calculation#fee-calculation","content":""},{"title":"Introduction​","type":1,"pageTitle":"Network Fees","url":"/arch/fee-calculation#introduction","content":"Transaction fees consist of a few types of different fees connected to the execution of a single transaction. Transactions itself are complex processes, and fees are paid relative to different stages of executing them. In this document, we explain how the fees are calculated. We shall define transaction_fee as a sum of all fees for a single transaction. transaction_fee = inbound_external_message_fee + storage_fees + gas_fees + total_action_fees + outbound_internal_messages_fee  Where: inbound_external_message_fee — is deducted, if an inbound external message is imported in the transaction. storage_fees — storage costs since the moment of the last transaction. gas_fees — include all gas fees associated with the transaction. You can find more info in the Gas calculation basics section. total_action_fees — fees for performing send message actions. outbound_internal_messages_fee — is calculated as a sum of fees for all outbound internal messages generated by the transaction. Depending on the nature of the transaction, all of these except storage fees may not be applicable. Below we examine these types of fees in detail. Note: Block creation fee is not to be confused with the fees discussed in this document. Block creation fee is the new coins minted by the elector contract and distributed among validators as reward for creating blocks. It is not part of transaction fees. "},{"title":"Storage fees​","type":1,"pageTitle":"Network Fees","url":"/arch/fee-calculation#storage-fees","content":"Every transaction in Everscale has a storage phase that implies a certain storage fee charged on an account balance. This fee is charged for the period between transactions and is calculated according to the following formula: storage_fees = CEIL( ( account.bits * global_bit_price + account.cells * global_cell_price ) * period / 2 ^ 16 )  Where: account.bits and account.cells — stand for a number of bits and cells in the Account structure represented as tree of cells (including code and data). global_bit_price — is a global configuration parameter (p18 for both masterchain and workchains), price for storing one bit. global_cell_price — another global configuration parameter (p18 for both masterchain and workchains), price for storing one cell. period — number of seconds since previous storage fee payment. Note: While account.bits are generally easy to estimate, the account.cells value can vary greatly for different types of data. A cell can contain no more than 1023 bits and 4 references to other cells. Contract code and numerical variables tend to be packed into cells effectively, resulting in mostly full cells, and thus a minimal number of cells needed to store the data. More complex data structures can be packed into cells less efficiently, taking up more cells to store the same amount of data. Example: Let's calculate a minimal fee for storing 1KB of data for the duration of one day on a workchain: global_bit_price = 1 global_cell_price = 500 period = 86400 seconds account.bits = 8192 The minimal account.cells value for 8192 bits of data is 9 (rounding 8192/1023 up to the nearest integer). Thus the minimum storage fee would be calculated as follows: storage_fees = CEIL( ( 8192 * 1 + 9 * 500 ) * 86400 / 65536 ) = 16733 nanotokens = 0.000016733 tokens  Real storage fees for 1KB account can be higher, depending on the specific features of the contract. If the account balance is less than the due storage fee, the account is frozen and its balance is subtracted from storage fee and reduced to zero. Remaining storage fee is stored in account as debt. Note: Current global configuration can be always reviewed on [ever.live]( https:/ /ever.live/) in the master config section of the latest key block details (example) FIXME broken link. It can only be changed by a vote of validators. "},{"title":"Message fees​","type":1,"pageTitle":"Network Fees","url":"/arch/fee-calculation#message-fees","content":"Every message is subject to a forwarding fee, which is calculated according to the following formula: msg_fwd_fee = ( lump_price + CEIL( ( bit_price * msg.bits + cell_price * msg.cells ) / 2 ^ 16 ) )  msg.bits and msg.cells are calculated from message represented as a tree of cells. Root cell is not counted. lump_price, bit_price, cell_price are contained in global config parameters p24 and p25, and can and can only be changed by a vote of validators. Note: Like in storage fees, msg.bits are generally easy to estimate, while the msg.cells value can vary for different types of messages. Example: Let's calculate a minimal forward fee for sending a 1KB message on a workchain: lump_price = 10000000 bit_price = 655360000 cell_price = 65536000000 To calculate msg.bits we subtract the root cell bits from the total message bits. For this example we'll assume that the root cell is filled completely (usually this is not the case, and the subtracted value is smaller, which results in a higher fee): msg.bits = 8192 - 1023 = 7169  To calculate msg.cells we subtract the root cell from the total umber of cells. The minimal number of cells in a 1 KB message is 9 (rounding 8192/1023 up to the nearest integer). Thus msg.cells is calculated as follows: msg.bits = 9 - 1 = 8  The minimum forward fee for a 1KB message would be calculated as follows: msg_fwd_fee = ( 10000000 + CEIL( ( 655360000 * 7169 + 65536000000 * 8 ) / 65536 ) ) = 89690000 nanotokens = 0.08969 tokens  Real forward fees for 1 KB messages may be higher, depending on the type and contents of the message. Note: Current global configuration can be always reviewed on ever.live in the master config section of the latest key block details (example) FIXME broken link. Outbound messages​ outbound_internal_messages_fee is calculated as a sum of outbound internal message fees for every message generated as result of transaction execution: outbound_internal_messages_fee = SUM( out_int_msg.header.fwd_fee + out_int_msg.header.ihr_fee )  Where out_int_msg.header.fwd_fee is a part of the standard forward fee for the outbound internal message. out_int_msg.header.ihr_fee is currently disabled. Routing​ The forward fee for outbound internal message is split into int_msg_mine_fee and int_msg_remain_fee: msg_forward_fee = int_msg_mine_fee + int_msg_remain_fee  Where: int_msg_mine_fee = msg_forward_fee * first_frac / 2 ^ 16  first_frac — is contained in global config parameters p24 and p25, and determines the fraction of the fee, that the current set of validators receive. Note: Current global configuration can be always reviewed on ever.live in the master config section of the latest key block details (example) FIXME broken link. int_msg_mine_fee then becomes part of transaction action fees (see below). The remaining int_msg_remain_fee is placed in the header of outbound internal message (becoming out_int_msg.header.fwd_fee) and will go to validators who will process the message. If, while being forwarded to the destination address, the message passes through additional validator sets (i.e. if the validator set changes more than once while the message is being forwarded), a part of out_int_msg.header.fwd_fee is payed to the relevant validator set every time and the remaining fee in the message header is reduced by this amount: intermediate_fee = out_int_msg.header.fwd_fee * next_frac / 2 ^ 16  next_frac — is contained in global config parameters p24 and p25, and determines the fraction of the remaining forward fee, that intermediary validators receive. Note: Current global configuration can be always reviewed on ever.live in the master config section of the latest key block details (example) FIXME broken link. Note: Length of route does not affect the initial calculation of the forward fee. The fee is simply split between all involved validators according to global config parameters. Note: If an exception is thrown, and a bounce message is generated, it is subject to fees, just like a single regular outbound message. Inbound external messages​ Whenever an inbound external message needs to be imported for transaction execution, the for this action fee is calculated according to the standard forwarding fee formula, and paid to the current validators. "},{"title":"Action fees​","type":1,"pageTitle":"Network Fees","url":"/arch/fee-calculation#action-fees","content":"Action fees pay for performing 'send message' actions. They consist of all fees for external outbound messages, and the first fraction of internal outbound message fees. They are calculated as follows: total_action_fees = total_out_ext_msg_fwd_fee + total_int_msg_mine_fee  where: total_out_ext_msg_fwd_fee — sum of implicit forward fee for all generated outbound external messages.total_int_msg_mine_fee — sum of 'mine' parts of message forward fees for outbound internal messages.total_fwd_fees — is a separate way to calculate total forwarding fees. total_fwd_fees = total_action_fees + SUM( int_msg_remain_fee + out_int_msg.header.ihr_fee )  out_int_msg.header.ihr_fee — this fee is currently zero. The action fee might be absent if no actions are performed during the transaction. "},{"title":"Gas fees​","type":1,"pageTitle":"Network Fees","url":"/arch/fee-calculation#gas-fees","content":"trans.gas_fees includes all gas fees associated with the transaction. As with Action fees, Gas fees are not always applicable. They can be skipped if the TVM compute phase is not initialized for a transaction. In order to study the calculation of Gas fees in detail please consult this page. "},{"title":"Managing gas​","type":1,"pageTitle":"Network Fees","url":"/arch/fee-calculation#managing-gas","content":""},{"title":"Gas calculation basics​","type":1,"pageTitle":"Network Fees","url":"/arch/fee-calculation#gas-calculation-basics","content":"Specification Overview​ The entire state of TVM consists of the five components: StackControl registersCurrent continuationCurrent codepageGas limits Collectively these are called SCCCG. Check out section 1.4 of the TVM specification. The Gas component limits gas usage and сontains four signed 64-bit integers: the remaining gas: grthe current gas limit: glthe maximal gas limit: gmthe gas credit: gc The following is always true: 0≤gl≤gm,gc≥0,andgr≤gl+gc0 ≤ gl ≤ gm, gc ≥ 0, and gr ≤ gl + gc0≤gl≤gm,gc≥0,andgr≤gl+gc gc is initialized by zero for internal messages, gr is initialized by gl + gc and gradually decreases, as the TVM runs. When gr becomes negative or if contract terminates with gc &gt; 0, an out of gas exception is triggered. Gas prices​ As stated in A.1 of the TVM specification. According to the original TON, for most primitives gas is calculated according to the following formula: Pb:=10+bPb := 10 + bPb:=10+b where b is the instruction length in bits. The same is true for EverX implementation. For example: the gas required for A0 (ADD) instruction is 10 + 8 = 18 gas, while the gas for A6cc (ADDCONST cc) instruction is 10 + 16 = 26 gas. For some instructions this rule does not apply. TVM specification lists either total gas prices, or prices in addition to the basic Pb for them explicitly. Instruction list with additional information may be obtained in A.2 through A.13 of the TVM specification. Apart from integer constants, the following expressions may appear: The total price of loading cells. Currently it is 100 gas units per cell. Reloading a cell again now costs 25 gas units.The total price of creating new Cells from Builders. Currently it is 500 gas units.Exception throwing. 50 gas units per exception.Exiting the block costs 5 gas units per implicit RET. Jumping to the first link costs 10 gas units - implicit JUMP.Moving to a new continuation with transferring parameters costs gas if there are more then 32 parameters. It costs N-32 gas, where N is the number of parameters.Tuple gas price. 1 gas unit for every tuple element. Note: that the most expensive operations are dictionary read/write operations. Dictionaries are stored in the form of trees of cells, where each cell can only be linked to four others. As result, these trees can grow quite large, depending on the data that needs to be stored. To read data in any cell, all its parent cells need to be read first, at the price of 100 gas per cell, and to write data in a cell, similarly all its parent cells need to be (re)created at the price of 500 gas per cell. Global gas limits​ Global gas limits are values stored in the masterchain configuration contract. Global values are standard and do not change at contract deployment. Only validator consensus can modify them. The values currently used can always be reviewed on ever.live in the latest key block details (example FIXME broken link). p20 config parameter values are used for masterchain and p21 values are used for workchain. Gas-related TVM primitives​ These is the list of official TVM primitives used for gas-related operations: F800 — ACCEPT, sets current gas limit gl to its maximal allowed value gm, and resets the gas credit gc to zero, decreasing the value of gr by gc in the process. In other words, the current smart contract agrees to buy some gas to finish the current transaction. This action is required to process external messages, which bring no value (hence no gas) with themselves.F801 — SETGASLIMIT (g – ), sets current gas limit gl to the minimum of g and gm, and resets the gas credit gc to zero. If the gas consumed so far (including the present instruction) exceeds the resulting value of gl, an (unhandled) out of gas exception is thrown before setting new gas limits. Notice that SETGASLIMIT with an argument g ≥ 2 63 − 1 is equivalent to ACCEPT.F802 — BUYGAS (x – ), computes the amount of gas that can be bought for x nanotokens, and sets gl accordingly in the same way as SETGASLIMIT.F804 — GRAMTOGAS (x – g), computes the amount of gas that can be bought for x nanotokens. If x is negative, returns 0. If g exceeds 2 63−1, it is replaced with this value.F805 — GASTOGRAM (g – x), computes the price of g gas in nanotokens.F806–F80F — Reserved for gas-related primitives. These are yet to be released. Note: F802, F804, F805 are not implemented in Telegram TON node. In Evernode, the general gas formula is the same as specified by TON specifications. Overall, Evernode operate in compliance with the specification. For every executed primitive, the amount of gas is added to the virtual machine according to the specification formula. Gas value for every primitive is based on gr. "},{"title":"Gas initialization types​","type":1,"pageTitle":"Network Fees","url":"/arch/fee-calculation#gas-initialization-types","content":"1. Calling contract from another contract​ An internal message with a balance value is received. In this case, the following formulas are applied to determine limits: gm = MIN(account balance / gas price, global_gas_limit) gl = MIN(message value / gas price, global_gas_limit) gc = 0 gr = gc + gl  By default, gas costs are allocated to the caller contract that triggers the transaction with a message. Accepting is also available for internal contracts. If ACCEPT is not called, gas is taken from the caller contract according to the message value. In other words, the message value defines the current limit. The message value determines the starting TVM gas limit. So, to put it plain, if ACCEPT is not called, the message pays, if ACCEPT is used, additional gas can be bought by the target contract. This approach enables flexible contract design where either total gas is paid by the caller contract (but in this case it has to have enough gas at any moment of time) or the target contract also incurs costs. 2. Offchain contract call​ External messages do not carry balance values. In this case, the values are calculated according to the following formulas: gm = MIN(account balance / gas price, global_gas_limit) gl = 0 gc = MIN(gm, global_gas_credit) gr = gc + gl  As external messages have no gas value, gas is credited to execute it. Target contracts have to cover costs by calling Accept to buy gas. If a contract returns an exception before the credit is given, no gas fee applies. As the public code for node has just been released this documentation is likely to be updated. Managing Gas in Solidity Some Theory Anyone can send external message to your contract. When a message arrives, the contract initial gas limit is equal to 10,000 units of credit gas that should be bought later by the ACCEPT TVM primitive. Otherwise when credit gas falls to zero, the TVM throws the out of gas exception. The contract is supposed to spend these 10,000 units of 'free' gas to check the body of an inbound message tp make sure that it is valid and can be processed by contract successfully. The idea of credit gas allowance is that as long as it is beyond zero, any exception thrown by contract prevents all further gas charges. But once the contract accepts a message, all gas consumed by contract is converted to gas fees regardless of whether a transaction is aborted or not. ACCEPT is useful in internal messages too. When another contract sends an internal message to your contract, initial gas limit is equal to an inbound message value divided by the gas_price or global gas limit, if it is smaller. If this value is not enough to finish execution, the contract then can increase its gas limit by calling ACCEPT or SETGASLIMIT primitive. The ACCEPT primitive increases the limit to the value of its balance divided by the gas_price, and the SETGASLIMIT primitive sets the current gas limit to the value popped from the TVM stack (the value cannot be bigger than the gm limit). With the ACCEPT command a contract can choose whether gas for its execution is paid by the caller contract or by the contract itself. Implementation In EverX the ACCEPT primitive is implemented in Solidity as a private function called by public functions. Find below actual usage examples. All can be compiled using EverX Solidity compiler. Accept gas inside function To avoid gas payment when the foo function is called by another contract, we can use the following code: Remember that the caller contract should attach enough tokens to its message to cover all gas that will be spend by foo function. Accept gas inside modifier contract AcceptExample2 { uint _sum = 0; modifier AlwaysAccept() { tvm.accept(); _; } function foo(uint a, uint b) AlwaysAccept() public { _sum = a + b; } }  Important: modifier is called before arguments are deserialized from inbound message body. In the example above AlwaysAccept() will be called before a and b are decoded. "},{"title":"Logical Time and Message Delivery Guarantees","type":0,"sectionRef":"#","url":"/arch/logic-time","content":"","keywords":""},{"title":"Delivery order for two contracts​","type":1,"pageTitle":"Logical Time and Message Delivery Guarantees","url":"/arch/logic-time#delivery-order-for-two-contracts","content":"When a contract receives incoming messages, it is guaranteed that it will receive them strictly in ascending order of the LT of those messages. That is, if we send two messages from the same transaction, the one that was sent first will be received first. If two messages are sent by different transactions, then the one that was sent first will be received first (the LT of the second transaction is greater than the first).  In this case, too, Int 1 will come first, but only if Ext 1 happens before Ext 2 (if you send two external messages at the same time or close in time, there is no guarantee regarding the order in which they will be added into the block).   "},{"title":"Complicated cases​","type":1,"pageTitle":"Logical Time and Message Delivery Guarantees","url":"/arch/logic-time#complicated-cases","content":"note There is no consensus on whether or not you can count on this, so USE ONLY IF YOU UNDERSTAND WHAT YOU ARE DOING 100%, otherwise you should only use delivery order guarantees for two contracts. (This may change after new consensus) If we send two messages from contract A, and message 1 is sent before message 2, then message 1 will arrive earlier than any other message generated by message 2, as in the example below, Int 1 will always arrive before Int 3.  If you have more than 3 contracts, then the order of delivery is mostly undefined. For all other cases, you definitely shouldn’t count on this if you don’t consider yourself a super expert in LT and node operation. Below I will demonstrate several cases where the delivery order is not defined.  Here the order is not defined, G can receive a message from any of the chains first.  This is a more complicated example. If Ext 1 happens before Ext 2, but they occur close to each other in time, then 1 arrives before 3 and 4, but we don’t know in which order C will receive messages 3 and 4.   "},{"title":"Gas Calculation for Processing","type":0,"sectionRef":"#","url":"/arch/managing-gas","content":"","keywords":""},{"title":"Gas calculation basics​","type":1,"pageTitle":"Gas Calculation for Processing","url":"/arch/managing-gas#gas-calculation-basics","content":""},{"title":"Specification Overview​","type":1,"pageTitle":"Gas Calculation for Processing","url":"/arch/managing-gas#specification-overview","content":"The entire state of TVM consists of the five components: StackControl registersCurrent continuationCurrent codepageGas limits Collectively these are called SCCCG. Check out section 1.4 of the TVM specification. The Gas component limits gas usage and сontains four signed 64-bit integers: the remaining gas: grthe current gas limit: glthe maximal gas limit: gmthe gas credit: gc The following is always true: 0≤gl≤gm,gc≥0,andgr≤gl+gc0 ≤ gl ≤ gm, gc ≥ 0, and gr ≤ gl + gc0≤gl≤gm,gc≥0,andgr≤gl+gc gc is initialized by zero for internal messages, gr is initialized by gl + gc and gradually decreases, as the TVM runs. When gr becomes negative or if contract terminates with gc &gt; 0, an out of gas exception is triggered. "},{"title":"Gas prices​","type":1,"pageTitle":"Gas Calculation for Processing","url":"/arch/managing-gas#gas-prices","content":"As stated in A.1 of the TVM specification. According to the original TON, for most primitives gas is calculated according to the following formula: Pb:=10+bPb := 10 + bPb:=10+b where b is the instruction length in bits. The same is true for EverX implementation. For example: the gas required for A0 (ADD) instruction is 10 + 8 = 18 gas, while the gas for A6cc (ADDCONST cc) instruction is 10 + 16 = 26 gas. For some instructions this rule does not apply. TVM specification lists either total gas prices, or prices in addition to the basic Pb for them explicitly. Instruction list with additional information may be obtained in A.2 through A.13 of the TVM specification. Apart from integer constants, the following expressions may appear: The total price of loading cells. Currently it is 100 gas units per cell. Reloading a cell again now costs 25 gas units.The total price of creating new Cells from Builders. Currently it is 500 gas units.Exception throwing. 50 gas units per exception.Exiting the block costs 5 gas units per implicit RET. Jumping to the first link costs 10 gas units - implicit JUMP.Moving to a new continuation with transferring parameters costs gas if there are more then 32 parameters. It costs N-32 gas, where N is the number of parameters.Tuple gas price. 1 gas unit for every tuple element. Note: that the most expensive operations are dictionary read/write operations. Dictionaries are stored in the form of trees of cells, where each cell can only be linked to four others. As result, these trees can grow quite large, depending on the data that needs to be stored. To read data in any cell, all its parent cells need to be read first, at the price of 100 gas per cell, and to write data in a cell, similarly all its parent cells need to be (re)created at the price of 500 gas per cell. "},{"title":"Global gas limits​","type":1,"pageTitle":"Gas Calculation for Processing","url":"/arch/managing-gas#global-gas-limits","content":"Global gas limits are values stored in the masterchain configuration contract. Global values are standard and do not change at contract deployment. Only validator consensus can modify them. The values currently used can always be reviewed on ever.live in the latest key block details (example FIXME broken link). p20 config parameter values are used for masterchain and p21 values are used for workchain. "},{"title":"Gas-related TVM primitives​","type":1,"pageTitle":"Gas Calculation for Processing","url":"/arch/managing-gas#gas-related-tvm-primitives","content":"These is the list of official TVM primitives used for gas-related operations: F800 — ACCEPT, sets current gas limit gl to its maximal allowed value gm, and resets the gas credit gc to zero, decreasing the value of gr by gc in the process. In other words, the current smart contract agrees to buy some gas to finish the current transaction. This action is required to process external messages, which bring no value (hence no gas) with themselves.F801 — SETGASLIMIT (g – ), sets current gas limit gl to the minimum of g and gm, and resets the gas credit gc to zero. If the gas consumed so far (including the present instruction) exceeds the resulting value of gl, an (unhandled) out of gas exception is thrown before setting new gas limits. Notice that SETGASLIMIT with an argument g ≥ 2 63 − 1 is equivalent to ACCEPT.F802 — BUYGAS (x – ), computes the amount of gas that can be bought for x nanotokens, and sets gl accordingly in the same way as SETGASLIMIT.F804 — GRAMTOGAS (x – g), computes the amount of gas that can be bought for x nanotokens. If x is negative, returns 0. If g exceeds 2 63−1, it is replaced with this value.F805 — GASTOGRAM (g – x), computes the price of g gas in nanotokens.F806–F80F — Reserved for gas-related primitives. These are yet to be released. Note: F802, F804, F805 are not implemented in Telegram TON node. In Evernode, the general gas formula is the same as specified by TON specifications. Overall, Evernode operate in compliance with the specification. For every executed primitive, the amount of gas is added to the virtual machine according to the specification formula. Gas value for every primitive is based on gr. "},{"title":"Gas initialization types​","type":1,"pageTitle":"Gas Calculation for Processing","url":"/arch/managing-gas#gas-initialization-types","content":""},{"title":"1. Calling contract from another contract​","type":1,"pageTitle":"Gas Calculation for Processing","url":"/arch/managing-gas#1-calling-contract-from-another-contract","content":"An internal message with a balance value is received. In this case, the following formulas are applied to determine limits: gm = MIN(account balance / gas price, global_gas_limit) gl = MIN(message value / gas price, global_gas_limit) gc = 0 gr = gc + gl  By default, gas costs are allocated to the caller contract that triggers the transaction with a message. Accepting is also available for internal contracts. If ACCEPT is not called, gas is taken from the caller contract according to the message value. In other words, the message value defines the current limit. The message value determines the starting TVM gas limit. So, to put it plain, if ACCEPT is not called, the message pays, if ACCEPT is used, additional gas can be bought by the target contract. This approach enables flexible contract design where either total gas is paid by the caller contract (but in this case it has to have enough gas at any moment of time) or the target contract also incurs costs. "},{"title":"2. Offchain contract call​","type":1,"pageTitle":"Gas Calculation for Processing","url":"/arch/managing-gas#2-offchain-contract-call","content":"External messages do not carry balance values. In this case, the values are calculated according to the following formulas: gm = MIN(account balance / gas price, global_gas_limit) gl = 0 gc = MIN(gm, global_gas_credit) gr = gc + gl  As external messages have no gas value, gas is credited to execute it. Target contracts have to cover costs by calling Accept to buy gas. If a contract returns an exception before the credit is given, no gas fee applies. As the public code for node has just been released this documentation is likely to be updated. Managing Gas in Solidity Some Theory Anyone can send external message to your contract. When a message arrives, the contract initial gas limit is equal to 10,000 units of credit gas that should be bought later by the ACCEPT TVM primitive. Otherwise when credit gas falls to zero, the TVM throws the out of gas exception. The contract is supposed to spend these 10,000 units of 'free' gas to check the body of an inbound message tp make sure that it is valid and can be processed by contract successfully. The idea of credit gas allowance is that as long as it is beyond zero, any exception thrown by contract prevents all further gas charges. But once the contract accepts a message, all gas consumed by contract is converted to gas fees regardless of whether a transaction is aborted or not. ACCEPT is useful in internal messages too. When another contract sends an internal message to your contract, initial gas limit is equal to an inbound message value divided by the gas_price or global gas limit, if it is smaller. If this value is not enough to finish execution, the contract then can increase its gas limit by calling ACCEPT or SETGASLIMIT primitive. The ACCEPT primitive increases the limit to the value of its balance divided by the gas_price, and the SETGASLIMIT primitive sets the current gas limit to the value popped from the TVM stack (the value cannot be bigger than the gm limit). With the ACCEPT command a contract can choose whether gas for its execution is paid by the caller contract or by the contract itself. Implementation In EverX the ACCEPT primitive is implemented in Solidity as a private function called by public functions. Find below actual usage examples. All can be compiled using EverX Solidity compiler. Accept gas inside function To avoid gas payment when the foo function is called by another contract, we can use the following code: Remember that the caller contract should attach enough tokens to its message to cover all gas that will be spend by foo function. Accept gas inside modifier contract AcceptExample2 { uint _sum = 0; modifier AlwaysAccept() { tvm.accept(); _; } function foo(uint a, uint b) AlwaysAccept() public { _sum = a + b; } }  Important: modifier is called before arguments are deserialized from inbound message body. In the example above AlwaysAccept() will be called before a and b are decoded. "},{"title":"Message","type":0,"sectionRef":"#","url":"/arch/message","content":"","keywords":""},{"title":"Message Header​","type":1,"pageTitle":"Message","url":"/arch/message#message-header","content":"Any message has a message header: a data-structure defining, among other things, the message type and source and destination addresses. The message header defines its type. It is described by the following enumeration: pub enum CommonMsgInfo { IntMsgInfo(InternalMessageHeader), ExtInMsgInfo(ExternalInboundMessageHeader), ExtOutMsgInfo(ExtOutMessageHeader), }  "},{"title":"Internal Message​","type":1,"pageTitle":"Message","url":"/arch/message#internal-message","content":"Within Everscale blockchain, smart-contracts communicate with each other by exchanging messages. Messages sent by smart-contracts are called internal. They are opposed to external messages that are sent by off-chain applications to smart-contracts. The message header of an internal message is defined as follows: pub struct InternalMessageHeader { pub ihr_disabled: bool, pub bounce: bool, pub bounced: bool, pub src: MsgAddressIntOrNone, pub dst: MsgAddressInt, pub value: CurrencyCollection, pub ihr_fee: Grams, pub fwd_fee: Grams, pub created_lt: u64, pub created_at: UnixTime32, }  InternalMessageHeader fields​ Field\tDescriptionihr_disabled\tIHR routing protocol disabled, always true bounce\tShould the answer message be generated in case of an error bounced\tIs this message was auto-generated by error handling src\tMessage source address dst\tMessage destination address value\tAmount of coins attached to the message ihr_fee\tIHR fee amount, always 0 fwd_fee\tMessage delivery fee amount created_lt\tMessage creation logic time created_at\tMessage creation time in Epoch Some clarifications: bounced flag is set when the message itself was auto-generated as a result of an error. If the message with bounced flag leads to an error itself, the next bounced message will not be generated.value is measured in Nano Evers (10−910^{-9}10−9)reated_lt is a monotonically increasing counter, thanks to this field, each new generated message is unique, even if the message payload is the same. The message creation logic time is also used to guarantee order of delivery. We do not dive deep into this question, because it is protocol-level details. "},{"title":"External Message​","type":1,"pageTitle":"Message","url":"/arch/message#external-message","content":"External messages are created outside of the blockchain and get sent through specially distinguished validator nodes called DApp Servers2. External message header is defined as follows: pub struct ExternalInboundMessageHeader { pub src: MsgAddressExt, pub dst: MsgAddressInt, pub import_fee: Grams, }  Fields src and dst are source and destination addresses.Field import_fee should have been the value paid to the validator for processing an external message. But in the current node, this field is not used. Hence, the fee is not paid. We reported this issue to the developers.The source address for an external message is always set to AddrNone. pub enum MsgAddressExt { AddrNone, AddrExtern(MsgAddrExt), }  The second variant AddrExtern is not supported currently. "},{"title":"Events​","type":1,"pageTitle":"Message","url":"/arch/message#events","content":"Event can be considered as a log record. It is used to signal external observers of reaching some significant state in a smart-contract. Usually, observers are external non-blockchain applications that constantly monitor blockchain state3. Other smart-contracts are not able to catch events. pub struct ExtOutMessageHeader { pub src: MsgAddressIntOrNone, pub dst: MsgAddressExt, pub created_lt: u64, pub created_at: UnixTime32, }  pub enum MsgAddressIntOrNone { None, Some(MsgAddressInt) }  Transaction Executor automatically assigns the source address src to be equal to the smart-contract address emitting the event.The destination address dst may contain any identifier. It is included for easier integration with off-chain applications, i.e. applications can monitor emitted events based on their destination address, and consume only those events destined to their custom identifier.Fields created_lt, created_at defines the logical creation time and epoch creation time. "},{"title":"Reference​","type":1,"pageTitle":"Message","url":"/arch/message#reference","content":"In the current protocol implementation, not all validator nodes process external messages. This is subject to change in the future protocol versions↩For example, by sending GraphQL requests to the DApp-server↩ "},{"title":"Multithreading and Message Queues","type":0,"sectionRef":"#","url":"/arch/multithreading","content":"","keywords":""},{"title":"How the blockchain works on the block and queue level​","type":1,"pageTitle":"Multithreading and Message Queues","url":"/arch/multithreading#how-the-blockchain-works-on-the-block-and-queue-level","content":"This note is just for a general understanding of how the blockchain works, it’s not 100% accurate, we are waiting for a description from the writers of the node. This may change after a new consensus. There is a workchain -1, this is the master chain, it is validated by the validators with the largest stake. Contracts can be deployed in the -1 workchain, but it is more expensive, and it was made mainly for governorship. (Probably in the future there will be no user contracts) There is a workchain 0, where contracts are mostly located. More workchains will be launched in the future. Workchains are further divided into Processing threads. There is a workchain parameter that indicates the minimum number of processing threads, and currently it is 16 for a 0 workchain. Thread processing is an interesting concept. In ES, only computation is shared between the validators of the same workchain, but they all have the same storage. Let’s look at what that means and how it works. For example, we have 160 validators for the 0 workchain. They are randomly divided into 16 groups of 10 validators, and each gets its own Processing thread. All workchain contracts are also divided into 16 groups, simply by address ranges. (0.00 - 0:08, 0:08 - 0.18, etc.). Each group of validators executes transactions only for their group of smart contracts, and releases blocks of their processing thread. But at the same time, they are constantly downloading blocks of other processing threads in order to see their outgoing and incoming message queues. At the same time, blocks are not a list of transactions that need to be rolled up, but a list of incoming messages + a state delta. So, when you download a block of another processing thread, you do not have to do computation in order to update your state. You’re just rolling state changes. How roughly works: The Masterchain generates block 1.All threads download the last master block.Threads create their own block and register it in the master block.The masterchain generates block 2, which contains the hashes of all blocks of threads that have registered in it.All threads download masterblock 2.All threads look at the hashes of the registered blocks of other threads, and download them all.All threads generate a block.This process gets repeated. Message delivery guarantees also work in this way. When you create a message, it is placed on that thread’s outgoing queue: Thread A generates a message for the contract that is in thread B, and creates a block with a new outgoing message in the outgoing queue.Thread A is registered in the master block.The masterchain generates a block.Thread B downloads the master block, and downloads the block of thread A registered there.Thread B sees the message in thread A and imports it into its inbound queue. (When a message is imported, it is immediately executed (transaction starts) If there is not enough gas for a transaction in the current block, then the message is simply not imported, and waits for its turn in another block. At the same time, there is a message import order, so that validators will not be able to ignore it forever).Thread B creates a block with a message in the incoming queue, and registers with the master.Thread A downloads the block in which it sees its message in thread B’s incoming queue and removes the message from its outgoing queue since it was delivered successfully.Generally, thread A generates a block, then registers it in the master block. Then thread B downloads it, sees that thread A has removed it from its outgoing queue, and deletes it from its incoming one. In fact, sharding in this blockchain is the sharding of computational resources. And the data is the same for everyone, with the expectation that all validators have gigabit channels, and we rest only on computation. If some processing thread is heavily loaded with the last N blocks, then it will split into two, and new processing threads can also split in turn. Then when the load drops, they all merge. "},{"title":"ADNL","type":0,"sectionRef":"#","url":"/arch/networking/adnl","content":"","keywords":""},{"title":"Address​","type":1,"pageTitle":"ADNL","url":"/arch/networking/adnl#address","content":"An ADNL address is equal to a 256-bit ECC public key. In turn, this public key can be randomly generated. This way, there is the possibility to create as many different network identities as the node requires. Still, there is the need to know the corresponding private key to be able to receive and decrypt messages intended for the recipient's address. Practically, the ADNL address is not the public key itself. It is a 256-bit SHA 256 hash of a serialized TL-object that can describe several types of public keys and addresses depending on its constructor. Tip A TCP-like stream protocol can be built over ADNL "},{"title":"Neighbor tables​","type":1,"pageTitle":"ADNL","url":"/arch/networking/adnl#neighbor-tables","content":"Practically, an Everscle ADNL node will have a so-called “neighbor table”. It includes the information about other known nodes: abstract addresses, public keys, IP addresses and UDP ports. With time, it will constantly extend this table using the information accumulated from these known nodes. This new information can be in the form of answers to special queries or sometimes the removal of obsolete records. "},{"title":"Peer Identity​","type":1,"pageTitle":"ADNL","url":"/arch/networking/adnl#peer-identity","content":"Each peer must have at least one identity. Although, there is the possibility to use multiple. Each identity is a key pair, which is used to perform the Diffie-Hellman between peers. An abstract network address is derived from the public key as follows: address = SHA-256(type_id || public_key). Note that type_id must be serialized as little-endian uint32 "},{"title":"Client-server protocol​","type":1,"pageTitle":"ADNL","url":"/arch/networking/adnl#client-server-protocol","content":"The client connects to the server via TCP and sends an ADNL handshake packet. It contains a server abstract address, a client public key and encrypted AES-CTR session parameters - determined by the client. "},{"title":"Initiating communications - Handshakes​","type":1,"pageTitle":"ADNL","url":"/arch/networking/adnl#initiating-communications---handshakes","content":"Initially, the client must perform a key agreement protocol. For instance, x25519 with the help of both the private key and server public key - considering server key type_id. Accordingly, the client will get a secret, which is used to encrypt session keys in upcoming steps. Then, the client has to generate AES-CTR session parameters, a 16-byte nonce and 32-byte key, both for TX (client-&gt;server) and RX (server-&gt;client) directions and serialize it into a 160-byte buffer as follows: Parameter\tSizerx_key\t32 bytes tx_key\t32 bytes rx_nonce\t16 bytes tx_nonce\t16 bytes padding\t64 bytes "},{"title":"Padding​","type":1,"pageTitle":"ADNL","url":"/arch/networking/adnl#padding","content":"It is not used by server implementations. However, It is recommended to fill the whole 160-byte buffer with random bytes. If not, an attacker may conduct a MitM assault via compromised AES-CTR session parameters. The next step is to encrypt session parameters using secret via the key agreement protocol. For this, AES-256 must be initialized in CTR mode with a 128-bit big-endian counter with the help of a key and nonce pair which is computed as in the example below: hash = SHA-256(aes_params) key = secret[0..16] || hash[16..32] nonce = hash[0..4] || secret[20..32]  Tip aes_params is a 160-byte buffer After the encryption of aes_params, noted as E(aes_params), AES should be removed because it is not needed anymore. Now we are ready to serialize all the information to the 256-byte handshake package and send it to the server: Parameter\tSize\tNotesreceiver_address\t32 bytes\tServer peer identity as described in the corresponding section sender_public\t32 bytes\tClient public key SHA-256(aes_params)\t32 bytes\tIntegrity proof of session parameters E(aes_params)\t160 bytes\tEncrypted session parameters The server decrypts session parameters using a secret, derived from the key agreement protocol, in the same way as the client. Then the server conducts the checks outlined below to confirm protocol security properties: The server must have the private key for receiver_address. Without it, there is no other way to perform the key agreement protocol.SHA-256(aes_params) == SHA-256(D(E(aes_params))). In case it is not so, the key agreement protocol failed, and the secret is not the same on both sides. In case one of the checks fails, the server will in a instant stop the connection. On the other hand, in case both checks pass, the server will issue an empty datagram to the client in order to prove that it owns the private key for the specified receiver_address. "},{"title":"Datagram​","type":1,"pageTitle":"ADNL","url":"/arch/networking/adnl#datagram","content":"Both the client and server must initialize two AES-CTR instances each, for TX and RX directions. AES-256 must be used in CTR mode with a 128-bit big-endian counter. Each AES instance is initialized using a key and nonce pair belonging to it, which can be taken from aes_params in the handshake. To send a datagram, a peer must build the structure shown below. Afterwards, it must be encrypted and sent to the receiver: Parameter\tSize\tNoteslength\t4 bytes (LE)\tLength of the whole datagram, excluding length field nonce\t32 bytes\tRandom value buffer\tlength - 64 bytes\tActual data to be sent to the other side hash\t32 bytes\tSHA-256(nonce || buffer) to ensure integrity The structure must be encrypted with the help of the AES instance (TX for client -&gt; server, RX for server -&gt; client). The receiver must fetch the first 4 bytes, decrypt them into the length field and read exactly the length of the bytes to get the full datagram. The receiver may start to decrypt and process the buffer earlier. However, it must consider that it may be corrupted, even unintentionally. The datagram hash must be checked to ensure the integrity of the buffer. In the event of failure, no new datagrams can be issued and the connection must be abandoned. The first datagram in the session always goes from the server to the client. It happens after a handshake package is accepted by the server and it's actual buffer is empty. In the event of failure, the client must decrypt it and drop the connection with the server. The reason is that the server has not followed the protocol accordingly. Correspondingly, actual session keys differ on the server and client side. "},{"title":"Security considerations​","type":1,"pageTitle":"ADNL","url":"/arch/networking/adnl#security-considerations","content":""},{"title":"Handshake padding​","type":1,"pageTitle":"ADNL","url":"/arch/networking/adnl#handshake-padding","content":"aes_params integrity is protected by a SHA-256 hash. The confidentiality, in turn, is protected by the key derived from the secret parameter. Possibly, it works this way due to initial TON developers thinking of migrating from AES-CTR at some point. To do this, the specification may be extended to include a special magic value in aes_params, which will signal that the peer is ready to use the updated primitives. The response to such a handshake may be decrypted twice: with new and old schemes. This is needed in order to to clarify which scheme the other peer is actually using. "},{"title":"Session parameters encryption key derivation process​","type":1,"pageTitle":"ADNL","url":"/arch/networking/adnl#session-parameters-encryption-key-derivation-process","content":"The encryption key will be static in case it is derived only from the secret parameter. This is due to the fact that the secret is static. To derive a new encryption key for each session, SHA-256(aes_params) is used. It is random if aes_params is random. It should be noted that the current key derivation algorithm linking different subarrays is considered poor. "},{"title":"Datagram nonce​","type":1,"pageTitle":"ADNL","url":"/arch/networking/adnl#datagram-nonce","content":"The nonce field necessity in the datagram is not obvious. Any two ciphertexts would be distinguished due to the session-bounded keys for AES and encryption in CTR mode even in case of its absence. With this in mind, however, the attack described below can be realized if there isn’t a nonce field or it is poor. CTR encryption turns block ciphers, such as AES, into stream ciphers to make a bit-flipping attack possible. In case the attacker is in possession of the plaintext which belongs to an encrypted datagram, he can easily obtain a pure keystream. Then, XOR it with his own plaintext and replace the message which was sent by a peer. We remember that buffer integrity is protected by a SHA-256 hash. However, an attacker can replace it too. This is because knowing a full plaintext means knowing its hash. The nonce field is there to prevent such an attack. No attacker can replace the SHA-256 without knowing the nonce. "},{"title":"DHT - Distributed Hash Table","type":0,"sectionRef":"#","url":"/arch/networking/dht","content":"","keywords":""},{"title":"DHT nodes​","type":1,"pageTitle":"DHT - Distributed Hash Table","url":"/arch/networking/dht#dht-nodes","content":"Each DHT node has a 256-bit DHT address. Contrary to ADNL addresses, a DHT address should not change often. In case it is changed too often, other nodes would not be able to locate the keys they are searching for. It is expected that the value of key K will be stored on S Kademlia-nearest nodes to K. Kademlia distance = 256-bit key XOR 256-bit DHT node address. S is a small parameter, for example S = 7, which is required in order to improve the reliability of DHT. If we were to keep the key only on one node. The nearest one to K. The value of the respective key would be lost if that single node goes offline. "},{"title":"Kademlia routing table​","type":1,"pageTitle":"DHT - Distributed Hash Table","url":"/arch/networking/dht#kademlia-routing-table","content":"Each node in DHT usually keeps a Kademlia routing table. It is comprised of 256 buckets (from 0 to 255). The i-th bucket incorporates the information about some known nodes, a fixed number of the “best” nodes and maybe some extra candidates that find themselves at a Kademlia distance from 2^i to 2^(i+1) − 1 from the node’s address a. The information includes: DHT addresses, IP addresses and UDP ports. Also, there is some other information such as the time and the delay of the last ping. When a Kademlia node learns about any other Kademlia node as a result of some query, it places it into a suitable bucket of its routing table. First, as a candidate, then, if some of the “best” nodes in that bucket fail, for instance, do not respond to ping queries for a long time, they can be replaced by some of these candidates. In this way, the Kademlia routing table stays populated. "},{"title":"Key-value pairs​","type":1,"pageTitle":"DHT - Distributed Hash Table","url":"/arch/networking/dht#key-value-pairs","content":"Everscale DHT allows key-value pairs addition and editing. It should be mentioned that updating rules can vary. In some instances, it is just the replacement of the old value with the new one. It is applicable in case the new value is signed by the owner. The signature, in turn, must be kept as part of the value. It is to be checked later by other nodes after they obtain the value of the key. In other instances, the old value somehow affects the new value. For instance, it can contain a sequence number and the old value is overwritten only if the new sequence number is larger. This is done in order to prevent replay attacks. The purpose of Everscale DHT is not only for storing IP Addresses of ADNL nodes. Besides this, it has many other applications, such as, the storage of: Lists of addresses of nodes included in an overlay subnetworkADNL Addresses of Everscale services ADNL addresses of accounts of the Everscale blockchain "},{"title":"Overlay","type":0,"sectionRef":"#","url":"/arch/networking/overlay","content":"","keywords":""},{"title":"ADNL in comparison with Overlay networks​","type":1,"pageTitle":"Overlay","url":"/arch/networking/overlay#adnl-in-comparison-with-overlay-networks","content":"Everscale overlay networks usually do not send datagrams to other arbitrary nodes as happens in ADNL. Alternatively, there are some semi-permanent links established between certain nodes (called neighbors) with respect to the overlay network. The messages are usually forwarded along these links. For instance, from a node to one of its neighbors. Tip Each overlay subnetwork has a 256-bit network identifier. Usually, it is equal to a SHA256 of the description of the overlay network—a TL-serialized object Overlay subnetworks work according to a special gossip protocol. "},{"title":"Transaction executor","type":0,"sectionRef":"#","url":"/arch/executor","content":"","keywords":""},{"title":"Introduction​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#introduction","content":"Transaction Executor is a crucial part of Everscale blockchain node. It applies incoming messages to accounts, sealing the end result of this operation into a block in the form of a transaction object. The Transaction Executor algorithms determine several critical aspects of smart-contracts behavior, such as: How a balance of an account is affected after the message gets processedWhat outbound messages will be generated as a resultShould the account be frozen or deleted?What fees should be charged from the accounts balance To be able to rigorously reason about a smart-contract behavior, it is important to construct the accurate model of this module, explain the main concepts, define its properties. In other words, make the groundwork for you, the reader, to foster the integration of this logic into the reasoning framework of your choice. In the current work, we made the best-effort attempt to write such specification. "},{"title":"Document Structure​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#document-structure","content":"The document consists of two logical parts, intermixed with each other: the explanation part and the specification part. The explanation part is done by providing extensive comments for data structures used through-out the Transaction Executor. The data structures are presented as Rust code snippets, taken from the original Node code. Sometimes, we intentionally omit details that are not relevant to the Transaction Executor, requiring much wider context to be explained. The specification part is presented in two flavors. When the precision is required, we describe the behavior by providing the pseudo-code implementing some algorithm. For more general properties, we formulate them in a form of semi-formal statements about the system behavior. By comparison to the program implementation, the specification pseudo-code overapproximates the implementation by throwing away non-relevant parts of the logic, for example: sophisticated error handling, non-interesting parts of the state being removed, introducing reasonable assumptions that greatly simplifies the logic, etc. In other words, the pseudo-code shows how the system behaves for its significant parts, putting away everything else. "},{"title":"Everscale Platform Architecture​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#everscale-platform-architecture","content":"The main actors of the EverScale blockchain are smart-contracts. Smart-contracts are programs that operate user valuable assets on their behalf. Valuable assets are usually cryptocurrency tokens or some digital goods, like NFTs. Smart-contract execution is triggered by a message sent from some other party. If the message was delivered from the outside world (i.e. from the user program), it is said to be external. Otherwise, the message is considered internal. Smart-contracts may also generate log records called events. Those records are used as information signals for an external observers. They foster communication between smart-contracts and off-chain programs. The platform overall architecture is depicted​  "},{"title":"Platform Implementation​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#platform-implementation","content":"EverScale blockchain is a database operated by a peer-to-peer network of computing nodes. The database store users code and data in a form of programmable units called smart-contracts. Smart-contacts may communicate with other contracts and outside world by sending messages. The computing node is called blockchain node in our context. Among other things, blockchain nodes are responsible for storing the smart-contract state, delivering messages from users and smart-contracts, executing the smart-contacts code when needed. Transaction Executor module is a part of the blockchain node responsible for proper execution of a smart-contract code upon receiving a message addressed to that smart-contract. The result of this execution is an updated smart-contract state and the transaction record that gets sealed into the block candidate. We now go into details on the internals of this module. "},{"title":"Transaction Executor Module​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#transaction-executor-module","content":"In this section, we go into the technical details of Transaction Executor module. The source code of the module is available here. "},{"title":"Remark​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#remark","content":"In our opinion, the name of this module was chosen quite unfortunate. In its current form, it feels like the object being executed is a transaction. This is not true. Transaction is an outcome of executing a message on a smart-contract state using the Transaction Executor logic. Hence, it is the message that is being executed, not the transaction. Nevertheless, we stick with the original name not to confuse developers too much. "},{"title":"Inputs and Outputs​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#inputs-and-outputs","content":"The principal architecture of the module is depicted​  We now describe each input/output entity in detail, together with the logic of the computation. "},{"title":"Multichain Architecture​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#multichain-architecture","content":"Everscale has a native support for multiple blockchains running in parallel. Each blockchain might be established by introducing a separate chain called workchain. Each workchain has a unique integer identifier in a range -127 ... 127, the values -1 and 0 are already taken. Smart-contracts from different workchains may interact with each other by message passing. At the moment, the system implements only two workchains — Masterchain (id -1) and Workchain (id 0). caution Currently, the creation of new workchains is not supported. "},{"title":"Multicurrency payments​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#multicurrency-payments","content":"The native coin of Everscale blockchain is called EVER. However, Everscale has an ability to work with other types of coins. While system payments like gas and storage fees are made only in Evers, the other value transfers may contain coins of other currencies. This contrasts with most of other blockchains where there is only a single native cryptocurrency, and other currencies may be made only using artificial token smart-contracts. Currently, this feature is not used widely. caution In this document, we limit our specification effort only for the case of a single currency — Evers. This choice significantly simplifies the business logic of the execution handlers. "},{"title":"Hashing Algorithm​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#hashing-algorithm","content":"Transaction Executor uses hashing in several places to compactly store data structures fingerprints. It is done in two steps. First, the data structure gets converted into a tree-like form. Then, a special hashing algorithm is applied to that tree. The basic hash function used is SHA256 from Sha2 Rust package. The exact hashing algorithm, as well as tree-like representation is not interesting for our purposes, so we do not consider it here. For details, check this. "},{"title":"Parameters​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#parameters","content":"Besides, incoming message and account, Transaction Executor has to have some external information regarding the current blockchain and non-blockchain state to support the TVM capabilities. For example, it has to know the current time to provide it for smart-contracts. It has to have some random seed to support the random number generator facility. All of this is passed using the ExecuteParams structure. pub struct ExecuteParams { pub state_libs: HashmapE, pub block_unixtime: u32, pub block_lt: u64, pub last_tr_lt: Arc&lt;AtomicU64&gt;, pub seed_block: UInt256, pub debug: bool }  ExecuteParams fields​ Field\tDescriptionstate_libs\tA set of references to external libraries. This mechanism is not supported currently block_unixtime\tCurrent time in Unix Epoch block_lt\tBlock logical time last_tr_lt\tThe last transaction logical time seed_block\tRandom number generator seed debug\tShould the TVM output debug information during its execution "},{"title":"Transaction​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#transaction","content":"Transaction is an object that describes the successful execution of a message on the account. If a message execution results in an error, such execution does not lead to a transaction creation. After transaction is created, it gets sealed into the block. And after the block is negotiated with fellow validators, it find its way into the Masterchain. From that point, it stays there forever1. Transaction is an output of the Transaction Executor, so we have to examine it more closely. pub struct Transaction { pub account_addr: AccountId, pub lt: u64, pub prev_trans_hash: UInt256, pub prev_trans_lt: u64, pub now: u32, pub outmsg_cnt: i16, pub orig_status: AccountStatus, pub end_status: AccountStatus, pub in_msg: Option&lt;ChildCell&lt;Message&gt;&gt;, pub out_msgs: OutMessages, pub total_fees: CurrencyCollection, pub state_update: ChildCell&lt;HashUpdate&gt;, pub description: ChildCell&lt;TransactionDescr&gt;, }  ExecuteParams fields​ Field\tDescriptionaccount_addr\tAccount identifier lt\tTransaction creation logical time prev_trans_hash\tPrevious transaction hash value prev_trans_lt\tPrevious transaction logical time now\tCurrent time in Unix Epoch outmsg_cnt\tNumber of generated outbound messages orig_status\tAccount state upon receiving the message end_status\tAccount state after executing the message in_msg\tProcessed message out_msgs\tSet of generated outbound messages total_fees\tTotal fee amount for all the processing state_update\tHash footprint of the account state change description\tTransaction Descriptor "},{"title":"Transaction Executor​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#transaction-executor-1","content":"Transaction Executor module is responsible for applying the incoming message to the destination account, using the supplied parameters. In case of success, Transaction Executor outputs the newly created transaction and the updated account. The main entry point is the function execute_with_libs_and_params() within transaction_executor.rs module. Other entry points were either flagged as deprecated, or reduce to calling this function after some minor parameters mangling. The message execution is being done in several phases. A phase is a logical step during the message execution. It may finish successfully or with an error. In case of an error, the next phase may not be executed. Phases are done mostly in a fixed order, but there are some nuances. Let us warn you that the phase is not just an implementation detail of the Transaction Executor internals that may be easily discarded. Message execution phases are a part of EverScale smart-contracts programming architecture. It is assumed that you have a good grasp on it, to be able to do proper troubleshooting in case something is not working as expected. Without this knowledge, it may be challenging to debug the problem. This document aims to support programmers in their strive for this knowledge. Transaction executor message processing general scheme​  Credit — Message coins are put on the balance agent Storage.Storage — Storage fee is deducted from the balance agent Computer.Computer — The contract bytecode gets executed inside TVM with proper parameters. Contract generate Actions.Action — Generated actions get executed by the action handler, producing outbound messages.Bounce — Bounce phase is executed if failure happened on compute phase or action phase. It sends back the reply with coins, mostly.Out messages — Queue get propagated to other validators. "},{"title":"Transaction Executor Types​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#transaction-executor-types","content":"There are several type of messages in EverScale. Besides already mentioned ordinary messages, there are also a special type of messages that is a part of a wider protocol. For example, TickTock messages, SplitMerge messages, etc. For each type of messages, there exists a separate Transaction Executor. In this work, we consider only the OrdinaryTransactionExecutor, that is defined in ordinary_transaction.rs. "},{"title":"Main Entry Point​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#main-entry-point","content":"fn execute_with_libs_and_params( &amp;self, in_msg: Option&lt;&amp;Message&gt;, account_root: &amp;mut Cell, params: ExecuteParams, ) -&gt; Result&lt;Transaction&gt;  ExecuteParams fields​ Field\tDescriptionself\tReference to the object calling the function in_msg\tIncoming message messages account_root\tAccount record serialized in a form of Cells account params\tTransaction Executor parameters parameters As a result, the function returns either Ok(Transaction) object or Err value. Please note that besides returning the Transaction, there is a side-effect of mutating the account_root object. This justifies our generalization that it returns two objects: the transaction and the updated account record. "},{"title":"BlockchainConfig parameters​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#blockchainconfig-parameters","content":"Besides ExecuteParams, the Transaction Executor relies on BlockchainConfig parameters. They are passed implicitly, at the Transaction Executor creation time. BlockchainConfig is a set of globally defined parameters regulating different nuances of blockchain work. For example, prices for smart-contract execution, storage and a set of system contract addresses. The latter is needed to let Transaction Executor apply special logic for them. Those parameters are global to the network, and negotiated between all the validators in advance. They are stored in a special system smart-contract, in the Masterchain. pub struct BlockchainConfig { gas_prices_mc: GasLimitsPrices, gas_prices_wc: GasLimitsPrices, fwd_prices_mc: MsgForwardPrices, fwd_prices_wc: MsgForwardPrices, storage_prices: AccStoragePrices, special_contracts: FundamentalSmcAddresses, capabilities: u64, global_version: u32, raw_config: ConfigParams, }  Field\tDescriptiongas_prices_mc\tFees for Masterchain smart-contract execution gas_prices_wc\tFees for Workchain smart-contract execution fwd_prices_mc\tFees for delivering messages in Masterchain fwd_prices_wc\tFees for delivering messages in Workchain storage_prices\tFees for information storage special_contracts\tSet of system smart-contract addresses capabilities\tSet of operation-mode flags global_version\tMinimum blocks version number allowed to be included in the chain raw_config\tDictionary with blockchain settings "},{"title":"Code Execution Fee​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#code-execution-fee","content":"As in most of blockchain, in Everscale the execution of a smart-contract costs money. Usually, this fee is deduced from the coins attached to the message initiating the call, but there are nuances. The fee amount to be deducted from the balance is calculated based on values found in gas_price_mc, gas_price_wc structures. They are defined as follows: pub struct GasLimitsPrices { pub gas_price: u64, pub gas_limit: u64, pub special_gas_limit: u64, pub gas_credit: u64, pub block_gas_limit: u64, pub freeze_due_limit: u64, pub delete_due_limit: u64, pub flat_gas_limit: u64, pub flat_gas_price: u64, pub max_gas_threshold: u128, }  Field\tDescriptiongas_price\tPrice of 1 unit of gas, expressed in Nano Evers gas_limit\tMaximum gas amount for execution of a single message for an ordinary account special_gas_limit\tMaximum gas amount for execution of a single message for a system account gas_credit\tGas credited for an account to execute the external message block_gas_limit\tMaximum gas amount of the whole block freeze_due_limit\tValue of an account debt leading to account freeze delete_due_limit\tValue of an account debt leading to account removal flat_gas_limit flat_gas_price max_gas_threshold\t "},{"title":"Message Passing Fee​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#message-passing-fee","content":"Validators do the work of message delivery. To compensate their efforts, account pays for the message passing. The message passing fee depends on BlockchainConfig parameters fwd_pricesand the message size. The fwd_prices_mc and fwd_prices_wchave the following definition: pub struct MsgForwardPrices { pub lump_price: u64, pub bit_price: u64, pub cell_price: u64, pub ihr_price_factor: u32, pub first_frac: u16, pub next_frac: u16, }  The fee amount is calculated using the expression: msg_fwd_fees=lump_price+bit_price×msg.bits+cell_price×msg.cellsmsg\\_fwd\\_fees = lump\\_price + bit\\_price \\times msg.bits + cell\\_price \\times msg.cellsmsg_fwd_fees=lump_price+bit_price×msg.bits+cell_price×msg.cells Here, msg.bits — bit-length of the message body, msg.cells is a total amount of cells that this message consists of. "},{"title":"Data Storage Fee​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#data-storage-fee","content":"In Everscale, account is charged a fee for storing the data. The fee amount is calculated using the formula: fee=(cells∗prices.cell_price+bits∗prices.bit_price)∗Δfee = (cells * prices.cell\\_price + bits * prices.bit\\_price) * \\Deltafee=(cells∗prices.cell_price+bits∗prices.bit_price)∗Δ Δ\\DeltaΔ — the time interval between now and the latest payment moment, measured in seconds. Here, we assume that storage prices stay constant during the Δ\\DeltaΔ interval. The storage fee gets charged on each message processing storage_phase. For greater flexibility, the storage prices may be changed depending on the current supply/demand situation. It is done by negotiating new blockchain config parameters prices.cell_priceprices.cell\\_priceprices.cell_priceand prices.bit_priceprices.bit\\_priceprices.bit_price among validators. After validators accept it, new parameters are written in the Masterchain config smart-contract. After the change, previous price parameters do no get lost. The whole history of storage price changes is stored in the config. It is done to provide precise calculation of the storage fee that take into account all the price changes during the interval of calculation. Data Storage Fee Calculation​ Here we describe the storage fee calculation expression in its generality. Lets assume we have the following list of prices equipped with a timestamp of a moment when the price change took place: T={t0,t1,...,tN}T = \\{ t_0, t_1, ..., t_N \\}T={t0​,t1​,...,tN​} Pr=⟨(pr0,t0),(pr1,t1),...,(prN,tN)⟩Pr = \\langle (pr_0, t_0), (pr_1, t_1), ..., (pr_N, t_N) \\ranglePr=⟨(pr0​,t0​),(pr1​,t1​),...,(prN​,tN​)⟩ Here, pr_0 is reserved for the initial prices set in the genesis block of the blockchain, and t0t_0t0​ is a timestamp of those initial prices being set. Let now denote the current timestamp, i.e. the moment of time when we want to calculate the storage fee, measured in Unix Epoch. Its value is always greater or equal than the most recent price change timestamp. Let last_paid denote the timestamp of the latest storage payment. If the payment didn't take place, last_paid=0last\\_paid = 0last_paid=0. To simplify the calculation formula, let us introduce a new listPr′Pr'Pr′, such that: Pr′=⟨(prk,tk),...,(prN,tN)⟩Pr' = \\langle (pr_k, t_k), ..., (pr_N, t_N) \\ranglePr′=⟨(prk​,tk​),...,(prN​,tN​)⟩ where t_k is the least timestamp among values t1...tNt_1 ... t_Nt1​...tN​ that is greater than last_paid. tk=min{ti∣ti∈T∧ti&gt;last_paid}t_k = min \\{ t_i | t_i \\in T \\land t_i &gt; last\\_paid \\}tk​=min{ti​∣ti​∈T∧ti​&gt;last_paid} In other words, the values tk,...,tNt_k, ..., t_Ntk​,...,tN​ form a subset ofT where each value is strictly greater than last_paid. We also add two more elements from the left and the right: Pr′′=⟨(prk,last_paid)⟩⋅Pr′⋅⟨(prN,now)⟩Pr'' = \\langle (pr_k, last\\_paid) \\rangle \\cdot Pr' \\cdot \\langle (pr_N, now) \\ranglePr′′=⟨(prk​,last_paid)⟩⋅Pr′⋅⟨(prN​,now)⟩ Here, dot operator denotes lists concatenation operation. We use the following shortcuts: pri=fst(Pri′′)pr_i = fst(Pr''_i)pri​=fst(Pri′′​) the first element of a two-element tuple, and ti=snd(Pri′′)t_i = snd(Pr''_i)ti​=snd(Pri′′​), the second element. The total storage fee for the time interval is: total_storage_fee=∑i=1..∣Pr′′∣(cells∗pri.cell_price+bits∗pri.bits_price)∗(ti−ti−1)total\\_storage\\_fee = \\sum_{i=1..|Pr''|}{(cells * pr_{i}.cell\\_price + bits * pr_{i}.bits\\_price) * (t_i - t_{i-1})}total_storage_fee=∑i=1..∣Pr′′∣​(cells∗pri​.cell_price+bits∗pri​.bits_price)∗(ti​−ti−1​) Data Storage Fee Calculation Algorithm​ For greater convenience, besides having the formula, we provide the pseudo-code for the algorithm calc_storage_fee, implemented in imperative fashion. Input: config — current blockchain configuration, has type BlockchainConfigstorage_info — the account storage info struct, has type StorageInfo.is_masterchain — is the account inhabits Masterchain or not, has type Boolnow — current time, measured in Unix Epoch, has type UInt Output: fee — the fee amount to be deducted from the account balance, has type UIntstorage_info — updated account storage info, has type StorageInfo def calc_storage_fee(config, storage_info, is_masterchain, now): cells = storage_info.used.cells bits = storage_info.used.bits last_paid = storage_info.last_paid prices = config.storage_prices # see AccStoragePrices assert len(prices) &gt; 0 if now &lt;= last_paid or last_paid == 0 or now &lt;= prices[0].utime_since: return 0 fee = 0 # calculate the fee according to prices that were actual # during the specific period of time for i in len(prices): cur_price = prices[i] if i &lt; len(prices) - 1: end = prices[i + 1].utime_since else: end = now_time if end &gt;= last_paid: delta = end - max(cur_price.utime_since, last_paid) if is_masterchain: fee += (cells * cur_price.mc_cell_prices_ps + \\ bits * cur_price.mc_bit_price_ps) * delta else: fee += (cells * cur_price.cell_price_ps + \\ bits * cur_price.bit_price_ps) * delta storage_info.last_paid = end return (fee, storage_info)  "},{"title":"Special Smart-Contracts​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#special-smart-contracts","content":"In Everscale blockchain, there is a set of smart-contracts that have a distinguished status in the system. For those contracts, validators are obligated to process their execution in a special priveledged manner. Such smart-contracts are called special or system. Accounts storing those contracts are called the same. Special smart-contracts enjoy the following privilege: No fee gets deducted for the code executionNo fee gets deducted for the storage useNo fee gets deducted for message passingIt has a special maximum gas limit, see GasLimitsPrices.special_gas_limitAllowed to process TickTock timer messages Upon executing a message for one of those special contracts, the Transaction Executor has to apply all those conditions. caution In this document, we mainly focus on ordinary accounts, leaving the special accounts processing details aside. "},{"title":"GlobalCapabilities Options​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#globalcapabilities-options","content":"There are several flags defining different aspects of the blockchain node operation mode. They are defined in GlobalCapabilities enumeration. Parameter\tDescriptionCapCreateStatsEnabled\tAllow update block statistics. Not related to Transaction Executor. CapBounceMsgBody\tInclude the first 256 bits of the original message in the bounce message body. CapReportVersion\tInclude the blockchain version info into the block. CapShortDequeue\tSome special mode of managing outbound messages by the Validator. Not related to Transaction Executor CapFastStorageStat\tUse alternative algorithm to update the structs AccountsStat. CapInitCodeHash\tUse the field init_code_hash in the AccountState. CapOffHypercube\tTurn off Hypercube routing algorithm for message delivery CapMycode\tProvide the virtual machine with the code of a smart-contract being executed. CapMbppEnabled\tNot used CapIhrEnabled\tNot used CapSplitMergeTransactions\tNot used "},{"title":"RawConfig options​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#rawconfig-options","content":"Besides already mentioned options, there are yet another set of options residing in the BlockchainConfig.raw_config. This field has the following structure: pub struct ConfigParams { pub config_addr: UInt256, pub config_params: HashmapE // &lt;u32, SliceData&gt; }  config_addr — is the configuration smart-contract account identifier (the workchain identifier equals - 1);config_params — dictionary with parameters, dictionary keys refers to an option number. We will not go deep into those options, because they are not relevant to our work. See ton-labs-block/src/config_params.rs for further investigation. "},{"title":"Error Code Enumeration​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#error-code-enumeration","content":"When Transaction Executor encounters an error during message processing, it returns a special answer to the calling side. The answer contains an error code. Here we list possible error codes and their short description. In our further discussion, we rely on those mnemonic names. "},{"title":"Error Code Enumeration​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#error-code-enumeration-1","content":"When Transaction Executor encounters an error during message processing, it returns a special answer to the calling side. The answer contains an error code. Here we list possible error codes and their short description. In our further discussion, we rely on those mnemonic names. Error Mnemonic Name\tDescriptionInvalidExtMessage\tIncorrect format of an incoming external message TrExecutorError(e)\tWide range of errors during message processing TvmExceptionCode(e)\tTVM produced exception e during byte-code execution NoAcceptError\tThe smart-contract did not accept external message NoFundsToImportMsg\tNot enough funds to process external message ExtMsgComputeSkipped(r)\tDuring the external message processing, the Compute phase was skipped with the reason r "},{"title":"Account State Update​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#account-state-update","content":"In the transaction object, there is a special field reflecting the change of the account state, the state_update field of type HashUpdate. The type is defined as follows: pub struct HashUpdate { pub old_hash: UInt256, pub new_hash: UInt256, }  Here old_hash refers to a hash value taken from the initial account state, before message processing; the new_hash is a hash taken from the updated account state, after successful message processing. "},{"title":"Transaction Description Object​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#transaction-description-object","content":"During the incoming message processing, Transaction Executor constructs the report about the processing. This report has a special name — Transaction Description, and defined by the following structure: pub struct TransactionDescrOrdinary { pub credit_first: bool, pub storage_ph: Option&lt;TrStoragePhase&gt;, pub credit_ph: Option&lt;TrCreditPhase&gt;, pub compute_ph: TrComputePhase, pub action: Option&lt;TrActionPhase&gt;, pub aborted: bool, pub bounce: Option&lt;TrBouncePhase&gt;, pub destroyed: bool }  This description object may be used for fast checkups on the main system invariants, critical for its safety, during runtime. Field\tDescriptionstorage_ph\tStorage phase descriptor credit_ph\tCredit phase descriptor compute_ph\tCompute phase descriptor action\tAction phase descriptor bounce\tBounce phase descriptor credit_first\tCredit phase was executed before Storage phase aborted\tIs Action phase failed destroyed\tIs account deleted after message execution We now describe each descriptor separately. Storage Phase Descriptor​ pub struct TrStoragePhase { pub storage_fees_collected: Grams, pub storage_fees_due: Option&lt;Grams&gt;, pub status_change: AccStatusChange }  storage_fees_collected denotes the amount of tokens deducted from the account balance to cover the storage fee.storage_fees_due denotes the debt value, if there is any. Otherwise, this value equals None.status_change denotes the possible account status change. It may have been the case that the status were frozen or deleted due to having a significant debt value. Possible values are: pub enum AccStatusChange { Unchanged, Frozen, Deleted, }  Credit Phase Descriptor​ The Credit Phase descriptor is defined as follows: pub struct TrCreditPhase { pub due_fees_collected: Option&lt;Grams&gt;, pub credit: CurrencyCollection, }  Field\tDescriptiondue_fees_collected\tAmount of coins deducted from the message balance to cover the debt of the account, if any existed at the beginning of the credit phase. If there were no debt, the value is None . credit\tMessage value after the fees were conducted from it. Compute Phase Descriptor​ Compute Phase descriptor is defined with the following enumeration: pub enum TrComputePhase { Skipped(TrComputePhaseSkipped), Vm(TrComputePhaseVm) }  Choice 1. Skipped​ If the Compute phase was not successfully performed, the descriptor value is Skippedin this case. It should have an argument with following type: pub struct TrComputePhaseSkipped { pub reason: ComputeSkipReason }  reason has to be one of the following: pub enum ComputeSkipReason { NoState, BadState, NoGas, }  Field\tDescriptionNoState\tCaused by the following conditions: 1) The account did not exist by the time of message arrival, and the incoming message did not contain the StateInit part; 2) The account was not initialized and the incoming message did not contain the StateInit part. NoState\tCaused by the following conditions: 1) The account did not exist by the time of message arrival, and the incoming message did not contain the StateInit part; 2) The account was not initialized and the incoming message did not contain the StateInit part. BadState\tCaused by the following conditions: 1) The account was in AccStateUninit state, the message did contain the StateInit part, but an attempt to initialize the account with the given StateInit failed due to being inconsistent with the account; 2) The account was in AccStateFrozen state, the message contained the StateInit part, but an attempt to unfreeze the account with the given state init failed due to being inconsistent with the account. NoGas\tCaused by the following conditions: 1) After Credit and Storage phases, the account balance had no coins: its balance equals zero; 2) Values gas_limit and gas_credit, calculated with the init_gas algorithm, both equals 0. Choice 2. Successful computation​ Successful Compute phase result is defined by the following TrComputePhaseVm structure: pub struct TrComputePhaseVm { pub success: bool, pub msg_state_used: bool, pub account_activated: bool, pub gas_fees: Grams, pub gas_used: VarUInteger7, pub gas_limit: VarUInteger7, pub gas_credit: Option&lt;VarUInteger3&gt;, pub mode: i8, pub exit_code: i32, pub exit_arg: Option&lt;i32&gt;, pub vm_steps: u32, pub vm_init_state_hash: UInt256, pub vm_final_state_hash: UInt256 }  Field\tDescriptionsuccess\tCompute phase completion status. See compute_phase_success gas_fees\tFees for the gas used by a smart-contract execution, see here gas_used\tAn exact amount of gas used by the VM during the execution gas_limit\tA strict upper bound on the amount of gas allowed for this account init_gas gas_credit\tAn amount of gas credited to be used for external messages before being accepted init_gas vm_steps\tNumber of steps performed by the VM exit_code\tComputation exit code, see compute_phase_exitcode exit_arg\tComputation exit argument, see compute_phase_exitcode mode\tAlways equals 0 vm_init_state_hash\tNot used vm_final_state_hash\tNot used msg_stated_used\tNot used account_activated\tNot used Action Phase Descriptor​ Action Phase descriptor is defined as follows: pub struct TrActionPhase { pub success: bool, pub valid: bool, pub no_funds: bool, pub status_change: AccStatusChange, pub total_fwd_fees: Option&lt;Grams&gt;, pub total_action_fees: Option&lt;Grams&gt;, pub result_code: i32, pub result_arg: Option&lt;i32&gt;, pub tot_actions: i16, pub spec_actions: i16, pub skipped_actions: i16, pub msgs_created: i16, pub action_list_hash: UInt256, pub tot_msg_size: StorageUsedShort, }  Field\tDescriptionsuccess\tAction phase completed successfully. The success condition is described here. valid\tAction phase is valid. The validity condition is described here. result_code\tAction phase failed with the result code, see action_result_codes. In case of success, the value equals to 0 result_arg\tIn case of an error, the item number of an action in the action list that caused the error no_funds\tTrue if the error was caused by a balance insufficiency status_change\tEquals AccStatusChange::Deleted in case of the account being deleted after processing actions total_fwd_fees\tTotal fees for the SendMsg actions processing total_action_fees\tTotal fees for the whole action list processing tot_actions\tTotal number of actions in the action list at a beginning of the Action phase spec_actions\tNumber of special actions, i.e. Reserve, SetCode, SetLib msg_created\tNumber of successful SendMsg actions action_list_hash\tHash of action list calculated at a beginning of the Action phase tot_msg_size\tTotal size of all the generated messages skipped_actions\tNot used Action Result Codes​ Result Code\tDescriptionRESULT_CODE_ACTIONLIST_INVALID\tMessage serialization error RESULT_CODE_TOO_MANY_ACTIONS\tContract generated more actions than allowed. Maximum actions count is 255 RESULT_CODE_UNKNOWN_OR_INVALID_ACTION\tBinary serialization error, or invalid flags. See remarks. RESULT_CODE_INCORRECT_SRC_ADDRESS\tWide source address address, or the source address does not equal to the account address RESULT_CODE_INCORRECT_DST_ADDRESS\tIncorrect destination address, or destination workchain is not allowed to receive messages, or destination workchain does not exist RESULT_CODE_ANYCAST\tDestination address of type Anycast. It is no longer supported and considered an error. RESULT_CODE_NOT_ENOUGH_GRAMS\tInsufficient balance. See remarks. RESULT_CODE_NOT_ENOUGH_EXTRA\tExtra-tokens balance is insufficient to execute to action RESULT_CODE_INVALID_BALANCE\tReserve action lead to an error, or outgoing message is too big to process RESULT_CODE_BAD_ACCOUNT_STATE\tActions SetCode or ChangeLib lead to an error RESULT_CODE_UNSUPPORTED\tSendMsg action has incorrect flags set Remarks:​ RESULT_CODE_UNKNOWN_OR_INVALID_ACTION reasons are: Actions serialization errorSendMsg action has invalid flags, that is: The mutually exclusive flags are set: SENDMSG_REMAINING_MSG_BALANCE and SENDMSG_ALL_BALANCEMessage was sent with an unknown flag sendmsg_flags;The flag SENDMSG_DELETE_IF_EMPTY is set, but the flag SENDMSG_ALL_BALANCE isn't; Reserve action has invalid flags Unknown flag is setFlag RESERVE_PLUS_ORIG is set, but RESERVE_REVERSE isn't RESULT_CODE_NOT_ENOUGH_GRAMS reasons are: For SendMsg action, the flag SENDMSG_REMAINING_MSG_BALANCE is set, but SENDMSG_PAY_FEE_SEPARATELY isn'tMessage balance is insufficient to cover message delivery feesAccount balance is insufficient to cover all message delivery fees Bounce Phase Transaction Descriptor​ Bounce Phase descriptor is defined with the following enumeration: pub enum TrBouncePhase { Negfunds, Nofunds(TrBouncePhaseNofunds), Ok(TrBouncePhaseOk), }  Negfunds choice is not used.Nofunds(TrBouncePhaseNofunds) denotes the insufficiency of account balance, details are put into the parameter valueOk(TrBouncePhaseOk) denotes success, i.e. that the bounce message has been formed and put into the Msg queue. Details of the phase are put into the parameter value. Choice 1. Nofunds​ pub struct TrBouncePhaseNofunds { pub msg_size: StorageUsedShort, pub req_fwd_fees: Grams, }  msg_size denotes the size of generated bounce message. This value is not used.req_fwd_fees denotes the fee for the message delivery. Choice 2. Ok(TrBouncePhaseOk)​ pub struct TrBouncePhaseOk { pub msg_size: StorageUsedShort, pub msg_fees: Grams, pub fwd_fees: Grams, }  msg_size not used.fwd_fees is a full forwarding fee for the bounce message.msg_fees is a part of fwd_fees that goes to the validator processing the message. "},{"title":"Actions​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#actions","content":"After successfully executing a smart-contract code, the TVM virtual machine provides the executor with updated contract state and a list of actions to be further processed. In our context, an action refers to an order for the Transaction Executor to perform a distinguished stateful act. It could be sending a message, changing the smart-contract's code or reserving coins on the balance. "},{"title":"Type of Actions​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#type-of-actions","content":"Here we provide a set of possible actions, with the description. We go deep on each of them further. pub enum OutAction { None, // default value SendMsg { mode: u8, out_msg: Message, }, SetCode { new_code: Cell, }, ReserveCurrency { mode: u8, value: CurrencyCollection, }, ChangeLibrary { mode: u8, code: Option&lt;Cell&gt;, hash: Option&lt;UInt256&gt;, } }  Action\tDescriptionSendMsg\tSend the message out_msg to some account using the provided mode ReserveCurrency\tManage the account's balance to guarantee its sufficiency SetCode\tChange the contract byte-code with the given new_code ChangeLibrary\tUpdate code library "},{"title":"Action SendMsg​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#action-sendmsg","content":"SendMsg(mode,outmsg)SendMsg(mode,out_msg)SendMsg(mode,outm​sg) action sends a message to an account. The message out_msgout\\_msgout_msg contains the destination address as well as the payload to be delivered. This action has a lot of modes that can be combined using logicalOR operator. Some mode combinations are prohibited. See rc_remarks. Mode\tValue\tDescriptionSENDMSG_ORDINARY\t0\tSend the message. Without other modes, the forwarding fee for the delivery is paid by the receiver. SENDMSG_PAY_FEE_SEPARATELY\t1\tSend the message. The forwarding fee is paid by the sender. SENDMSG_IGNORE_ERROR\t2\tIf an error occurs during the processing of this action, ignore it. SENDMSG_DELETE_IF_EMPTY\t32\tThe account gets deleted if, after the action processed, the balance becomes zero SENDMSG_REMAINING_MSG_BALANCE\t64\tThe message should carry all the remaining value of the inbound message additionally to the value specified in the field SENDMSG_ALL_BALANCE\t128\tThe message should carry all the remaining balance of the account, instead of the value specified in the value field "},{"title":"Action ReserveCurrency​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#action-reservecurrency","content":"ReserveCurrency(mode,val)ReserveCurrency(mode, val)ReserveCurrency(mode,val) action makes a coin reserve on the balance. This action has several modes of operation. Modes can be combined. Mode\tValue\tDescriptionRESERVE_EXACTLY\t0\tReserve exactly valvalval coins RESERVE_ALL_BUT\t1\tReserve acc_balance−valacc\\_balance - valacc_balance−val coins, where acc_balanceacc\\_balanceacc_balance is a remaining balance of the account RESERVE_IGNORE_ERROR\t2\tSkip the action on failure RESERVE_PLUS_ORIG\t4\tReserve acc_balance+valacc\\_balance + valacc_balance+val coins. It should be used only with RESERVE_REVERSE. RESERVE_REVERSE\t8\tReverse value of valvalval in the calculation of the reserve, i.e. substitute valvalval with −val-val−val "},{"title":"Action SetCode​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#action-setcode","content":"Currently, we skip this action. "},{"title":"Message Processing Algorithm​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#message-processing-algorithm","content":"In this section, we present a pseudo-code for incoming message processing algorithm. The algorithm is divided in two mutually exclusive parts: ExecuteInternalMessage — internal message execution internal_message_processingExecuteExternalMessage — external message execution external_message_processing Both algorithms rely on executing some or all of the phases: Credit phase credit_phaseStorage phase storage_phaseCompute phase compute_phaseAction phase action_phaseBounce phase bounce_phase Please note that we consider only ordinary accounts here. The algorithm for executing messages on special accounts is not considered. Input: in_msg — incoming message, has type Messageaccount — account, has type Accountparams — executor parameters, has type Parametersconfig — blockchain configuration, has type BlockchainConfig Output: On success, returns Ok(acc1, trans), such that: acc1 — updated account, has type Accounttrans — transaction, has type Transaction On error, returns error of the type ExecutorError Modifies: def ExecuteMessage(in_msg, account, params, config): if in_msg.header is ExtOutMsgInfo: return ExecutorError.InvalidExtMessage if in_msg.header.dst == None: return ExecutorError.TrExecutorError() if in_msg.header is ExtInMessageHeader and account.balance == 0: return ExecutorError.NoFundsToImportMsg() acc = account.clone() if in_msg.header is ExtInMsgInfo: return ExecuteExternalMessage(in_msg, acc, params, config) elif in_msg.header is IntMsgInfo: return ExecuteInternalMessage(in_msg, acc, params, config) return ExecutorError.TrExecutorError()  "},{"title":"Internal Message Processing Algorithm​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#internal-message-processing-algorithm","content":"At this point, the message is known to be internal. Execute it with the given account. Input: in_msg — incoming message, has type Messageaccount — account, has type Accountparams — executor parameters, has type Parametersconfig — blockchain configuration, has type BlockchainConfig Output: On success, returns Ok(acc1, trans), such that: acc1 — updated account, has type Accounttrans — transaction, has type Transaction On error, returns error of the type TransactionExecutor.TrExecutorError Modifies: account def ExecuteInternalMessage(in_msg, account, params, config): acc_balance = account.balance msg_balance = in_msg.hdr.value credit_first = not in_msg.hdr.bounce lt = max(account.last_tr_time, max(params.last_tr_lt, in_msg.lt + 1)) tr = Transaction(account.account_id, account.status, lt, now(), in_msg) descr = TransactionDescrOrdinary(credit_first: credit_first) # If the bounce flag is not set, execute the Credit Phase # before Storage phase if credit_first: credit_ph_res = credit_phase(account, tr, msg_balance, acc_balance) if credit_ph_res is Ok: descr.credit_ph = credit_ph_res.credit_ph else: return ExecutorError.TrExecutorError() # Execute Storage Phase storage_ph_res = storage_phase(account, acc_balance, tr, is_masterchain, config) descr.storage_ph = storage_ph_res.storage_ph # Why this is needed? if credit_first and (msg_balance &gt; acc_balance): msg_balance = acc_balance original_acc_balance = account.balance - tr.total_fees if not credit_first: credit_ph_res = credit_phase(account, tr, msg_balance, acc_balance) if credit_ph_res is Ok: descr.credit_ph = credit_ph_res.credit_ph else: return ExecutorError.TrExecutorError() # Both storage and credit phases are completed at this point. # We need to update the last_paid field not to loose this # information in case of some further errors showing up. account.last_paid = params.block_unixtime # Parameters to be passed into TVM smci = build_contract_info(acc_balance, account.address, params.block_lt, lt, params.seed_block) # First element is the bottom of the stack stack = Stack([acc_balance, msg_balance, Cell(in_msg), in_msg.body, False]) # Execute Compute Phase compute_ph_res = compute_phase(in_msg, account, acc_balance, msg_balance, params.state_libs, smci, stack, is_masterchain) if not (compute_ph_res is Ok): return ExecutorError.TrExecutorError() descr.compute_ph = compute_ph_res.compute_ph actions = compute_ph_res.actions new_data = compute_ph_res.new_data # Generated outbound messages to be sent into other accounts out_msgs = [] compute_gas_fees = descr.compute_ph.gas_fees tr.total_fee = tr.total_fee + compute_gas_fees if descr.compute_ph.success: act_phase_res = action_phase(tr, account, original_acc_balance, acc_balance, msg_balance, phase.gas_fees, actions, new_data) if act_phase_res is Ok: descr.action = act_phase_res.action_ph out_msgs = act_phase_res.msgs else: return ExecutorError.TrExecutorError() if descr.action != None: if descr.action.status_change == AccStatusChange.Deleted: account = Account() descr.destroyed = True descr.aborted = not descr.action.success else: descr.aborted = True # If the Action Phase failed, and the incoming message allows # bounce answer, execute the Bounce Phase if (descr.aborted == True) and (in_msg.hdr.bounce = True): if descr.compute_ph is Vm: bounce_ph_res = \\ bounce_phase(msg_balance, acc_balance, compute_gas_fees, tr, my_addr) if bounce_ph_res is Ok: descr.bounce = bounce_ph_res.bounce_ph if (bounce_ph_res.bounce_msg != None): out_msgs = out_msgs + [bounce_ph_res.bounce_msg] else: return ExecutorError.TrExecutorError() if descr.bounce is Ok: acc_balance = original_acc_balance if account.status == AccountStatus.AccStateUninit and \\ acc_balance == 0: account = Account() else: if account.is_none() and acc_balance != 0: account = Account.uninit(is_msg.hdr.dst, 0, last_paid, acc_balance) if account.status() == AccountStatus.AccStateUninit and acc_balance == 0: account = Account() tr.acc_end_status = account.status account.balance = acc_balance params.last_tr_lt = lt upd_lt = add_messages(tr, out_msgs, params.last_tr_lt) account.last_tr_time = upd_lt tr.descr = descr return Ok(tr, account)  The function add_messages assigns the proper logical timestamp for each message from the out_msgs collection, and then include the message into the transaction. def add_messages(tr, out_msgs, lt): lt_next = lt + len(out_msgs) + 1 lt_next += 1 for msg in out_msgs: msg.at = now() msg.lt = lt tr.add_out_message(msg) lt_next += 1 return Ok(lt_next)  "},{"title":"External Message Processing Algorithm​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#external-message-processing-algorithm","content":"The execution of external message on the given account. Input: in_msg — incoming message, has type Messageaccount — account, has type Accountparams — executor parameters, has type Parametersconfig — blockchain configuration, has type BlockchainConfig Output: On success, returns Ok(acc1, trans), such that: acc1 — updated account, has type Accounttrans — transaction, has type Transaction On error, returns error of the type TransactionExecutor.TrExecutorError Modifies: account def ExecuteExternalMessage(in_msg, account, params, config): acc_balance = account.balance msg_balance = in_msg.hdr.value is_masterchain = (in_msg.dst_workchain_id == -1) lt = max(account.last_tr_time, max(params.last_tr_lt, in_msg.lt + 1)) tr = Transaction(account.account_id, account.status, lt, now(), Cell(in_msg)) descr = TransactionDescrOrdinary(credit_first: True) in_fwd_fee = fwd_fee(Cell(in_msg)) if acc_balance &lt; in_fwd_fee: return ExecutorError.NoFundsToImportMsg tr.total_fee = tr.total_fee + in_fwd_fee # Execute Storage Phase storage_ph_res = storage_phase(account, acc_balance, tr, is_masterchain, config) descr.storage_ph = storage_ph_res.storage_ph if account.balance &gt;= tr.total_fees: original_acc_balance = account.balance - tr.total_fees else: original_acc_balance = account_balance # Credit Phase is skipped for external messages # Storage phase is completed at this point # We need to update the last_paid field not to loose this # information in case of some further errors showing up account.last_paid = params.block_unixtime # Parameters to be passed into TVM smci = build_contract_info(acc_balance, account.address, params.block_lt, lt, params.seed_block) # First element is the bottom of the stack stack = Stack([acc_balance, msg_balance, Cell(in_msg), in_msg.body, False]) # Execute Compute Phase compute_ph_res = compute_phase(in_msg, account, acc_balance, msg_balance, params.state_libs, smci, stack, is_masterchain) if compute_ph_res is Ok: descr.compute_ph = compute_ph_res.compute_ph else: return ExecutorError.TrExecutorError() # Generated outbound messages to be sent into other # accounts out_msgs = [] compute_gas_fees = descr.compute_ph.gas_fees tr.total_fee = tr.total_fee + compute_gas_fees if descr.compute_ph.success: act_phase_res = action_phase(tr, account, original_acc_balance, acc_balance, msg_balance, phase.gas_fees, accounts, compute_ph_res.new_data) if act_phase_res is Ok: descr.action = act_phase_res.action_ph out_msgs = act_phase_res.msgs else: return ExecutorError.TrExecutorError() if descr.action != None: if descr.action.status_change == AccStatusChange.Deleted: account = Account() descr.destroyed = True descr.aborted = not descr.action.success else: descr.aborted = True # The Bounce Phase is skipped for external messages if account.status() == AccountStatus.AccStateUninit and acc_balance == 0: account = Account() tr.acc_end_status = account.status account.balance = acc_balance params.last_tr_lt = lt upd_lt = add_messages(tr, out_msgs, params.last_tr_lt) account.last_tr_time = upd_lt tr.descr = descr return Ok(tr, account)  "},{"title":"Credit Phase​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#credit-phase","content":"At this phase, coins from the message balance goes to the account balance. This phase is executed only for internal messages. External messages have no coins attached. Input: account — account that the message is executed on, Accounttr — forming transaction, has type Transactionmsg_balance — message balance, has type Gramsacc_balance — current balance of the account, has type Grams Output: The phase always succeeds. It returns the value of type: /Ok(TrCreditPhase(collected, msg_balance))/, such that: collected — the amount of coins withheld for the account debt, if any.msg_balance — the amount of coins put on the account balance after the debt fee was conducted. Modifies: account — updates the due_payment field with the remaining debt, if anytr — updates the total_fees fieldmsg_balance — the original message balance after the debt conducted, if anyacc_balance — the account balance with message coins def credit_phase(account, tr, msg_balance, acc_balance): due_payment = account.due_payment collected = min(due_payment, msg_balance) msg_balance = msg_balance - collected due_payment_remaining = due_payment - collected account.due_payment = due_payment_remaining tr.total_fees = tr.total_fees + collected # put message coins on the account balance acc_balance = acc_balance + msg_balance return Ok(TrCreditPhase(collected, msg_balance))  "},{"title":"Storage Phase​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#storage-phase","content":"This phase withholds the storage fee from the account balance. The fee amount is calculated using the algorithm calc_storage_fee calc_storage_fee Input: account — account that the message is executed on, has type Accounttr — forming transaction, has type Transactionmsg_balance — message balance, has type Gramsacc_balance — current balance of the account, has type Gramsconfig — main blockchain parameters, has type BlockchainConfig Output: This phase always succeeds. The return values may differ Ok(TrStoragePhase(collected, fee, status_change)), such that: collected — the amount of coins withheld for the storage feedebt — if the balance was insufficient, the remaining debt of the accountstatus_change — should the account be frozen or deleted afterwards Modifies: account — updates due_payment and status fieldsacc_balance — the current balance after the fee got deductedtr — updates the total_fee field def storage_phase(account, tr, msg_balance, acc_balance, config): # It is assumed that the current transaction must have a more # recent timestamp than the latest payment timestamp. # Otherwise, something is terribly wrong. assert (tr.now &gt;= acc.last_paid) # The account does not occupy any space, so do not charge the fee if account == None: return Ok(TrStoragePhase()) fee, account.storage_info = config.calc_storage_fee(account.storage_info, is_masterchain, tr.now) if account.due_payment &gt; 0: fee = fee + account.due_payment account.due_payment = None if acc_balance &gt;= fee: acc_balance = acc_balance - fee tr.total_fee = tr.total_fee + fee return Ok(TrStoragePhase(fee, None, AccStatusChange.Unchanged)) storage_fees_collected = acc_balance acc_balance = 0 tr.total_fee = tr.total_fee + storage_fees_collected fee = fee - storage_fees_collected need_freeze = fee &gt; config.get_gas_config(is_masterchanin).freeze_due_limit need_delete = \\ (account.status == AccountStatus.AccStateUninit or \\ account.status == AccountStatus.AccStateFrozen) and \\ fee &gt; config.get_gas_config(is_masterchain).delete_due_limit if need_delete: tr.total_fee = 0 account = Account() return Ok(TrStoragePhase(storage_fees_collected, fee, AccStatusChange.Deleted)) elif need_freeze: account.due_payment = fee if account.status == AccountStatus.AccStateActive: account.status = AccountStatus.AccStateFrozen return Ok(TrStoragePhase(storage_fees_collected, fee, AccStatusChange.Frozen)) else: return Ok(TrStoragePhase(storage_fees_collected, fee, AccStatusChange.Unchanged)) else: account.due_payment = fee return Ok(TrStoragePhase(storage_fees_collected, fee, AccStatusChange.Unchanged))  "},{"title":"Compute Phase​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#compute-phase","content":"Execute the account smart-contract, update the state, gather generated actions to pass on the next phase. Input: msg — message, has type Messageaccount — account, has type Accountacc_balance — current account balance, has type Gramsmsg_balance — message balance,has type Gramsstate_libs — code libraries, has type Blob (not relevant; omitted)smc_info — extra data for TVM, has type SmartContractInfostack — TVM initial stack valuesis_masterchain — is the account belongs to Masterchain, has type bool Output: On success, returns Ok(TrComputePhase, out_actions, new_data), such that: TrComputePhase — actual Compute Phase Descriptorout_actions — an ordered list of generated actionsnew_data — updated smart-contract state On error, returns Err(ExecutorError) with proper code. Modifies: account — updated account statesmc_info — mycode field set to point to the code of the smart-contractacc_balance — account balance after the gas fee deduction def uninit_account(account): if account.storage.state is AccountState.AccountActive: account.storage.state = AccountState.AccountUninit def compute_phase(msg, account, acc_balance, msg_balance, state_libs, smc_info, stack, is_masterchain): result_acc = account.clone() vm_phase = TrComputePhaseVm() is_external = msg.header is ExtInMsgInfo if result_acc == None: new_acc = account_from_message(msg, msg_balance) if new_acc != None: result_acc = new_acc result_acc.last_paid = smc_info.unix_time account = result_acc account.uninit_account() if acc_balance == 0: return Ok(TrComputePhase:skipped(ComputeSkipReason.NoGas), None, None) gas_config = config.get_gas_config(is_masterchain) gas = init_gas(acc_balance, msg_balance, is_external, gas_config) # Is it possible? if gas.gas_limit == 0 and gas.gas_credit == 0: return Ok(TrComputePhase.skipped(ComputeSkipReason.NoGas), None, None) libs = [] if msg.state_init != None: libs = state_init.libraries (reason, result_acc) = result_acc.compute_new_state(acc_balance, msg) if reason != None: return Ok(TrComputePhase.skipped(reason), None, None) vm_phase.gas_credit = gas.gas_credit vm_phase.gas_limit = gas.gas_limit if result_acc.code == None: if is_external: return ExecutorError.NoAcceptError() vm_phase.success = False vm_phase.gas_fees = gas_config.calc_gas_fee(0) if acc_balance &lt; vm_phase.gas_fees: return ExecutorError.TrExecutorError() acc_balance -= vm_phase.gas_fees account = result_acc return Ok(TrComputePhase.Vm(vm_phase), None, None) code = result_acc.code data = result_acc.data libs.push(result_acc.libraries) # local libraries libs.push(state_libs) # masterchain libraries smc_info.mycode = code # Here, we initialize abstract TVM virtual machine. # The exact behavior of this device is out of scope. vm = TVM(code) vm.smc_info = smc_info vm.config = config vm.stack = stack vm.data = data vm.libraries = libs vm.gas = gas result = vm.execute() vm_phase.success = vm.commited_state.is_committed # vm.gas may have been updated after the execution gas_vm = vm.gas # how much credited gas remains unspent credit = gas_vm.gas_credit used = gas_vm.gas_used vm_phase.gas_used = used if credit != 0: if is_external: # The smart-contract has to explicitly accept the external message, # otherwise it gets rejected. The acceptance of a message manifests # itself in the credit field being equal to 0. return ExecutorError.NoAcceptError() vm_phase.gas_fees = 0 else: gas_fees = gas_config.calc_gas_fee(used) vm_phase.gas_fees = gas_fees vm_phase.mode = 0 vm_phase.vm_steps = vm.steps new_data = vm.commited_state if new_data == None: vm_phase.success = False out_actions = vm.actions if out_actions = None: vm_phase.success = False account = result_acc return Ok(TrComputePhase.Vm(vm_phase), out_actions, new_data)  "},{"title":"Compute Phase Success Conditions​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#compute-phase-success-conditions","content":"We would like to explicitly articulate what it means for theCompute Phase to succeed. To do that,we specify the opposite condition, i.e. when it fails. In all other scenarios the phase is considered successful. The success status is important, because it decides if the action phase has to be executed afterwards. For the phase to fail, one of the following conditions must hold: The smart-contract data is not committed after the execution1The new smart-contract data is ill-formedThe generated actions list is ill-formed caution The compute phase may be considered successful even if the computation thrown an exception. This is quite unintuitive, yet very important fact. "},{"title":"Compute Phase Exit Code​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#compute-phase-exit-code","content":"The exit code value shows if the computation finished normally or was aborted due to some exception. In case of the former, the exit code should have values 0 or 1. In case of the latter, the exception might be of a system or custom type. If the exception is a system one, i.e. not intentionally emitted by the code using a special TVM instruction, the exit code contains one of the standard exit codes. If the exception is custom, then the exit code should also equal to 0 or 1, but there is an extra exit_arg field that provides the user defined code. For standard TVM exception codes, see here. "},{"title":"Calculate Gas Fee Algorithm​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#calculate-gas-fee-algorithm","content":"The algorithm to calculate the amount of coins to be paid for the consumed gas. Input: gas_prices — a structure with actual gas prices, has type GasLimitsPricegas_used — amount of gas units consumed by the computation, has type Uint Output: The amount of coins to be paid for the gas. Modifies: None. def calc_gas_fee(gas_prices, gas_used): if gas_used &lt;= gas_prices.flat_gas_limit: return gas_prices.flat_gas_limit gas_fee = flat_gas_price + (gas_used - gas_prices.flag_gas_limit) * \\ gas_prices.gas_price return gas_fee  "},{"title":"Compute New State Algorithm​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#compute-new-state-algorithm","content":"The algorithm compute_new_state computes the actual account state by given account record, the balance and the message. In particular, this algorithm is used to initialize uninitialized accounts with code and data borrowed from an external message with non-emptystate_init field. Input: account — account structure, has type Accountacc_balace — current account balance, has type Uintin_msg — message being executed, has type Message Output: On success, returns None.On failure, returns one of the ComputeSkipReason codes. Modifies: account def compute_new_state(account, acc_balance, in_msg): if account.status == AccountStatus.AccStateNonexist: if in_msg.state_init == None: return ComputeSkipReason.NoState else: return ComputeSkipReason.BadState elif account.status == AccountStatus.AccStateActive: return None elif account.status == AccountStatus.AccStateUninit: if in_msg.state_init != None: if account.try_activate_by_init_code_hash(in_msg.state_init) != None: return None else: return ComputeSkipReason.BadState else: return ComputeSkipReason.NoState elif account.status == AccountStatus.AccStateFrozen: if acc_balance != 0 and in_msg.state_init != None: if account.try_activate_by_init_code_hash(in_msg.state_init) != None: return None else: return ComputeSkipReason.BadState return ComputeSkipReason.NoState return None  "},{"title":"Activate By Init Algorithm​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#activate-by-init-algorithm","content":"The algorithm try_activate_by_init_code_hash does the initialization or re-initialization of the account, with the given state_init. Input: account — account structure to be initializedstate_init — state_init field from the inbound message Output: On success, returns OkOn failure, returns Err Modifies: account — the field storage.state gets updated by the state_init on success def try_activate_by_init_code_hash(account, state_init): if account == None: return Err new_state = None if account.storage.state == AccountState.AccountUninit: if hash(state_init) == account.addr.address: new_state = AccountState.AccountActive( hash(state_init.code), state_init ) else: return Err elif account.storage.state == \\ AccountState.AccountFrozen(init_code_hash, state_init_hash): if state_init_hash == hash(state_init): new_state = AccountState.AccountActive(init_code_hash, state_init) else: return Err else: new_state = account.storage.state account.storage.state = new_state return Ok  "},{"title":"Initial Gas Algorithm​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#initial-gas-algorithm","content":"The algorithm computes TVM Gas-related initial values. Those values are provided to the virtual machine right before a smart-contract execution. If the execution takes more than allowed gas, it gets stopped. Input acc_balance: current account balancemsg_balance: message balanceis_external: is the message externalgas_info: structure with limits and prices for the workchain Output Returns the structure Gas() containing 4 values: gas_limit: the maximum gas value available for any smart-contract of the workchaingas_credit: the amount of gas to be credited for the execution before the smart-contract accepts the messagegas_max: the maximum allowed gas to be spent on the execution of the current smart-contractgas_prices: a structure with gas prices Modifies: None def init_gas(acc_balance, msg_balance, is_external, gas_info): gas_max = min(gas_info.gas_limit, gas_info.calc_gas(acc_balance)) gas_credit = 0 if is_external: gas_credit = min(gas_info.gas_credit, gas_max) gas_limit = gas_credit else: gas_limit = min(gas_max, gas_info.calc_gas(msg_balance)) return Gas(gas_limit, gas_credit, gas_max, gas_info.get_real_gas_price())  "},{"title":"Account From Message Algorithm​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#account-from-message-algorithm","content":"The algorithm creates new account by using data from the internal message. External messages are rejected. Creation of a new account based on an external message is located elsewhere. Seecompute_new_state algorithm. Input msg: incoming message being processed, has type Messagemsg_remaining_balance: the current amount of coins left on the message balance, has type Uint Output Either returns a new Account object, or None. Both results are considered successful. Modifies: None def account_from_message(msg, msg_remaining_balance): if not (msg.header is IntMsgInfo): return None if msg_remaining_balance == 0: return None header = msg.header init = msg.state_init if init != None and init.code != None and hash(init) == header.dst.address: return Account.active_by_init_code_hash(hdr.dst, msg_remaining_balance, 0, init) if header.bounce: return None else: return Account.uninit(hdr.dst, 0, 0, msg_remaining_balance)  "},{"title":"Action Phase​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#action-phase","content":"By given ordered action list, the Action phase executes each action item in the list by applying proper action handler. Input: tr — transaction being constructed, has type Transactionaccount — account executing the message, has type Accountoriginal_acc_balance — account balance after storage and credit phase, has type Uintacc_balance — the mutable copy of the original_acc_balance, has type Uintmsg_remaining_balance — message balance without debt value if any, has type Uintcompute_phase_fees — gas fees from the compute phase, has type Uintactions — list of actions generated on the Compute Phase, has type list(OutAction)new_data — the smart-contract data after the Compute Phase, some binary blob. Output: On success, returns Ok(phase, messages) such that: phase denotes the Action Phase Descriptormessages denotes a list of messages to be sent, has type list(Message) On error, returns Err(result_code), such that: result_code describes a type of an error, see here. Modifies: traccountacc_balancemsg_remaining_balance MAX_ACTIONS = 255 def action_phase(tr, account, original_acc_balance, acc_balance, msg_remaining_balance, compute_phase_fees, actions, new_data): acc_copy = account.clone() acc_remaining_balance = acc_balance phase = TrActionPhase() total_reserved_value = 0 # Serialization issues are put aside, it is too low-level for # our purpose. # Interesting to note, actions overload leads to OK, not Error? if len(actions) &gt; MAX_ACTIONS: phase.result_code = RESULT_CODE_TOO_MANY_ACTIONS return Ok(phase, []) phase.action_list_hash = hash(actions) phase.tot_actions = len(actions) account_deleted = False out_msgs_tmp = [] address = acc_copy.address for action in actions: if action is OutAction.SendMsg: if action.mode &amp; SENDMSG_ALL_BALANCE: out_msgs_tmp.push((action.mode, action.out_msg)) continue result = outmsg_action_handler(phase, action.mode, action.out_msg, acc_remaining_balance, msg_remaining_balance, compute_phase_fees, config, address, total_reserved_value, account_deleted) if result is Ok: phase.msgs_created += 1 out_msgs_tmp.push((action.mode, action.out_msg)) else: return result elif action is OutAction.ReserveCurrency: result = reserve_action_handler(action.mode, action.value, original_acc_balance, acc_remaining_balance) if result is Ok: phase.spec_actions += 1 total_reserved_value += result.reserved_value else: phase.valid = True phase.result_code = result # phase.no_funds = True return Ok(phase, []) else: return Ok(phase, []) # process messages that have SENDMSG_ALL_BALANCE flag set last # skipping all other already processed messages out_msgs = [] for (mode, out_msg) in out_msgs_tmp: if not (mode &amp; SENDMSG_ALL_BALANCE): out_msgs.push(out_msg) continue result = outmsg_action_handler(phase, mode, out_msg, acc_remaining_balance, msg_remaining_balance, compute_phase_fees, config, address, total_reserved_value, account_deleted) if result == Ok: phase.msgs_created += 1 out_msgs.push(out_msg) else: return Ok(phase, []) acc_remaining_balance += total_reserved_value tr.total_fee += phase.total_action_fees if account_deleted: phase.status_change = AccStatusChange.Deleted phase.valid = True phase.success = True acc_balance = acc_remaining_balance account = acc_copy account.data = new_data return Ok(phase, out_msgs)  "},{"title":"Action Phase Success Condition​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#action-phase-success-condition","content":"All actions formed at the Compute Phase were successfully processed. If an action had a special error-canceling flag set, such error will not result in the whole phase failure. The action will be skipped in this case. "},{"title":"Action Phase Validity Condition​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#action-phase-validity-condition","content":"To specify the validity condition, we will define the opposite, i.e. when the action phase is considered invalid. The number of actions in the action list is greater than MAX_ACTIONSAny SendMsg action processing finished with an errorThe unknown action type was found during the processing In all other cases, the action phase is considered valid. "},{"title":"SendMsg Action Handler​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#sendmsg-action-handler","content":"The SendMsg action handler is responsible for generating messages to be sent. It may fail due to several reasons. In this case, the action phase get stopped, unless the SENDMSG_IGNORE_ERROR flag is set. Input: phase — actual Action Phase Descriptormode — flags for sending the messagemsg — message being sent, has type Messageacc_balance — actual account balance, has type UIntmsg_balance — the message balance after debt being deducted, has type Uintcompute_phase_fees — gas fees from Compute Phaseconfig — blockchain configuration, has type BlockchainConfigmy_addr — account addressreserved_value — the value of coins reserved by the ReserveCoins actionsaccount_deleted — the output value, set to True if account needs to be deleted Output: On success, returns Ok(value), such that: value — the amount of coins to be deducted from the account balance On failure, returns Err(result_code), such that: result_code — describes the error, see here Modifies: phasemodemsgacc_balancemsg_balanceaccount_deleted MAX_MSG_BITS = 2**21 # 2 Mb MAX_MSG_CELLS = 2**13 def get_fwd_prices(config, is_masterchain): if is_masterchain: return config.fwd_prices_mc else: return config.fwd_prices_wc def outmsg_action_handler(phase, mode, msg, acc_balance, msg_balance, compute_phase_fees, config, my_addr, reserved_value, account_deleted): invalid_flags = SENDMSG_REMAINING_MSG_BALANCE or SENDMSG_ALL_BALANCE mode_not_valid = mode and (not SENDMSG_VALID_FLAGS) mode_has_invalid = mode and invalid_flags == invalid_flags mode_delete_not_sab = (mode and SENDMSG_DELETE_IF_EMPTY) and \\ (not (mode and SENDMSG_ALL_BALANCE)) if mode_not_valid or mode_has_invalid or mode_delete_not_sab: return Err(RESULT_CODE_UNSUPPORTED) skip = not (mode and SENDMSG_IGNORE_ERROR) msg.header.src = my_addr fwd_prices = config.get_fwd_prices(msg.is_masterchain()) compute_wd_fee = fwd_prices.fwd_fee(Cell(msg)) # The message should be either internal message or event. # It is impossible to send external message from the smart-contract. if not ((msg.header is IntMsgInfo) or (msg.header is ExtOutMsgInfo)): return Err(-1) if msg.header is IntMsgInfo: # ===================================== # Internal message # ===================================== msg.header.bounced = False result_value = msg.header.value msg.header.ihr_disabled = True msg.header.ihr_fee = 0 fwd_fee = max(msg.header.fwd_fee, compute_wd_fee) fwd_mine_fee = fwd_prices.mine_fee(fwd_fee) total_fwd_fees = fwd_fee + msg.header.ihr_fee fwd_remain_fee = fwd_fee - fwd_mine_fee if (mode and SENDMSG_ALL_BALANCE): result_value = acc_balance msg.header.value = acc_balance mode = (mode and (not SENDMSG_PAY_FEE_SEPARATELY)) if (mode and SENDMSG_REMAINING_MSG_BALANCE): # Send all the remaining balance of the inbound message result_value += msg_balance if not (mode and SENDMSG_PAY_FEE_SEPARATELY): if result_value &lt; compute_phase_fees: return Err() result_value -= compute_phase_fees msg.header.value = result_value if (mode and SENDMSG_PAY_FEE_SEPARATELY): result_value += total_fwd_fees else: if msg.header.value &lt; total_fwd_fees: return Err() else: msg.header.value -= total_fwd_fees msg.header.fwd_fee = fwd_remain_fee else: # ===================================== # Event # ===================================== fwd_mine_fee = compute_fwd_fee total_fwd_fees = compute_fwd_fee result_value = compute_fwd_fee if acc_balance &lt; result_value: return Err(RESULT_CODE_NOT_ENOUGH_GRAMS) if (mode and SENDMSG_DELETE_IF_EMPTY) and \\ (mode and SENDMSG_ALL_BALANCE) and \\ (acc_balance + reserved_value == 0): account_deleted = True if total_fwd_fees != 0: phase.total_fwd_fees += total_fed_fees if fwd_mine_fee != 0: phase.total_action_fees += fwd_mine_fee phase.tot_msg_size.append(Cell(msg)) if phase.tot_msg_size.bits() &gt; MAX_MSG_BITS or \\ phase.tot_msg_size.cells() &gt; MAX_MSG_CELLS: return Err(RESULT_CODE_INVALID_BALANCE) if mode and (SENDMSG_ALL_BALANCE or SENDMSG_REMAINING_MSG_BALANCE): msg_balance = 0 return Ok(result_value)  "},{"title":"ReserveCurrency Action Handler​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#reservecurrency-action-handler","content":"ReserveCurrency action handler is responsible for managing the reserve coins. Input: mode — Reserve flags for the reserve action, has type Uintval — amount of coins to be reserved, has type Uintorig_acc_balance — account balance after the deduction of the storage fee and the debt, if any, has type Uintacc_remaining_balance — amount of coins left on the balance after the reserve, has type Uint Output: On success, returnsOk(reserved) value, such that: reserved denotes the amount of coins being reserved for the account On failure, returns Err(result_code), such that: result_code Modifies: acc_remaining_balance — remaining account balance after the reserve amount being withheld def reserve_action_handler(mode, val, orig_acc_balance, acc_remaining_balance): if mode and (not RESERVE_VALID_MODES): return Err(RESULT_CODE_UNKNOWN_OR_INVALID_ACTION) reserved = 0 if mode and RESERVE_PLUS_ORIG: if mode and RESERVE_REVERSE: reserved = orig_acc_balance if reserved &lt; val: return Err(RESULT_CODE_UNSUPPORTED) reserved -= val else: reserved = val reserved += orig_acc_balance else: if mode and RESERVE_REVERSE: return Err(RESULT_CODE_UNKNOWN_OR_INVALID_ACTION) reserved = val if mode and RESERVE_IGNORE_ERROR: reserved = min(reserved, acc_remaining_balance) remaining = acc_remaining_balance if remaining &lt; reserved: return Err(RESULT_CODE_NOT_ENOUGH_GRAMS) remaining -= reserved remaining, acc_remaining_balance = acc_remaining_balance, remaining if mode and RESERVE_ALL_BUT: reserved, acc_remaining_balance = acc_remaining_balance, reserved return Ok(reserved)  "},{"title":"Bounce Phase​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#bounce-phase","content":"If error happens on the previous phases, the bounce phase takes place. Input: remaining_msg_balance — message balance after all previous phases executed, has type Uintacc_balance — remaining account balance after all previous phases executed, has type Uintcompute_phase_fees — the fees of the compute phase, has type Uintmsg — message being processed, has type Messagetr — transaction object, has type Transaction Output: On success, returns Ok(TrBouncePhase, bounce_message), such that: TrBouncePhase is a Bounce Phase Descriptorbounce_message is a bounce message to be included into the out_msgs queue On error, returns /ExecutorError.TrExecutorError/ Modifies: tr — adds the bounce message delivery fee to the total NOTE: Function get_fwd_prices() was defined here. def bounce_phase(remaining_msg_balance, acc_balance, compute_phase_fees, msg, tr): header = msg.header if not header.bounce: return ExecutorError.TrExecutorError() header2 = header.clone() header2.src, header2.dst = header.dst, header.src storage = StorageUsedShort() fwd_prices = config.get_fwd_prices(msg.is_masterchain) fwd_full_fees = fwd_prices.fwd_fee(Cell()) fwd_mine_fees = fwd_prices.mine_fee(fwd_full_fees) fwd_fees = fwd_full_fees - fwd_mine_fees if remaining_msg_balance &lt; fwd_full_fees + compute_phase_fees: return Ok(TrBouncePhase.no_funds, None) acc_balance -= remaining_msg_balance remaining_msg_balance -= fwd_full_fees remaining_msg_balance -= compute_phase_fees header2.ihr_disabled = True header2.bounce = False header2.bounced = True header2.ihr_fee = 0 header2.fwd_fee = fwd_fees header2.value = remaining_msg_balance bounce_msg = Message.with_header(header2) if config.has_capability(GlobalCapabilities.CapBounceMsgBody): body = msg.body.clone() body.shrink_data(0..256) # leave only 256 bits of the original body bounce_msg.body = body tr.total_fees += fwd_mine_fees return Ok(TrBouncePhase.ok(storage, fwd_mine_fees, fwd_fees), bounce_msg)  "},{"title":"Functional Properties​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#functional-properties","content":"In this section, we define the main risks of malfunction in the module, and define several higher-level properties that should hold for the module to mitigate those risks. "},{"title":"Risks​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#risks","content":"We define a risk as a hazard event causing a significant loss for the end user. We distinguish the following types of risks. Financial Risks​ The Transaction Executor is the only place in the Node that is responsible for changing the account balance. Hence, any errors in related operations lead to tokens loss for the user. We identify the following financial risks for the module: Incorrect storage, delivery or gas fees calculation logicIncorrect message value processing logicIncorrect SendMsg, ReserveCoins actions processing logic Behavioral Risks​ Everscale blockchain praises the distributed programming paradigm in application development. It means that instead of producing huge smart-contract monoliths, it is encouraged to separate the system into many manageable smart-contracts that communicate with each other by means of message passing. The message passing scheme used in a system induces some protocol. If message passing breaks in an unexpected way, the whole protocol may stall, potentially leading to global system deadlocks. It is of utter importance to guarantee that all produced correct messages will be eventually delivered to the destination account. The delivery process is complicated and rely on several node components. Here, we identify risks related to the Transaction Executor part of it: Successful SendMsg action does not lead to creation of a corresponding messageGenerated messages do not occur in the Out Message queueMessage delivery order gets brokenA bounce message does not get generated as expected "},{"title":"Assumptions​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#assumptions","content":"All the properties formulated with the following assumptions in mind: We consider only ordinary accounts, not system (special) accounts. For the latter, the properties might look different. "},{"title":"System Properties​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#system-properties","content":"System properties are high-level general statements on the system behavior that the Transaction Executor should obey to. A subset of those statements related to mitigating the main risks, identified in the previous section. Fees​ FEE1 — Gas fees for the computation equal the amount calculated using the algorithm calc_gas_fee.FEE2 — Storage fees for an account equal the amount calculated using the algorithm calc_storage_fee.FEE3 — Forwarding fees are calculated according to the algorithm message_passing_fees .FEE4 — During the message execution process, all type of fees get deducted only once for an account. Message Processing​ MSG1 — The message coins get credited to the account balance before executing a smart-contract logic.MSG2 — Messages delivery order between the current account a1a_1a1​ and some other account a2a_2a2​does not depend on messages sent from a1a_1a1​ to some other account a3a_3a3​, when a2≠a3a_2 \\neq a_3a2​=a3​. Credit Phase Processing​ CRD1 — If the inbound message is external, the credit phase does not get executed.CRD2 — If the inbound message is internal, the account's balance get credited with the message value minus the account debt, if any. Storage Phase Processing​ STR1 — If there is not enough funds to cover the storage phase fee on the account's balance, and if the account is in the Active status, then the account gets a debt storing in the due_payment field of the account. If the debt value exceeds the freeze_due_limit value, the account is switched into a frozen status. If the debt exceeds the delete_due_limit value, the account gets deleted. Compute Phase Processing​ CMP1 — If the Compute Phase fails, the execution of a message is aborted. The bounce message is not created in this case.CMP2 — After the Compute Phase, the account's balance gets decreased exactly on the amount of consumed gas. Action Phase Processing​ ACT1 — Each successful SendMsg action leads to creation of a message.ACT2 — Successfully created message is added into the out queue exactly once.ACT3 — If the action phase fails and the incoming message has the bounce flag set, then a single bounce message is generated and put into the out queue. Bounce Phase Processing​ BNC1 — The bounce message is generated only if and only if all of the following conditions hold: 1) The incoming message is an internal message 2) The incoming message has the bounce flag set 3) During the message processing, the action phase was executed, but failed 4) After the failed action phase, there is enough funds left on the incoming message balance to cover the bounce message processing2. BNC2 — A bounce message attach all the original message value minus the storage, gas and delivery fees. "},{"title":"Footnotes​","type":1,"pageTitle":"Transaction executor","url":"/arch/executor#footnotes","content":"Well, at least, until the part of the chain residing the transaction gets cut-off to reduce the disk space consumption.↩See the definition of COMMIT TVM instruction.↩ "},{"title":"Reliable External Messaging Protocol","type":0,"sectionRef":"#","url":"/arch/networking/remp","content":"","keywords":""},{"title":"Introduction​","type":1,"pageTitle":"Reliable External Messaging Protocol","url":"/arch/networking/remp#introduction","content":"Reliable External Messaging Protocol (REMP) is a protocol that adds some additional guarantees/features for external messages processing: 1. Replay protection If a message is processed and added into an accepted block, then the same message (that is, the message with the same hash) will not be collated for some time period. If the message has some expiration time (corresponding to the time period), then this effectively makes efficient replay protection. 2. No messages are lost You only need to send the message once. If there will be a possibility to accept it and add it to a block, then it will be done. Message loss may occur only for blockchain overloading reasons. 3. One can trace the message processing. There are several checkpoints on the message processing path (when validators received the message, when message was added to a block, when the block was finalized, etc). Upon reaching certain checkpoints one can predict that the message will be successfully processed with a high accuracy - most messages can be considered to be processed when validators acknowledge that they were received (this happens in 100-200 ms; after that it’s highly unlikely that the message is declined). Thus, depending on the message importance one may trade efficiency for reliability in the software, choosing not to trace further processing results. On the other hand, if a transaction is really important, then you can wait till the block with the transaction result is issued. "},{"title":"General description​","type":1,"pageTitle":"Reliable External Messaging Protocol","url":"/arch/networking/remp#general-description","content":"REMP is a set of protocols and data structures that are designed to keep trace of incoming external messages. Message flow in REMP can be seen on the following diagram:  A message from the user application is sent to a REMP Client (e.g., it could be some Full Node; also the user application may implement the necessary protocol by itself). The client in turn sends the message to its shard validators. The validators, aside from processing the message, gather info about message validation status and send it back to the REMP Client and then further to the user (such messages are called “receipts”). "},{"title":"REMP Catchain​","type":1,"pageTitle":"Reliable External Messaging Protocol","url":"/arch/networking/remp#remp-catchain","content":"The validators exchange info between them using a special REMP Catchain protocol. Each validator Catchain session (protocol/data structures used for controlling consensus on block candidates) is accompanied by a REMP Catchain session (Reliable Message Queue, RMQ), which is used to store incoming messages. When validator Catchain sessions are started/stopped/split/merged/etc, the same happens with related REMP Catchain session. When the validator session expires, all messages being processed are transferred to the next REMP Catchain session. There is some significant difference between validation and REMP Catchain sessions. Validator Catchain session is shared among validators that are currently validating the given shard. REMP Catchain session is shared among validators that are currently validating the given shard and validators that validated this shard in the previous session. So number of participants in REMP Catchain session is about two times bigger than in validator Catchain session. The reason for this is the necessity to pass RMQ data between sessions with respect to practical network bandwidth. So each newly created REMP Catchain session will contain validators from previous validator Catchain session that will provide reliable RMQ data handover for validators from current validator Catchain session. "},{"title":"REMP Client​","type":1,"pageTitle":"Reliable External Messaging Protocol","url":"/arch/networking/remp#remp-client","content":"Besides the REMP Catchain protocol, there is a communication between outer world of blockchain and shard validators that is provided by REMP Client protocol. REMP Client can be run as a part of some blockchain node and provides following: reception of external messages from outer worldpre-evaluation of received message against current state of destination shard (to filter out invalid messages)transfer of messages to each current validator of given shard to include it into their REMP Catchainreception of status updates from shard validators for all previously transferred messagesreport of messages status to outer world If at least 1/3 + 1 of validators receive the message via REMP Client protocol, then at least one “good” validator processes it — and resends it to all other validators via REMP Catchain session. Thus it is not necessary to send the message to all validators in shard. "},{"title":"Message life cycle​","type":1,"pageTitle":"Reliable External Messaging Protocol","url":"/arch/networking/remp#message-life-cycle","content":"The message lifetime is counted according to master catchain sequence numbers: if a message is received when master catchain N was in action, then it becomes obsolete at master catchain N+2. Such message is not copied to new catchains anymore. Each validator tries to collate the message until its collator rejects the attempt. So, the message processing may result in three outcomes: accepted by collator - and then validated - and included into shard block - and the block is included into masterchain (accept, finalized)rejected by fullnode before processing - or by all collators (reject)timeout - its collation/validation attempts were fruitless, and the message became obsolete. This gives hard replay protection guarantees (if message has expiration mechanism included — making the message obsolete before two catchains are switched), and soft processing guarantees (message collation/validation attempts may be fruitless if the message is wrong, or if the blockchain is overloaded). "},{"title":"Replay protection in more detail​","type":1,"pageTitle":"Reliable External Messaging Protocol","url":"/arch/networking/remp#replay-protection-in-more-detail","content":"Traditional approaches to replay protection in Everscale usually require some mutable structures in the contract: sequence counter (updated each time the message is sent), previous messages’ hash table, or something similar. REMP keeps track of all messages accepted by the Blockchain and avoids repeated collation, even if the message is sent several times — thus REMP replay protection mechanism is similar to hash table method, although it is transparent for user and does not consume any gas. A bit more detail about the mechanism. All messages from accepted blocks are parsed and their id’s are kept in Message Cache on each node (think of this as about some extended Shard State).Collator requests the Cache for each message proposed for collation (and, of course, messages’ collation is refused if they were already included into some accepted block).After each session all old messages (that is, messages which were added two master sessions earlier or more) are removed from the Cache. Thus, expiration time must be specified in messages, so that the messages removed from the Cache should be already invalid by that moment. And a bit more about expiration time fine-tuning. The session lifetime is specified in Blockchain config parameter 28 (field mc_catchain_lifetime), traditional value for this config is 250 seconds, current value should be checked in network configuration.The message is tracked by Remp during two consecutive master sessions — the session the message arrived, and the next one (exception: when master sessions are shorter than specified in config, then the message is remembered longer, until total session lifetime exceeds twice of mc_catchain_lifetime; such shorter sessions can happen, for example, when a keyblock is issued).Sessions switch according to their own schedule. So, it is quite possible that the message arrives just seconds before the first session ends. As shown on the diagram above, Message 1 arrives in the beginning of the first session, and Message 3 arrives just moments before session switching. So, actual time of message tracking in Remp is between mc_catchain_lifetime and mc_catchain_lifteme*2, and expiration time should not exceed mc_catchain_lifetimeOn another hand, according to testing on real networks, it is unreasonable to have expiration time smaller than 40 seconds (or a minute), since a message may expire too soon, before it receives a second chance for collation. The message can easily miss its first collation due to blockchain overfilling, session switching, etc. "},{"title":"Message statuses​","type":1,"pageTitle":"Reliable External Messaging Protocol","url":"/arch/networking/remp#message-statuses","content":"During validation, a message processing passes through several stages (that is, changes some statuses), and validator sends receipts about that. Some of them are given on the diagram below (as inscriptions near arrows). The statuses that are “final” (that is, nothing is happening after it) are shown in blue.  Since message is validated by several validators simultaneously, the statuses are reported by the validators separately, so some of them can be reported several times. E.g., one validator may decide that the message should be rejected, but other validators may decide just the opposite — so the user may receive “Rejected” and then “Finalized” for its message. "},{"title":"Performance​","type":1,"pageTitle":"Reliable External Messaging Protocol","url":"/arch/networking/remp#performance","content":"REMP performance toll may be split into network and processor performance toll. Processor performance influence is very limited (and may even reduce processor overloading), since a message is not processed by REMP, it only keeps track of messages. Moreover, replay protection may even reduce processor load, since messages are rejected before collation if they are processed already (thus removing necessity to execute replay protection code in contracts) Network performance, on another hand, is burdened by Catchains (remember, each Catchain is doubled), which can be expensive from network load perspective. The real performance toll depends on the contracts’ details, and needs measurement in real-life conditions. "},{"title":"Data structures & REMP-SDK interop​","type":1,"pageTitle":"Reliable External Messaging Protocol","url":"/arch/networking/remp#data-structures--remp-sdk-interop","content":"REMP message flow "},{"title":"Send REMP message​","type":1,"pageTitle":"Reliable External Messaging Protocol","url":"/arch/networking/remp#send-remp-message","content":"External messages are sent the same way, as before. Use GraphQL API's postRequests mutation for it. See this guide for more info "},{"title":"Receive message status​","type":1,"pageTitle":"Reliable External Messaging Protocol","url":"/arch/networking/remp#receive-message-status","content":"REMP message statuses While REMP message is being processed, it passes through multiple phases (that is, REMP messages have different statuses). Message can be in some statuses multiple times. Possible statuses: SentToValidators - message was read from kafka and successfully sent to validatorsRejectedByNode - message was rejected by full node before sending to validators; it’s a final decision, message will not be resent again.PutIntoQueue - message was received by validator and included into special REMP catchain — waiting for collationRejectedByCollator - message was rejected by collator, and will not be tried again by this particular validator. All validators must reject the message before it is finally rejected. A message, rejected by one node, may be successfully included into a block by another node later (reasons: bugs in software, change of state — e.g. money suddenly arrived to the account, etc)IncludedIntoBlock - message was successfully included into block candidate.IncludedIntoAcceptedBlock - the block candidate was accepted by shard's validators.Finalized - ****the block candidate's hash (or its descendant) was committed into master chain. Each stage contains message_id - root hash of message boctimestamp - unix time in millisecondssource id - who generated information about stage (for example it is full node for SentToValidators stage, or collator for RejectedByCollator stage)signature - record about the stage is signed by sourcespecial fields (see below) All possible REMP massage stages with all data fields: { { &quot;kind&quot;: &quot;SentToValidators&quot;, &quot;message_id&quot;: &quot;16923245c4bd57762330e454926a81dcb45626b433121c51804075b3cc26984e&quot;, // 32 bytes hex &quot;timestamp&quot;: 1632750383000, // 64 bits, unix time in milliseconds &quot;source_id&quot;: &quot;1692345dc4bd57762330e454926a81dcb45626b433121c51804075b3cc26984e&quot;, // 32 bytes hex &quot;signature&quot;: &quot;1692345dc4bd57762330e454926a81dcb45626b433121c51804075b3cc26984e&quot;, // 32 bytes hex, &quot;sent_to&quot;: 4, // number of validators message was successfully sent to &quot;total_validators&quot;: 5 }, { &quot;kind&quot;: &quot;RejectedByFullnode&quot;, &quot;message_id&quot;: &quot;16923245c4bd57762330e454926a81dcb45626b433121c51804075b3cc26984e&quot;, &quot;timestamp&quot;: 1632750383000, &quot;source_id&quot;: &quot;1692345dc4bd57762330e454926a81dcb45626b433121c51804075b3cc26984e&quot;, &quot;signature&quot;: &quot;1692345dc4bd57762330e454926a81dcb45626b433121c51804075b3cc26984e&quot;, &quot;error&quot;: &quot;Can't deserialize message&quot; }, { &quot;kind&quot;: &quot;PutIntoQueue&quot;, &quot;message_id&quot;: &quot;16923245c4bd57762330e454926a81dcb45626b433121c51804075b3cc26984e&quot;, &quot;timestamp&quot;: 1632750383000, &quot;source_id&quot;: &quot;1692345dc4bd57762330e454926a81dcb45626b433121c51804075b3cc26984e&quot;, &quot;signature&quot;: &quot;1692345dc4bd57762330e454926a81dcb45626b433121c51804075b3cc26984e&quot;, }, { &quot;kind&quot;: &quot;RejectedByCollator&quot;, &quot;message_id&quot;: &quot;16923245c4bd57762330e454926a81dcb45626b433121c51804075b3cc26984e&quot;, &quot;timestamp&quot;: 1632750383000, &quot;source_id&quot;: &quot;1692345dc4bd57762330e454926a81dcb45626b433121c51804075b3cc26984e&quot;, &quot;signature&quot;: &quot;1692345dc4bd57762330e454926a81dcb45626b433121c51804075b3cc26984e&quot;, &quot;error&quot;: &quot;Contract rejected message with error code 52&quot; }, { &quot;kind&quot;: &quot;IncludedIntoBlock&quot;, &quot;message_id&quot;: &quot;16923245c4bd57762330e454926a81dcb45626b433121c51804075b3cc26984e&quot;, &quot;timestamp&quot;: 1632750383000, &quot;source_id&quot;: &quot;1692345dc4bd57762330e454926a81dcb45626b433121c51804075b3cc26984e&quot;, &quot;signature&quot;: &quot;1692345dc4bd57762330e454926a81dcb45626b433121c51804075b3cc26984e&quot;, // shard block the message was included to &quot;block_id&quot;: &quot;1692345dc4bd57762330e454926a81dcb45626b433121c51804075b3cc26984e&quot;, &quot;block_file_hash&quot;: &quot;00a2345dc4bd57762330e454926a81dcb45626b433121c51804075b3cc26984e&quot;, &quot;block_seqno&quot;: 123, &quot;shard&quot;: &quot;3800000000000000&quot;, &quot;wc&quot;: 0, }, { &quot;kind&quot;: &quot;IncludedIntoAcceptedBlock&quot;, &quot;message_id&quot;: &quot;16923245c4bd57762330e454926a81dcb45626b433121c51804075b3cc26984e&quot;, &quot;timestamp&quot;: 1632750383000, &quot;source_id&quot;: &quot;1692345dc4bd57762330e454926a81dcb45626b433121c51804075b3cc26984e&quot;, &quot;signature&quot;: &quot;1692345dc4bd57762330e454926a81dcb45626b433121c51804075b3cc26984e&quot;, // shard block the message was included to &quot;block_id&quot;: &quot;1692345dc4bd57762330e454926a81dcb45626b433121c51804075b3cc26984e&quot;, &quot;block_file_hash&quot;: &quot;00a2345dc4bd57762330e454926a81dcb45626b433121c51804075b3cc26984e&quot;, &quot;block_seqno&quot;: 123, &quot;shard&quot;: &quot;3800000000000000&quot;, &quot;wc&quot;: 0, }, { &quot;kind&quot;: &quot;Finalized&quot;, &quot;message_id&quot;: &quot;16923245c4bd57762330e454926a81dcb45626b433121c51804075b3cc26984e&quot;, &quot;timestamp&quot;: 1632750383000, // 64 bits &quot;source_id&quot;: &quot;1692345dc4bd57762330e454926a81dcb45626b433121c51804075b3cc26984e&quot;, &quot;signature&quot;: &quot;1692345dc4bd57762330e454926a81dcb45626b433121c51804075b3cc26984e&quot;, // master block where shard block with the message is commited to &quot;mc_block_id&quot;: &quot;1692345dc4bd57762330e454926a81dcb45626b433121c51804075b3cc26984e&quot;, &quot;block_file_hash&quot;: &quot;33b2345dc4bd57762330e454926a81dcb45626b433121c51804075b3cc269800&quot;, &quot;mc_block_seqno&quot;: 234, // shard block the message was included to &quot;block_id&quot;: &quot;1692345dc4bd57762330e454926a81dcb45626b433121c51804075b3cc26984e&quot;, &quot;block_file_hash&quot;: &quot;00a2345dc4bd57762330e454926a81dcb45626b433121c51804075b3cc26984e&quot;, &quot;block_seqno&quot;: 123, &quot;shard&quot;: &quot;3800000000000000&quot;, &quot;wc&quot;: 0, } }  You can receive REMP receipts via rempReceipts GraphQL subscription. See REMP subscription guide for more info. subscription{ rempReceipts(messageId: &quot;082a5c2ab5b68b0ef9b8ced4fa865933ab19603f5171ec1190f3f45943214de0&quot;){ messageId timestamp json kind } }  "},{"title":"Other statuses​","type":1,"pageTitle":"Reliable External Messaging Protocol","url":"/arch/networking/remp#other-statuses","content":"The statuses listed above are the most common. However, in REMP, core statuses are pairs of two parameters: ”level” - the node component that processed the message and “status” - the outcome of the message processing. There are also some out-of-the-order statuses. In JSON, both level and status are combined into a “kind” field. The table below shows how each level and status mixes are called in JSON. The main statuses listed above are marked green, while the statuses you can get in special situations are marked orange. The empty cell means you will never get such a mix of parameters. ↓ status | level →\tFull node\tQuenue\tCollator\tShard chain\tMaster chainAccepted IncludedIntoBlock(optimistic finality).\tIncludedIntoAcceptedBlock\tFinalized !!! +5-25s Ignored IgnoredByQueue\tIgnoredByCollator\tIgnoredByShardchain\tIgnoredByMasterchain Rejected\tRejectedByFullnode +0s RejectedByCollator\tRejectedbyShardchain SentToValidators\tSentToValidators New PutIntoQueue Duplicate Duplicate Timeout Timeout + 4 min  green status means right sequence of eventsorange status means non critical errors or warningsred status means critical error - the message will never be included into blockchainblue status means successful - the message was included into blockchainOptimistic finality is IncludedIntoBlock. When a message is sent via REMP, it passes through several software components, operating on different computers. Each component has a name (a level of message processing), each level has a number assigned. Full node - level 0 - messages are accepted by the full node and checked there.Queue - level 1 - messages are sent to validator nodes. Seven or more validator nodes per thread, depending on the blockchain config. Accepted by the Queue.Collator - level 2 - messages are added to block candidates - collated. Each validator node has its own collator component. Accepted by the collator.Shardchain - level 3 - block candidates are validated. A node collated a block candidate and reports about its success. A successfully validated candidate becomes a shardblock.Masterchain - level 4 - the shard blocks are added to the masterchain.  Due to byzantine nature of the blockchain algorithms, Queue, Collator and Shardchain stages are executed in parallel on each validator node separately, and each validator node reports about its message copy success on its own. That is, some statuses (from Fullnode level and Masterchain level) are returned once, and all other statuses (from Queue, Collator and Shardchain levels) are returned in many (7 or more, depending on the blockchain config) copies. Unless a message is failed on all its parallel ways, one cannot consider that the message is failed. "},{"title":"Statuses - general picture​","type":1,"pageTitle":"Reliable External Messaging Protocol","url":"/arch/networking/remp#statuses---general-picture","content":"Almost all statuses may be separated into three categories: Accepted, Rejected and Ignored. Each “Accepted” means that the message is processed and transferred to the next component. It adds 1 to the level. Each “Ignored” means that the message was lost (didn’t fit into the block, etc), so it returns the message to the Queue level. Each ”Rejected” means that the message will not be processed further by the particular node. Also, there are some additional statuses not fitting into the general scheme: “Duplicate” returns/keeps the message at the Queue level. “New” (”PutIntoQueue”) is sent when the message first enters the Queue level. “SentToValidators” may be thought of as Accepted for level 0. Full node level and Finalized status originated from Full node (one instance). All other statuses are multithread. One thread per thread validator, usually seven instances. Each “New” status will be followed by a series of other statuses, with “Reject”/”Timeout” at the end in case of failure. "},{"title":"The main sequence - the message is sent and accepted​","type":1,"pageTitle":"Reliable External Messaging Protocol","url":"/arch/networking/remp#the-main-sequence---the-message-is-sent-and-accepted","content":"The message is accepted at all levels: Full node, Queue, Collator, Shardchain, and Masterchain. “SentToValidators” (Accepted by the Full node) → “PutIntoQueue” (New) → (Accepted by the Queue — internal status, not sent from the full nodes ) → “IncludedIntoBlock” (Accepted by a Collator) → “IncudedIntoAcceptedBlock” (Accepted by Shardchain) → “Finalized” (Accepted by the Masterchain). "},{"title":"Rejection sequences​","type":1,"pageTitle":"Reliable External Messaging Protocol","url":"/arch/networking/remp#rejection-sequences","content":"A message may be rejected by the full node before processing. For instance, when it’s incompatible with its current state. “RejectedByFullnode” No more messages from that full node will follow. It’s a final state.A message may be rejected by a collator. For instance, in case the message becomes incompatible with the new state. “RejectedByCollator” It’s a final state for each validator from the validator set. However, other validators may validate the message. One should wait for 2/3 rejects for a highly probable reject and for all rejects for a guaranteed reject. After that, nobody will try to collate the message.Messages may be repeatedly ignored until a timeout happens (after 4 mins) “Timeout” It’s a final state for each validator from the validator set. However, other validators may manage to successfully include the message in the block. One should wait for all timeouts. All validators must reply with timeout. In 2 and 3 cases (rejects/timeouts), one should consider that all “New” messages must be answered with a corresponding “Reject” or “Timeout”. Unless you have a pair for each “New” message, you cannot be sure that the message is finally declined. "},{"title":"Possible flow variations​","type":1,"pageTitle":"Reliable External Messaging Protocol","url":"/arch/networking/remp#possible-flow-variations","content":"A message may be ignored by a Collator, Shardchain or Masterchain. This means that the message didn’t fit into the block, the block didn’t fit into the masterchain, etc. The message will then return to the collator queue and will be included into the next available block candidate. A message may be switched between Collator and Queue levels several times: SentToValidators, New, PutIntoQueue, IncludedIntoBlock, PutIntoQueue, IncludedIntoBlock, IncudedIntoAcceptedBlock, Finalized. It also may be switched in more elaborate ways, returning to Queue level several times — and finally either Finalizing or falling into Timeout/Reject. "},{"title":"Message statuses in kafka​","type":1,"pageTitle":"Reliable External Messaging Protocol","url":"/arch/networking/remp#message-statuses-in-kafka","content":"Each status is produced into a kafka topic. The key is a message ID while value is a json with one status. "},{"title":"Checking the signature of the status​","type":1,"pageTitle":"Reliable External Messaging Protocol","url":"/arch/networking/remp#checking-the-signature-of-the-status","content":"To check a signature status, you need to convert it into binary format and then check your signature using a key you can get from the validator set. The full node’s key will go another way (it will be described later). // parse json let json: serde_json::Value = serde_json::from_slice(receipt)?; // convert json -&gt; binary struct let (receipt, signature) = ton_block_json::parse_remp_status( json.as_object().ok_or_else(|| error!(&quot;Can't parse remp status json as a map&quot;))? )?; // serialize binary struct let receipt_bytes = adnl::common::serialize(&amp;receipt)?; // find pub key in validator set // validator_set: ton_block::ValidatorSet let mut pub_key = None; for v in validator_set.list() { let k = adnl::common::KeyOption::from_type_and_public_key( KeyOption::KEY_ED25519, v.public_key.key_bytes()); if k.id().data() == receipt.source_id().as_slice() { pub_key = Some(k); break; } } // check signature if let Some(pub_key) = pub_key { pub_key.verify(&amp;receipt_bytes, &amp;signature)?; }  "},{"title":"RLDP","type":0,"sectionRef":"#","url":"/arch/networking/rldp","content":"","keywords":""},{"title":"Protocol​","type":1,"pageTitle":"RLDP","url":"/arch/networking/rldp#protocol","content":"To exchange data, RLDP uses the following TL structures: fec.raptorQ data_size:int symbol_size:int symbols_count:int = fec.Type; fec.roundRobin data_size:int symbol_size:int symbols_count:int = fec.Type; fec.online data_size:int symbol_size:int symbols_count:int = fec.Type; rldp.messagePart transfer_id:int256 fec_type:fec.Type part:int total_size:long seqno:int data:bytes = rldp.MessagePart; rldp.confirm transfer_id:int256 part:int seqno:int = rldp.MessagePart; rldp.complete transfer_id:int256 part:int = rldp.MessagePart; rldp.message id:int256 data:bytes = rldp.Message; rldp.query query_id:int256 max_answer_size:long timeout:int data:bytes = rldp.Message; rldp.answer query_id:int256 data:bytes = rldp.Message;  The serialized structure is wrapped in an adsl.message.custom TL schema and sent over ADNL UDP. The big data is transmitted via transfers. A random transfer_id is generated while the data itself is processed by the FEC algorithm. The received pieces are wrapped in the rldp.MessagePart structure and sent to the recipient until the recipient returns rldp.complete. When the recipient collects the pieces of rldp.MessagePart needed to assemble a complete message the following has to be done: connecting them all together, decoding them using FEC and deserializing the resulting byte array into one of the rldp.query or rldp.answer structures - depending on the type of TL ID prefix. "},{"title":"FEC​","type":1,"pageTitle":"RLDP","url":"/arch/networking/rldp#fec","content":"Valid Forward Error Correction algorithms to use with RLDP are Round Robin, Online, and Raptor. Currently, Raptor is used for data exchange. Raptor​ The essence of RaptorQ is that the data is divided into so-called symbols - blocks of the same, predetermined size.4 Blocks, in turn, serve to create matrices, to which discrete mathematical operations are applied. This allows us to create an almost infinite number of characters from the same data. All characters are mixed, and, thanks to this, it is possible to recover lost packets without requesting additional data from the server. This is accomplished by sending fewer packets than it would be if we were to send the same pieces in the cycle. The generated symbols are sent to the recipient until he says that all data has been received and restored by applying the same discrete operations. "},{"title":"RLDP-HTTP​","type":1,"pageTitle":"RLDP","url":"/arch/networking/rldp#rldp-http","content":"HTTP (wrapped in RLDP) is used to interact with Everscale sites. The hoster places his site on any HTTP web server and raises the rldp-http proxy next to it. All requests from the Everscale network come via the RLDP protocol to the proxy, and the proxy already reassembles the request into regular HTTP and calls the web server locally. Tip The user on his side locally (ideally) raises a proxy, for example Tonutils Proxy, and uses .ton, all traffic is wrapped in reverse order, requests go to the local proxy, and it sends them via RLDP to the remote TON site. HTTP inside RLDP is implemented using TL structures: http.header name:string value:string = http.Header; http.payloadPart data:bytes trailer:(vector http.header) last:Bool = http.PayloadPart; http.response http_version:string status_code:int reason:string headers:(vector http.header) no_payload:Bool = http.Response; http.request id:int256 method:string url:string http_version:string headers:(vector http.header) = http.Response; http.getNextPayloadPart id:int256 seqno:int max_chunk_size:int = http.PayloadPart;  "},{"title":"TL","type":0,"sectionRef":"#","url":"/arch/networking/tl","content":"","keywords":""},{"title":"Encoding bytes in TL​","type":1,"pageTitle":"TL","url":"/arch/networking/tl#encoding-bytes-in-tl","content":"To encode an array of bytes, we first need to determine its size. If it is less than 254 bytes, then encoding with 1 byte is used as size. If it is larger, then 0xFE is written as the first byte, as an indicator of a large array, and then 3 bytes of size follow it. For example, we encode an array [0xAA, 0xBB], its size is 2. We use 1 byte of size and then we write the data ourselves, we get [0x02, 0xAA, 0xBB]. That's it! However, we see that the final size is 3 and not a multiple of 4 bytes, then we need to add 1 byte of padding so that there is 4. We get: [0x02, 0xAA, 0xBB, 0x00]. If we need to encode an array whose size is, for example, 396, we proceed as follows: 396 &gt;= 254, which means we use 3 bytes to encode the size and 1 byte of the increased size indicator, we get: [0xFE, 0x8C, 0x01, 0x00, array bytes], 396+4 = 400, which is a multiple of 4 and does not need to be adjusted. "},{"title":"Non-obvious rules of serialization​","type":1,"pageTitle":"TL","url":"/arch/networking/tl#non-obvious-rules-of-serialization","content":"Often, a prefix of 4 bytes is written before the scheme itself - its ID. The schema ID is a CRC32 with an IEEE table from the schema text, while characters such as ; and brackets () are removed from the text. Serialization of a scheme with an ID prefix is called boxed. This allows the parser to determine which scheme is in front of it if several options are possible. How to determine whether to serialize as boxed or not? If our schema is part of another schema, then we need to see how the field type is specified. If it is specified explicitly, then we serialize without a prefix. If not explicitly (there are many such types), then we need to serialize as boxed. Example: pub.unenc data:bytes = PublicKey; pub.ed25519 key:int256 = PublicKey; pub.aes key:int256 = PublicKey; pub.overlay name:bytes = PublicKey;  We have such types. If PublicKey is specified in the schema, for example, adnl.node id:PublicKey addr_list:adnl.AddressList = adnl.Node, then it is not explicitly specified and we need to serialize with the ID prefix (boxed). And if it were specified like this: adsl.node id:pub.ed25519 addr_list:all.address List = add.Node, then it would be explicit, and the prefix would not be needed. "},{"title":"Smart Contract Security","type":0,"sectionRef":"#","url":"/arch/security","content":"","keywords":""},{"title":"Replay Attack Protection​","type":1,"pageTitle":"Smart Contract Security","url":"/arch/security#replay-attack-protection","content":"All external messages must be protected against replay attacks. Otherwise, a malicious party can resend an external message obtained from blockchain and repeat a transaction for a smart contract. For example, a hacker can repeat a Token transfer and bring an account balance to zero. For internal messages the risk of replay attacks is irrelevant, as they only can be generated inside blockchain by other contracts. "},{"title":"Implementation Options​","type":1,"pageTitle":"Smart Contract Security","url":"/arch/security#implementation-options","content":"Different approaches to implementing replay attack protection exist. None of them is a silver bullet, but there are several indicators applied to compare and evaluate them: Gas consumptionStorage feesRace conditionUsability "},{"title":"Sequence number​","type":1,"pageTitle":"Smart Contract Security","url":"/arch/security#sequence-number","content":"This is a very simple protection option. It implies that each protected contract stores a counter (i.e. 32bit integer) that is initially set to zero. An external message is then accepted by the contract only under condition that it contains a number equal to the current contract counter value. Each time a new message is accepted, the contract counter value is incremented by one. Pros: simple implementation in contractslow gas and storage fees Cons: To get the right sequence number off-chain, a client must request the contract state from blockchain before sending an external message. If the state is large, it can cause a network traffic overheadRace condition issue that arises when there are multiple contract owners who can simultaneously call it. One owner can increment the contract counter value before this counter becomes available to the next ownerLess sensitive issue of a potential counter overflow in the future. In this case the TVM will throw an exception causing the owner to lose access to the contract "},{"title":"Timestamp​","type":1,"pageTitle":"Smart Contract Security","url":"/arch/security#timestamp","content":"Another simple protection option is adding a timestamp to every external message. It can be a 64-bit value in unixtime format. The contract must store the timestamp of the last accepted external message. When a new external message comes, the contract verifies the message timestamp. It must to be bigger than the previous message timestamp and less then now + interval. The interval value is necessary, because now does not stand for the current time, but indicates creation time of the relevant block. The interval can be equal the block generation period or bigger. Pros: Very simple implementationNo need to request account state before sending external messages Cons: Race condition issues remains unresolved as in case of sequence number implementationClient time must be synchronized with blockchain time "},{"title":"Set of accepted messages​","type":1,"pageTitle":"Smart Contract Security","url":"/arch/security#set-of-accepted-messages","content":"Dictionary of randoms This option implies that every external message contains a random value, for example, a 32bit integer. A protected contract, in turn, stores previously used randoms in a dictionary, compares message randoms with it and rejects a message if there is a match detected. Pros: No need to request account state before sending an external messageNo race condition; simultaneous access to contract of multiple parties is supported. Collisions are still possible when multiple clients have the same random, but chances can be minimized. Cons: Consumes a lot of gas for dictionary write/read operations. Note that the gas fee will increase in the futureHigh storage fees for storing dictionary Dictionary of messages with garbage collection This option implies that every external message contains an expire-at integer that defines the time when the message becomes invalid (i.e. expires). The contract, in turn, must store a dictionary with all recently accepted and not expired external messages. The key is a message hash, the value is the relevant expire-at integer. The contract then rejects all messages that are already present in its dictionary. To avoid persistent data increase, a protected contract can delete messages with the expire-at value less than now from its dictionary. Pros: No need to request the account state before sending an external messageNo race condition issues Cons: Harder to implement compared to the above option with a dictionary of randomsHigh gas fees caused by the need to access a dictionaryHigh storage fees, yet these can be reduced by deleting expired messages from the dictionaryGarbage collecting also involves some gas costs "},{"title":"Sessions​","type":1,"pageTitle":"Smart Contract Security","url":"/arch/security#sessions","content":"Before sending requests to contract, a user creates a session with a contract by sending a create_session external message. The message contains a new session ID, its expired-at time and a starting sequence number. The contract stores a session dictionary. After a session is created, the user adds the session_id and the next session sequence number to every external message. For every external message (not create_session) the contract checks that: The message session ID exists in dictionary The message sequence number is equal to the stored session number, and The now value is less then the expired-at value for session If all checks are passed successfully, the contract increments the stored sequence number for the session. In case of failure, the message is rejected. Also, expired sessions require some garbage collection. Pros: No need to request the account state before sending an external messageNo race condition issuesNo collisions Cons: Harder to implement compared to all the options covered aboveHigh gas feesHigh storage feesNeed to use garbage collectingUnsuitable for simple single-user contracts "},{"title":"Conclusion​","type":1,"pageTitle":"Smart Contract Security","url":"/arch/security#conclusion","content":"In EverX, we selected a lightweight and simple replay protection option, it will be implemented in the compiler by default and based on the timestamp approach. It is supposed to work well for single-user contracts, as well as for contracts without heavy race conditions. It is easy to use given that EverX SDK enables inserting a timestamp automatically on the client side. Also, there will be an option to redefine the default protection method by overloading a special contract function. This is how contract developers will be able to implement any protection option they seem fit. "},{"title":"TL-B and BoC","type":0,"sectionRef":"#","url":"/arch/tlb-and-boc","content":"","keywords":""},{"title":"TL-B​","type":1,"pageTitle":"TL-B and BoC","url":"/arch/tlb-and-boc#tl-b","content":"Typed Language - Binary is used to describe the scheme of deserialization of objects to cells. "},{"title":"Scheme​","type":1,"pageTitle":"TL-B and BoC","url":"/arch/tlb-and-boc#scheme","content":"TL-B schemes are comprised of declarations. Each declaration, in turn, describes a constructor for some type. For example, a Bool type may have constructors for true and false values. Please see typical TL-B declarations below: bool_false$0 = Bool; bool_true$1 = Bool; unary_zero$0 = Unary ~0; unary_succ$1 {n:#} x:(Unary ~n) = Unary ~(n + 1); acc_trans#5 account_addr:bits256 transactions:(HashmapAug 64 ^Transaction CurrencyCollection) state_update:^(HASH_UPDATE Account) = AccountBlock;  Each TL-B declaration is comprised of: A constructor name followed by an optional constructor tagA list of both explicit and implicit field definitions separated by whitespaces (&quot; &quot;, &quot;\\n&quot;, etc)= signType name (optionally parametrized)  Example: Two constructors with different binary prefixes for a Bool type. bool_false$0 = Bool; bool_true$1 = Bool;  Constructor​ A constructor is declared via constructor_name[separator,tag]. A constructor_name is comprised of [A-z0-9_] symbols. Normally, snake_case names are used. A constructor name can be followed by a separator. If there is no separator it means that the tag will be calculated automatically as a 32bit CRC32-sum of constructor declarations. If there is a separator, it can take two values: # and $. The first value means that a tag will be given in a hexadecimal form while the second means a binary tag. After both separators, there may be an underscore symbol _ which stands for an empty tag. There is also a special constructor name called anonymous constructor which means that there is only one unnamed constructor with an empty tag for a given type. Please see the table below for possible tag definitions. Constructor\ttag_\tempty tag for anonymous constructor some\tautomatically calculated 32-bit tag some#bba\t12-bit tag equal to 0b101110111010 some$01011\t5-bit tag equal to 0b01011 some#_\tempty tag some$_\tempty tag Please note that pregenerated tags are not usually used. Those explicitly declared are preferred. Field definitions​ Explicit​ Each field definition has the ident: type-expr. ident is an identifier for the name of the field. It is replaced by an underscore _ for anonymous fields. type-expr is the field type. The type provided here is a type expression. It may include simple types or parametrized types with suitable parameters. The identifiers of the previously defined fields of types # (natural numbers) or Type (type of types) may be used as parameters for the parametrized types. There are a few predefined types: # - means an unsigned 32-bit number## N - the same as uintN - means an unsigned N-bit number#&lt;= N - means a number between 0 and N (including both). Such a number is stored in ceil(log2(N+1)) bits.N * Bit - means N-bit slice^Cell - means an arbitrary cell in reference^[ field_definitions ] - means that field definitions are stored in the referenced cellType - stands for arbitrary type (but only presents in implicit definitions). type-expr usually consist of optionally parametrized Type only as: last_trans_lt:uint64 or _:StateInit. Yet, it is possible that type-expr also contains conditions. In that case, type-expr consists of ident, :, condition, ?, type. If a condition, which can refer to previously defined fields, renders to false, the corresponding field is not presented. For instance, prev:n?^(ProofChain n) means that prev field is only presented for objects when n&gt;0. Implicit​ Some fields may be implicit. Their definitions are surrounded by curly brackets. It indicates that the field is not actually present in the serialization. Their value must be deduced from some other data. Usually, the parameters of the type are being serialized. For instance nothing$0 {X:Type} = Maybe X; just$1 {X:Type} value:X = Maybe X;  Some other constructor may define the field var:(Maybe #). In that case, the variable will be serialized either as 1 bit and a serialization of # (uint32) if var is present or as 0 bit if var is absent. That way, Maybe is declared as a C++-like template type for arbitrary type X. However, if Maybe is declared as nothing$0 {X:#} = Maybe X;, that will mean that Maybe is declared for an arbitrary number (not totally arbitrary type X). Type definition​ A type name consists of [A-z0-9_] symbols. By practice, it is a CamelCase name. It can be parametrized by one or more parameters. In some cases, the variables are prefixed by a tilde (~). Basically, it means that, prior to deserialization, the exact value of that variable is not known. It will be computed during deserialization. Let's consider: unary_zero$0 = Unary ~0; unary_succ$1 {n:#} x:(Unary ~n) = Unary ~(n + 1);  In the case when we want to deserialize the Unary ~N object from the slice containing 0b1111111100101 bit string. Thus, when we intend to deserialize Unary ~N, it means that we do not know yet whether we deserialize Unary 0, Unary 7 or Unary 1020. We begin with 0b1111111100101 and compare it with the constructor prefixes 0b0 for unary_zero and 0b1 for unary_succ. We can see that we have unary_succ. However, the value of N cannot be deducted. It should be obtained from the deserialization of variable x. This variable has type Unary ~(N-1) and the value of N-1 can be deducted from the deserialization of the remaining bits in the slice. We get the remaining bits of the slice and try to deserialize Unary ~(N-1) and again see the unary_succ tag. We, therefore, recursively dive into Unary until we get to the Unary ~(N-8). Then, we see that the rest of the slice starts from the unary_zero tag and thus constitutes a Unary 0 object. Looking back, we can see that we initially had a Unary 8 object. After the deserialization of Unary ~N from Slice(0b1111111100101) we get a Unary 8 object and the remaining slice(0b0101) from which subsequent variables of the constructor can be deserialized. Constraints​ Some implicit fields may contain constraints, for instance {n &lt;= m}. It means that the previously defined variables n and m should satisfy the corresponding inequality. This inequality is an inherent property of the constructor. It should be checked during serialization and objects with variables which do not satisfy these constraints are invalid. An example of constructors with constraints: hml_short$0 {m:#} {n:#} len:(Unary ~n) {n &lt;= m} s:(n * Bit) = HmLabel ~n m; hml_long$10 {m:#} n:(#&lt;= m) s:(n * Bit) = HmLabel ~n m; hml_same$11 {m:#} v:Bit n:(#&lt;= m) = HmLabel ~n m;  "},{"title":"Deserialization​","type":1,"pageTitle":"TL-B and BoC","url":"/arch/tlb-and-boc#deserialization","content":"With the help of TL-B schemes, any object can be serialized to the builder and deserialized from the slice. In particular, in order to deserialize an object, we need to start with the determination of the constructor. For this purpose we use a tag and then deserialize variables one by one from left to right. It is done recursively turning to the serialization of variables (they are TL-B objects). Throughout the serialization process we go the other way. Write to the builder tag which corresponds to a given object of that type and then, continue from left to right with each variable. "},{"title":"BoC​","type":1,"pageTitle":"TL-B and BoC","url":"/arch/tlb-and-boc#boc","content":"All data in ES is stored and sent in a structure called the BoC (Bag of cell). This is a confusing structure invented by Nikolai Durov, and it’s not very clear whether it was necessary in order to create the blockchain, or Nikolai over-engineered here. In general, all data stored in the contract (not the code, the code is separate, but also the BoC is stored in the contract :-)) is stored in one BoC, this is a given cell (TVMCell) with links to subcells. The TVMCell is a structure that has 1023 Bits of data and 4 references to its child cells. A cell reference is the HASH of that cell. With ES have have a singly connected graph, where each node can have 4 descendants. And we need to pack all smart contract data or messages into a cell with sub cells. Thank God, by using Ton Solidty and knowing the interfaces of contracts, you don’t have to manually pack and unpack cells. The compiler will do everything for you. However, there are rare cases when you will have to do it yourself. In order to do this, there are special primitives in Solidity. When this is necessary, you simply declare state variables in Solidity and read and write to them as usual. The compiler will pack and unpack everything in the BoC for you. Some BoC properties to understand. BoC is an acyclic graph. The link to a cell c is a hash of its data and its hash links to subcells. So we cannot create a cycle. (Because if we add a link from the parent cell to the child cell, then, by doing so, we recalculate all hashes from the changed cell to the root cell and the link to the parent cell changes). The entire state of the contract is BoC. This is one cell with as many child cells as you like. Ton Solidity takes care of work with states for us, but you need to understand that, because of ES’s tree structure, we normally don’t write contracts with a lot of data. In order to illustrate how it works, consider (schematically) how a dictionary could be implemented in BoC.  Each circle in the picture is a separate cell. To get the value by key 2, TVM needs to load a cell of depth 0, then depth 1 and then depth 2. We have to pay gas for each time a cell is loaded. And if we change the value by key two, we will need to recalculate all references from the cell with the value of the root cell because the cell reference is a hash (cell.data + cell.refs). So, links to all cells along the way will change and we will need to change them from bottom to top. So, the more elements our dictionary has, the deeper the cell will be and the more expensive it will be to work with. For a dictionary, the cost of gas will increase to O(log n) in a worst case scenario. (In reality, everything would be more complicated but O (log n) can be useful to look at as a worst case scenario). Now, if we are creating an ERC20 token, then the more owners this token has, the more expensive the gas will be to use this contract (the size of the owner-number map will grow). And although O(Log n) doesn’t sound scary at all, and the cost of working with the map will increase very, very slowly after the first hundred elements, and then even slower after that, in ES there we have a storage fee that grows linearly. If you have accounts in your ERC-20 token that contain pennies, then the fees for holding these accounts will greatly exceed the value of these accounts over the years. Therefore, in ES it is customary to make separate contracts for separate accounts, which themselves pay for their storage. Fun fact: this entire overcomplicated data storage scheme helps to scale the network, so that the validator can quickly execute smart contracts. Validators do not need to store the entire current state of the blockchain in Ram, because loading the smart contract state from the disk will be fast, since all smart contracts are small. Additionally, since all contracts are small, they are evenly distributed across all shards. "},{"title":"TVM","type":0,"sectionRef":"#","url":"/arch/tvm","content":"","keywords":""},{"title":"Additionally​","type":1,"pageTitle":"TVM","url":"/arch/tvm#additionally","content":"TVM Extended Instructions "},{"title":"Transactions","type":0,"sectionRef":"#","url":"/arch/transactions","content":"","keywords":""},{"title":"Transaction​","type":1,"pageTitle":"Transactions","url":"/arch/transactions#transaction","content":"A transaction is the result of an inbound message processing by a recipient account code. That is, when an account receives an inbound message, it leads to the computation of the account's new state and the possibility of generating one or more outbound messages with the account serving as the source. The inbound message and the previous state of the account serve as inputs for the transaction, while the generated outbound messages and the next state of the account serve as outputs. This relationship can be represented as a Directed Acyclic Graph (DAG).  "},{"title":"Transaction phases​","type":1,"pageTitle":"Transactions","url":"/arch/transactions#transaction-phases","content":"A transaction is composed of several phases. Each phase may either complete successfully or result in an error. In case of error, the next stage is not completed. Storage phase - is for the collection of storage payments for the account state (smart contract code and data). Throughout this phase, the smart contract may be frozen if its balance is insufficient to pay the storage fee. It is worth mentioning that there is no storage phase if the transaction is sent to deploy a new smart contract. Credit phase - adding the value of the internal message received to the account's balance. Computing phase - starts when the smart contract code is invoked inside an instance of TVM with appropriate parameters, including the inbound message and the account's persistent data. The result of this phase is an exit code, new persistent data, and an action list, which includes outbound messages to be sent. Also, it may end up creating a new account, uninitialized or active, or activating a previously uninitialized or frozen account. The gas fee for computation is deducted from the account balance. Action phase - starts when the actions from the actions list are performed if the smart contract is executed successfully (with exit code 0 or 1). Suppose, it is impossible to perform all the actions. For example, because of insufficient funds to transfer with an outbound message. In that case, the transaction is terminated, and the account state is rolled back. Bounce phase - starts when a transaction is terminated. That is, the inbound message has its bounce flag set. Respectively, there is an automatically generated outbound message, with the bounce flag clear, transferring the funds back to the sender. It takes the value of the original inbound message, deducts gas and forwarding fees and transfers the resulting amount to the newly generated message. "},{"title":"Specification​","type":1,"pageTitle":"Transactions","url":"/arch/transactions#specification","content":"Read more about transactions execution in Transaction executor Specification "},{"title":"How to determine a successful transaction?​","type":1,"pageTitle":"Transactions","url":"/arch/transactions#how-to-determine-a-successful-transaction","content":"It depends on the account state before and after the transaction (fields orig_status and end_status): If the account was already deployed, i.e. if (tx.orig_status == tx.end_status == active) then you can use tx.aborted field. If it is true, then the transaction is not successful. If the account was not yet deployed then if (orig_status == nonExist &amp;&amp; end_status == uninit &amp;&amp; aborted == true) then transaction is successful. All the transactions executed on non-deployed accounts are aborted by definition but if we see the state has changed to uninit, it means that the transfer was successfully received. if (orig_status == uninit &amp;&amp; end_status == uninit &amp;&amp; aborted == true &amp;&amp; in_message.bounce==false)then transaction is successful. Non-bounced messages are successfully received by non-deployed accounts, though the transaction status is aborted. Instead of checking tx.in_message.bounce==false you can check if tx.bounce.bounce_type&lt;2 (tx.bounce.bounce_type==2(Ok) is equal to in_message.bounce==true) "},{"title":"How the blockchain works on the block and queue level","type":0,"sectionRef":"#","url":"/arch/workchains","content":"How the blockchain works on the block and queue level This note is just for a general understanding of how the blockchain works, it’s not 100% accurate, we are waiting for a description from the writers of the node. This may change after a new consensus. There is a workchain -1, this is the master chain, it is validated by the validators with the largest stake. Contracts can be deployed in the -1 workchain, but it is more expensive, and it was made mainly for governorship. (Probably in the future there will be no user contracts) There is a workchain 0, where contracts are mostly located. More workchains will be launched in the future. Workchains are further divided into Processing threads. There is a workchain parameter that indicates the minimum number of processing threads, and currently it is 16 for a 0 workchain. Thread processing is an interesting concept. In ES, only computation is shared between the validators of the same workchain, but they all have the same storage. Let’s look at what that means and how it works. For example, we have 160 validators for the 0 workchain. They are randomly divided into 16 groups of 10 validators, and each gets its own Processing thread. All workchain contracts are also divided into 16 groups, simply by address ranges. (0.00 - 0:08, 0:08 - 0.18, etc.). Each group of validators executes transactions only for their group of smart contracts, and releases blocks of their processing thread. But at the same time, they are constantly downloading blocks of other processing threads in order to see their outgoing and incoming message queues. At the same time, blocks are not a list of transactions that need to be rolled up, but a list of incoming messages + a state delta. So, when you download a block of another processing thread, you do not have to do computation in order to update your state. You’re just rolling state changes. How roughly works: The Masterchain generates block 1.All threads download the last master block.Threads create their own block and register it in the master block.The masterchain generates block 2, which contains the hashes of all blocks of threads that have registered in it.All threads download masterblock 2.All threads look at the hashes of the registered blocks of other threads, and download them all.All threads generate a block.This process gets repeated. Message delivery guarantees also work in this way. When you create a message, it is placed on that thread’s outgoing queue: Thread A generates a message for the contract that is in thread B, and creates a block with a new outgoing message in the outgoing queue.Thread A is registered in the master block.The masterchain generates a block.Thread B downloads the master block, and downloads the block of thread A registered there.Thread B sees the message in thread A and imports it into its inbound queue. (When a message is imported, it is immediately executed (transaction starts) If there is not enough gas for a transaction in the current block, then the message is simply not imported, and waits for its turn in another block. At the same time, there is a message import order, so that validators will not be able to ignore it forever).Thread B creates a block with a message in the incoming queue, and registers with the master.Thread A downloads the block in which it sees its message in thread B’s incoming queue and removes the message from its outgoing queue since it was delivered successfully.Generally, thread A generates a block, then registers it in the master block. Then thread B downloads it, sees that thread A has removed it from its outgoing queue, and deletes it from its incoming one. In fact, sharding in this blockchain is the sharding of computational resources. And the data is the same for everyone, with the expectation that all validators have gigabit channels, and we rest only on computation. If some processing thread is heavily loaded with the last N blocks, then it will split into two, and new processing threads can also split in turn. Then when the load drops, they all merge.","keywords":""},{"title":"Everscale Bug Bounty Program","type":0,"sectionRef":"#","url":"/contribute/bug-bounty-program","content":"","keywords":""},{"title":"Introduction​","type":1,"pageTitle":"Everscale Bug Bounty Program","url":"/contribute/bug-bounty-program#introduction","content":"Everscale is an asynchronous message passing system of stateful programmable agents called smart-contracts. Those contracts manage digital assets of users on their behalf. In this context, digital assets mean tokens, NFTs, native cryptocurrency, etc. Some smart-contracts lock value worth millions of dollars. Hence, to be trustworthy, the Everscale platform has to provide security, integrity and availability of user assets. "},{"title":"Program Objectives​","type":1,"pageTitle":"Everscale Bug Bounty Program","url":"/contribute/bug-bounty-program#program-objectives","content":"The Everscale Bug Bounty Program aims to: Provide security researchers, white hackers, developers and other interested parties incentives to report found severe vulnerabilities to Everscale Platform developersRapidly improve Everscale Platform security by addressing critical and major vulnerabilities in a timely, confidential mannerImprove the overall public image of the platform as security-oriented and trustworthy "},{"title":"Definition of a Bug​","type":1,"pageTitle":"Everscale Bug Bounty Program","url":"/contribute/bug-bounty-program#definition-of-a-bug","content":"Three pillars of the blockchain platform reliability are: Security - digital assets are allowed to be managed only by eligible usersIntegrity - digital assets are managed exactly in a way anticipated by usersAvailability - digital assets are constantly accessible to be managed for eligible users Any Everscale Platform software defect possibly leading to partial or full disruption of one of the above is called a bug. Throughout the document, we use the terms bug, vulnerability and software defect interchangeably. "},{"title":"Bug Bounty Scope​","type":1,"pageTitle":"Everscale Bug Bounty Program","url":"/contribute/bug-bounty-program#bug-bounty-scope","content":"We are interested in finding bugs in the following software components. Only master branches of those repositories are in scope of this Bug Bounty. Everscale Node modules: TVM virtual machineNode protocolTransaction ExecutorMain data structures: block structuresLow-level types TON Solidity CompilerTVM LinkerConfig smart-contractSafe Multisig WalletWrapped EverFlat QubeOctus Bridge modules: RelayContracts "},{"title":"Bugs Severity Ranking​","type":1,"pageTitle":"Everscale Bug Bounty Program","url":"/contribute/bug-bounty-program#bugs-severity-ranking","content":"To rank submitted bug reports it is suggested to use the DREAD1 vulnerabilities rating system. The reported bug is evaluated by the following criteria: Damage potential - If the threat is exploited, how severe consequences are?Reproducibility - How easy is it to reproduce the attack?Exploitability - How easy is it to perform the attack?Affected users - After successful attack, how many users would be affected and how important are they?Discoverability - How easy is it to spot the vulnerability in the software? For a specific bug, each criteria is assigned a number from 0 to 10. The overall bug rating is an arithmetic average of all those values. The higher the rating, the more valuable the finding, hence the higher reward. "},{"title":"Involved Parties​","type":1,"pageTitle":"Everscale Bug Bounty Program","url":"/contribute/bug-bounty-program#involved-parties","content":"We distinguish the following parties involved in the Bug Bounty application and evaluation process: Applicant is a person that found software vulnerability and wants to submit it and receive the reward.Reviewers - a group of experts evaluating the submission.Administrator - a person responsible for receiving bug reports from Applicants and transferring them to the Review Committee, conducting their evaluation of the report. This person is the manager of the whole evaluation process, starting from receiving the initial report from the Applicant, and up to transferring the final reward, if any. "},{"title":"Application and Evaluation Process​","type":1,"pageTitle":"Everscale Bug Bounty Program","url":"/contribute/bug-bounty-program#application-and-evaluation-process","content":"Applicant conducts the vulnerability report that should reflect the following: Threat short titleAffected componentsDescriptionResult of attackMitigation strategiesDREAD vulnerability evaluation with rational for each item Applicant sends the report to the Administrator. From that very moment, all details of the vulnerability shall stay undisclosed! This is of paramount importance for both Platform developers and the Applicant.Administrator acknowledges the report and does the pre-evaluation of the report. If the report looks reasonable and within the scope of Bug Bounty Program, then the report is sent to the corresponding Reviewers for further in-depth evaluation. If the report is not good enough, or out of scope, the Administrator informs the Applicant about that.Reviewers evaluate the vulnerability report and prepare the Report Evaluation Summary document, (RES). The RES document contains the experts opinion on how severe the presented vulnerability is, and if it deserves to be fixed.Reviewers send the RES to the Administrator.Administrator acknowledges the Applicant about the RES evaluation. If RES is positive, and the Applicant agrees on it, the Administrator initiates the reward transaction to the Application wallet according to the Reward Structure section.After the bug is fixed, all involved parties are free to report the vulnerability to the public. Before that, it is strictly prohibited. "},{"title":"Report Evaluation Summary​","type":1,"pageTitle":"Everscale Bug Bounty Program","url":"/contribute/bug-bounty-program#report-evaluation-summary","content":"Reviewers are responsible for in-depth technical evaluation of the report. In particular, they evaluate the submitted report from the perspective of DREAD: How severe are the consequences if the vulnerability gets exploited?How easy is it to reproduce the bug?How easy is it to exploit the bug on the real network?If the attack succeeds, what are the consequences for users and how important are they?How difficult is it to discover this bug having the software artifacts at hand? For each item, RC assigns a number from 0 to 10. The final score is an arithmetic average of those. This score equipped with a short rationale is put into the Report Evaluation Summary document. "},{"title":"Reward Structure​","type":1,"pageTitle":"Everscale Bug Bounty Program","url":"/contribute/bug-bounty-program#reward-structure","content":"The reward depends on the final score stated in the Report Evaluation Summary. The following severity levels and their respective rewards are suggested. Bug Severity\tDREAD score\tReward (USD equivalent)Critical\t[8 .. 10)\t50000 High\t[5 .. 7)\t30000 Medium\t[3 .. 5)\t10000 Low\t[1 .. 3)\t1500 Information\t[0 .. 1)\t0 note Rewards are paid in USDT tokens, LEVER2 tokens or some of their combinations, depending on the current Bug Bounty budget restrictions. The specific reward structure is decided individually, after the bug report is accepted and approved. The current Bug Bounty budget restrictions are decided by DeFi Alliance members. note The Bug Bounty program may be stopped for some period of time without prior notice. In this case, if there are pending bug reports, they will be processed on a fair basis after the program is resumed. "},{"title":"Conflicts Resolution​","type":1,"pageTitle":"Everscale Bug Bounty Program","url":"/contribute/bug-bounty-program#conflicts-resolution","content":"In case the Applicant does not agree with the Reviewers decision, or Administrator decision regarding their bug report, the Administrator reserves the right to draw the final decision on the vulnerability severity evaluation and the reward. It is well understood by all parties that unfair or inadequate evaluation of Applicant’s work will result in a significant reputation harm. "},{"title":"Non-Disclosure Agreement​","type":1,"pageTitle":"Everscale Bug Bounty Program","url":"/contribute/bug-bounty-program#non-disclosure-agreement","content":"After the application process is started, all involved parties shall not publish the vulnerability details within the public space. The vulnerability publishing is prohibited up until the moment the vulnerability is fixed in the software and corresponding updates are uploaded into the network. "},{"title":"Rules of Conduct​","type":1,"pageTitle":"Everscale Bug Bounty Program","url":"/contribute/bug-bounty-program#rules-of-conduct","content":"Applicants shall not break the rules stated in this document. Otherwise, an Applicant may be banned from the program, temporarily or forever.Applicants shall not be affiliated with EverX Labs and Broxus companies.Applicants shall not use social engineering techniques to gain knowledge of bugs.Applicants shall not impersonate others work. It is prohibited to publish the report based on findings of another person.Applicants shall not test found vulnerabilities on the main network or public test networks. Only private networks shall be used for that purpose.After the report is submitted, Applicant shall not disclose the report details to the public. This rule is canceled after the vulnerability is fixed.Both Administrator and Reviewers shall not disclose the report details to the public until the vulnerability has been fixed and reward is paid.Applicants shall not report a bug that was previously disclosed by others.Applicants shall not underreport or misinterpret found vulnerabilitiesAdministrator shall provide feedback to the Applicant, and act on the report in a timely manner. If the process stalls, the Applicant has the right to ask for an action. "},{"title":"Contacts​","type":1,"pageTitle":"Everscale Bug Bounty Program","url":"/contribute/bug-bounty-program#contacts","content":"Bug report shall be sent to bugreport@everx.dev The applicant may also contact our support team on Telegram: @Custler, @lotumba, @isheldon, @Rexagon, @UsernameBarsik, @prigolovko "},{"title":"Appendix A. Vulnerability Report Example​","type":1,"pageTitle":"Everscale Bug Bounty Program","url":"/contribute/bug-bounty-program#appendix-a-vulnerability-report-example","content":"Here, we provide a brief example of how the Vulnerability Report should look like for some fictional vulnerability in the SafeMultisigWallet. Threat title — Safe MultiSig allows unauthorized token transfersAffected components — All deployed SafeMultiSig wallets in the networkDescription — We consider the method SafeMultisigWallet: Transfer(param:uint, send_to: address) as vulnerable. If the value of param = 1, and the wallet has less than 3 owners, the method will not perform proper user authorization and transfer all the wallet funds to send_to address. This is due to incorrect check at line 123. The current check is: &lt;incorrect check goes check&gt;, the correct check would be: &lt;correct check goes here&gt;Result of attack — Complete loss of user funds in the worst case.Mitigation strategies — To fix the code error: Fix the check at line 123, Inspect all probable places with similar checks in the source code. To overcome the bug on the deployed wallets: If you have less than 3 custodians, add extra wallet custodians so their total amount becomes at least 3.DREAD score Damage potential: 9 — Wallet users lose their fundsReproducibility: 9 — The bug is reproducible on all wallets with a number of custodians less than 3.Exploitability: 9 — The bug can be exploited by a simple transaction with proper parametersAffected users: 6 — All users of the network with SafeMultiSig wallets with custodian number less than 3 . By our estimation, the total number of such user wallets is ~200 which is less than 5% of all the population, with total funds locked for 1$ mln worth of Ever.Discoverability: 9 — The incorrect check is easy to spot. You need no special knowledge to discover this bug.Total: (9 + 9 + 9 + 6 + 9) / 5 = 8.4 Critical "},{"title":"Notes​","type":1,"pageTitle":"Everscale Bug Bounty Program","url":"/contribute/bug-bounty-program#notes","content":"DREAD is part of a system for risk-assessing computer security threats that was formerly used at Microsoft.↩The LEVER token is an EVER equivalent locked for 2 years after being minted. This token is not yet introduced into wide usage. A brief description may be found here.↩ "},{"title":"Getting started","type":0,"sectionRef":"#","url":"/contribute/getting-started","content":"","keywords":""},{"title":"Everscale Grants​","type":1,"pageTitle":"Getting started","url":"/contribute/getting-started#everscale-grants","content":"Everscale Grants is a campaign that aims to attract promising IT projects that can contribute to the Everscale ecosystem's growth. Approved projects receive not only financial, but also technical and marketing support. The formation and distribution of grants is handled by DeFi Alliance. DeFi Alliance is a business combination that creates the necessary infrastructure to attract teams and projects, raises liquidity from other projects in Everscale, and builds partnerships with large companies with large amounts of liquidity. To apply, use the form on the Everscale Grants page on the network's website or Everscale DeFi Alliancecorresponding page of their official website. "},{"title":"Contests​","type":1,"pageTitle":"Getting started","url":"/contribute/getting-started#contests","content":"Contests are a way to develop and support Everscale, as well as a way that the network’s meritocratic coin distribution model is put into practice. Contests are held in various areas, such as programming, design, SMM, PR, and so on. Some of them are aimed at technically improving operation, while others are to increase awareness of the blockchain and attract new users. Everscale's management is divided into subgovernances – groups of people, each of which is responsible for a certain type of activity and contests within Everscale. Members of the subgovernances receive a portion of tokens for community development, contests, etc. Prizes for first place sometimes reach 500,000 EVER and average between 10,000 and 100,000 EVER. Check out active and completed contests at EverKit Governance. "},{"title":"EVER DAO​","type":1,"pageTitle":"Getting started","url":"/contribute/getting-started#ever-dao","content":"EVER DAO is a decentralized governance platform that allows EVER (wEVER) token holders to vote on proposals relating to the Everscale network. Community members can express their will and opinion on significant network events in a transparent and verifiable way. To participate in voting, you must have a certain stake EVER, which will be equivalent to the strength of your vote. "},{"title":"EverStart​","type":1,"pageTitle":"Getting started","url":"/contribute/getting-started#everstart","content":"EverStart - is a DAO-managed multi-chain launcher for connecting to curated projects. This is the first Everscale blockchain launchpad, thanks to which the community has the opportunity not only to decide which project is worthy of being in the network ecosystem, but also to benefit from its further development through vesting. (DAO mechanism not launched yet). "},{"title":"Octus Bridge DAO​","type":1,"pageTitle":"Getting started","url":"/contribute/getting-started#octus-bridge-dao","content":"Octus Bridge is a cross-chain solution that allows you to move liquidity between Everscale and many other chains. Octus Bridge also has its native BRIDGE token. BRIDGE token holders can vote on certain operational decisions of the Octus Bridge platform to make the bridge better. The voting protocol is a real smart contract that is allowed to make changes to other smart contracts. There are now more than 23 relays of particular importance in the Bridge DAO structure. Any user with at least 100,000 BRIDGE tokens can become a relay. "},{"title":"Account Abstraction","type":0,"sectionRef":"#","url":"/develop/account-abstraction","content":"","keywords":""},{"title":"On the differences between Ethereum and Everscale approaches to Account Abstraction​","type":1,"pageTitle":"Account Abstraction","url":"/develop/account-abstraction#on-the-differences-between-ethereum-and-everscale-approaches-to-account-abstraction","content":"The EIP-4337, also known as an Account Abstraction (AA) was recently deployed on the Ethereum mainnet. In the Everscale blockchain, we believe in the idea of AA as a key enabler for extended wallet functionality, better security, and UX. However, due to the desire to deploy it without changes to the core protocol, the original Ethereum AA design is a bit complicated and comes with a separate alt-mempool, bundler nodes, and EntryPoint contract. Everscale comes with natively built-in &quot;AA batteries&quot;, which makes the dev experience with AA much easier to pick up, especially for newbies. Let's dive deeper into how Everscale's AAs work. "},{"title":"No AA and EOA. Just A​","type":1,"pageTitle":"Account Abstraction","url":"/develop/account-abstraction#no-aa-and-eoa-just-a","content":"The Value, be it a native coin or TIP-3 token, can only flow as an effect of smart contract code execution. For us, the notion of EOA shouldn't exist per se, and all Accounts are &quot;abstract&quot;. "},{"title":"Lifecycle of an Account​","type":1,"pageTitle":"Account Abstraction","url":"/develop/account-abstraction#lifecycle-of-an-account","content":"The Account is deployed with some initial state (code + data). The TVM comes with instructions to access and modify Accounts' code, state, send Messages, deploy new Accounts, and more. Executing the code in the TVM is invoked by an inbound Message. Both Account-to-Account and User-2-Account Messages are possible. "},{"title":"No EntryPoint​","type":1,"pageTitle":"Account Abstraction","url":"/develop/account-abstraction#no-entrypoint","content":"Users interact with Accounts via sending External Messages. They also may want to use key pairs or session keys to authorize External Messages. As there are no EOAs, all External Messages carry no value. When External Message is processed by an Account, the TVM gives some small portion of &quot;credit gas&quot;. The developer can use it to perform certain logic before accepting a Message. Using the Accounts' own balance requires the &quot;accept&quot; to be done explicitly with a corresponding TVM instruction. To reject the External Message, an Account should just not accept it. Rejected External Messages are never included in blocks. Thus, each Account is an EntryPoint itself. "},{"title":"Content Addressable Account Spaces​","type":1,"pageTitle":"Account Abstraction","url":"/develop/account-abstraction#content-addressable-account-spaces","content":"Each Account is content-addressable: the Account address is deterministically derived from its initial code and state. Imagine A1 sends the Message to A2. If such a message includes A1's initial data, A2 can check if A1 has the same code. For that, it will take its own initial code + A1's data and derive the expected address for A1. This approach to auth enables developers to build secure systems with address-based access control rules without the need to maintain access control lists explicitly. "},{"title":"Upgradeability​","type":1,"pageTitle":"Account Abstraction","url":"/develop/account-abstraction#upgradeability","content":"On EVM, to implement upgradeability for a given A1 you need to deploy at least one additional A2 for your A1. Each upgrade will require at least 1 new Account to be deployed. This approach is well-adopted and known as Upgradeable Proxy Pattern. On TVM, there is SETCODE instruction, which allows Account to upgrade itself with any code, that it can take from inbound Message, or its own storage. Accounts' address remains unchanged, and the Upgrade requires no extra deployments. "},{"title":"Smart Contract Wallets​","type":1,"pageTitle":"Account Abstraction","url":"/develop/account-abstraction#smart-contract-wallets","content":"One of the key motivations for AA is to put the ownership model in the developers' hands to implement (code is a law). With greater power comes great responsibility, and cooking AAs right is important. The best practices and audited templates for AAs are yet to come into the EVM ecosystem. At Everscale, there is a formally verified implementation for singlesig / multisig + the Upgradable version, that enables one to build any logic and plug it on top (keeping the address unchanged) "},{"title":"Actor model","type":0,"sectionRef":"#","url":"/develop/actor-model","content":"Actor model Let's consider one smart contract. In Everscale, it is a thing with properties like address, code, data, balance and others. In other words, it is an object which has some storage and behavior. That behavior has the following pattern: a contract gets a messagecontract handles that event by executing its code in TVMcontract modifies its own properties (code, data and others)contract optionally generates outgoing messages (which may include deployments of other contracts)contract goes into standby mode until the next event occurs A combination of these steps is called a transaction. It is important that events are handled one by one, thus transactions are strictly ordered and cannot interrupt each other. This pattern is well known and called Actor Model.","keywords":""},{"title":"Intro","type":0,"sectionRef":"#","url":"/develop/intro","content":"","keywords":""},{"title":"Distributed Programming approach​","type":1,"pageTitle":"Intro","url":"/develop/intro#distributed-programming-approach","content":"Instead of writing contracts in which the state can continuously grow, we write distributed systems of smart contracts. For example TIP-3 token standard is designed as a system of main TokenRoot contract, which stores metadata, and has a function to deploy a separate smart-contract called TokenWallet for each token owner (that is what a wallet is) and can send tokens directly among contracts without a central hub. Important concept In Everscale, each contract address is a uniquely computed value. A contract address is a hash of the contract code and initial data (initial data is a value of static variables, and not what you pass to the constructor, since in Everscale the constructor is a function that you call after the deployment of the contract in one transaction). This is a very important pattern of distributed programming (as it is understood in Everscale). Knowing the code of a contract, and its initial data you can make sure that you are being called by a contract with the same parents as your own. Or, knowing the contract code and its initial data, you can compute the address of a contract on the fly and send messages to it. By creating small contracts for a single system (like in TIP-3 token) we solve a number of issues: All contracts end up in different shards which distributes the load evenly throughout the network.Contract states are very small. Validators can load them very quickly from a disk.Storage fee. If we had one contract with a huge hash map, then it would have to pay a large fee for its storage, and it is not clear who should pay and how for this storage. If there are many accounts with small balances that their owners no longer need, then naturally they will not pay for its storage, and the rest of the holders of this token will have to pay for all of the “remainders.” So that smart contract programmers do not have to think about how to force users to pay for storage or clean up old data inside the contract, Everscale has allowed each user to deploy their own contract. Each user determines how long they will pay for storage and can always adjust these parameters. "},{"title":"Contract Deployment​","type":1,"pageTitle":"Intro","url":"/develop/intro#contract-deployment","content":"The concept about deterministic address calculations, described above, is also tied to how contracts are deployed in Everscale. The contract can naturally be deployed by another contract. But what should we do if we want to deploy a contract from outside? To do this, we have to take the contract code and its initial data, and compute its future address. After that, we simply send money there, with a bounce flag = false. And the money just stays on the address, which has no initialized code. Then we send a special external message to this address with the code and initial data, and we say “Look, here we have the code and initial data, the hash of which gives us this address, initialize it please” and the network initializes the contract. "},{"title":"GraphQL code generation","type":0,"sectionRef":"#","url":"/develop/payment","content":"","keywords":""},{"title":"Evercloud GraphQL​","type":1,"pageTitle":"GraphQL code generation","url":"/develop/payment#evercloud-graphql","content":"Evercloud makes it easy to set up and manage a GraphQL endpoint for your application, providing you with secure access to the Everscale blockchain. Follow this guide to set up a project on Evercloud. Make sure to note down the project ID in the security tab, as well as the project secret and the HTTP Authorization value, as you will need to configure these in the code. Once you have the necessary credentials, you're ready to start making GraphQL queries to the Everscale network in your TypeScript project. To cater to various development preferences, we'll provide two versions for each example: one using the Everscale SDK (follow this guide for setup instructions) and another using Axios, a popular HTTP client for JavaScript. "},{"title":"Setting up code generation​","type":1,"pageTitle":"GraphQL code generation","url":"/develop/payment#setting-up-code-generation","content":"First, add both the graphql and @graphql-codegen/cli packages to your project's dependencies: npmyarn npm install graphql npm install -D typescript npm install -D @graphql-codegen/cli npm install -D @graphql-codegen/typescript  Next, create a file named codegen.ts in your project's root folder containing the following (adjust as needed): import type {CodegenConfig} from '@graphql-codegen/cli' // configure your credentials here const PROJECT_ID = '' const PROJECT_HTTP_AUTHORIZATION = '' const schemaUrl = `https://mainnet.evercloud.dev/${PROJECT_ID}/graphql` const config: CodegenConfig = { overwrite: true, schema: [ { [schemaUrl]: { headers: { Authorization: PROJECT_HTTP_AUTHORIZATION, }, }, }, ], documents: ['src/**/*.ts'], ignoreNoDocuments: true, // for better experience with the watcher generates: { 'src/generated/graphql.ts': { plugins: ['typescript'], }, }, watch: true, } export default config  Finally, follow these instructions to add GraphQL code generation to your development workflow. "},{"title":"API initialization​","type":1,"pageTitle":"GraphQL code generation","url":"/develop/payment#api-initialization","content":"To start making queries to the GraphQL API, you'll need to configure your client. Following is an example on how you can do that using either the Everscale SDK or Axios. Everscale SDKAxios import {TonClient} from '@eversdk/core' import {libNode} from '@eversdk/lib-node' // configure your credentials here const PROJECT_ID = '' const PROJECT_SECRET = '' TonClient.useBinaryLibrary(libNode) const client = new TonClient({ network: { endpoints: [`https://mainnet.evercloud.dev/${PROJECT_ID}/graphql`], access_key: PROJECT_SECRET, }, })  "},{"title":"Code examples​","type":1,"pageTitle":"GraphQL code generation","url":"/develop/payment#code-examples","content":"Following examples demonstrate how you can use the types generated from the GraphQL schema in your project. "},{"title":"Get account balance​","type":1,"pageTitle":"GraphQL code generation","url":"/develop/payment#get-account-balance","content":"Everscale SDKAxios // Add this to imports at the top of the file import {BlockchainQuery} from './generated/graphql' // Specify your account's address const ACCOUNT_ADDRESS = '' async function main() { try { const query = ` query { blockchain { account( address: &quot;${ACCOUNT_ADDRESS}&quot; ) { info { balance(format: DEC) } } } }` const {result} = await client.net.query({query}) const blockchain: BlockchainQuery = result.data.blockchain console.log(`The account balance is ${parseInt(blockchain.account?.info?.balance || '0', 10) / 10 ** 9}`) client.close() } catch (error) { console.error(error) } } main()  "},{"title":"Get incoming messages​","type":1,"pageTitle":"GraphQL code generation","url":"/develop/payment#get-incoming-messages","content":"This example shows how to query incoming messages for a specified destination account using both the Everscale SDK and Axios. This can be particularly useful for processing incoming token transfers or other transaction-related information. Everscale SDKAxios // Add this to imports at the top of the file import {BlockchainQuery} from './generated/graphql' // Specify your account's address const ACCOUNT_ADDRESS = '' interface MyQuery { address: string cursor: string | null count: number seq_no: number } async function main() { try { const query = ` query MyQuery($address: String!, $cursor: String, $count: Int, $seq_no: Int){ blockchain { account(address: $address){ messages( msg_type: ExtIn master_seq_no_range: { start: $seq_no } first: $count after: $cursor ){ edges{ node{ hash msg_type value(format: DEC) src } } } } } }` const variables: MyQuery = { address: ACCOUNT_ADDRESS, cursor: null, count: 10, // number per page, max: 50 seq_no: 1, // set to the initial block sequence number } while (true) { // infinity loop, implement exit condition here const {result} = await client.net.query({query, variables}) const data: BlockchainQuery = result.data const messages = data.account?.messages const edges = messages?.edges || [] variables.cursor = messages?.pageInfo.endCursor || variables.cursor edges.forEach(edge =&gt; { const message = edge.node // do something with message console.log(message) }) // implement a delay here so as not to spam the API } client.close() } catch (error) { console.error(error) } } main()  "},{"title":"Example project​","type":1,"pageTitle":"GraphQL code generation","url":"/develop/payment#example-project","content":"See the examples directory in this repository for a demo project containing these examples. "},{"title":"GraphQL Block and Transaction Pagination: Best Practice","type":0,"sectionRef":"#","url":"/develop/graphql-pagination","content":"","keywords":""},{"title":"Introduction​","type":1,"pageTitle":"GraphQL Block and Transaction Pagination: Best Practice","url":"/develop/graphql-pagination#introduction","content":"Before the development of Blockchain API many developers formed a habit of implementing pagination via block and transaction collections, using fields such as created_at, now, lt, etc. While it might seem more convenient and simple, this is a sub-optimal practice. In certain circumstances, such as periods of large loads and intensive sharding, it has been shown to lead to data loss. GraphQL Blockchain API was developed for this exact reason - to provide a reliable way of blockchain data pagination and prevent any potential data inconsistencies regardless of network load. Note: With GraphQL API 1.0 update by default Blockchain API provides only data for the past 7 days. For use cases where earlier data is needed make sure to use the 'archive: true' flag in blockchain query filters, as shown in the samples below. Do not however use it, if archive data isn't required, as it will generate unnecessary load. Note: Query Collections are a supported instrument and will remain so. However, they are intended and optimized primarily for tasks that are not critically dependent on data completeness, such as analytics. "},{"title":"Blocks Pagination with Blockchain API​","type":1,"pageTitle":"GraphQL Block and Transaction Pagination: Best Practice","url":"/develop/graphql-pagination#blocks-pagination-with-blockchain-api","content":"Note: For Blockchain API documentation, refer here. Block pagination is based on the fact that all workchain blocks are committed into masterchain blocks in a specific order. The masterchain is ordered by seq_no and has only one thread. The pagination cursor thus divides all blockchain blocks into ranges between masterchain blocks and provides a complete selection. Let’s look at the following sample: query { blockchain { blocks( master_seq_no_range: { start: 2660661 end: 2670661 } workchain: 0 archive: true ) { edges { node { workchain_id id shard seq_no hash file_hash } cursor } pageInfo { endCursor } } } }  Here we specify masterchain blocks seq_no range. Block seq_no numbers can be found on block detail pages in blockchain explorers, such as https://ever.live/ or https://everscan.io/. Examples: here and here. We also specify that we want to paginate only 0 workchain blocks. To get only masterchain blocks, you can specify -1. If the workchain parameter is omitted, you will get all blocks from all workchains. In the result shown below you can see cursor field in each edge object. The cursor value can be passed over to the next query for pagination. Or you can get the latest cursor for the result set in PageInfo.endCursor field. { &quot;data&quot;: { &quot;blockchain&quot;: { &quot;blocks&quot;: { &quot;edges&quot;: [ { &quot;node&quot;: { &quot;workchain_id&quot;: 0, &quot;id&quot;: &quot;block/b4eb28c24a8b4f1fd57a644ee577b79ae69384482e0136014db6ef69a9219791&quot;, &quot;shard&quot;: &quot;5800000000000000&quot;, &quot;seq_no&quot;: 3670226, &quot;hash&quot;: &quot;b4eb28c24a8b4f1fd57a644ee577b79ae69384482e0136014db6ef69a9219791&quot;, &quot;file_hash&quot;: null }, &quot;cursor&quot;: &quot;52899360053800d211a&quot; }, // ... { &quot;node&quot;: { &quot;workchain_id&quot;: 0, &quot;id&quot;: &quot;block/8eba270b0b225cf03e3edf997fea70f29e58489dc6f30602ca18bf3a56d19101&quot;, &quot;shard&quot;: &quot;b800000000000000&quot;, &quot;seq_no&quot;: 3671807, &quot;hash&quot;: &quot;8eba270b0b225cf03e3edf997fea70f29e58489dc6f30602ca18bf3a56d19101&quot;, &quot;file_hash&quot;: null }, &quot;cursor&quot;: &quot;52899360053806ff11d&quot; } ], &quot;pageInfo&quot;: { &quot;endCursor&quot;: &quot;52899360053806ff11d&quot; } } } } }  Now let’s get the next page of our range. The following parameters will be used: after/first - shows first number of items after (not including) specified cursor value.before/last- shows last number of items before (not including) specified cursor value. This can be used for backward pagination. In the following sample pagination is continued within the same seq_no range. The next 10 blocks after the last block in the previous query are displayed. query { blockchain { blocks( master_seq_no_range: { start: 2660661 end: 2670661 } after: &quot;52899360053806ff11d&quot; first: 10 workchain: 0 archive: true ) { edges { node { workchain_id id shard seq_no hash file_hash } cursor } pageInfo { endCursor hasNextPage } } } }  PageInfo section here gets an additional parameter: pageInfo.hasNextPage Its output (true/false) shows whether there is data for another page in the current seq_no range. The result of the query looks like this: { &quot;data&quot;: { &quot;blockchain&quot;: { &quot;blocks&quot;: { &quot;edges&quot;: [ { &quot;node&quot;: { &quot;workchain_id&quot;: 0, &quot;id&quot;: &quot;block/b313465a71e0e89977ef052a3ed56cb4969e5bf6eed857ec1fd89b0c4be401a0&quot;, &quot;shard&quot;: &quot;c800000000000000&quot;, &quot;seq_no&quot;: 3661331, &quot;hash&quot;: &quot;b313465a71e0e89977ef052a3ed56cb4969e5bf6eed857ec1fd89b0c4be401a0&quot;, &quot;file_hash&quot;: null }, &quot;cursor&quot;: &quot;528993700537de13113&quot; }, // ... { &quot;node&quot;: { &quot;workchain_id&quot;: 0, &quot;id&quot;: &quot;block/c66528d454dc621ca9b6e6f48889e4da87c160bcdf5e05263b7e390aa5e035a3&quot;, &quot;shard&quot;: &quot;6800000000000000&quot;, &quot;seq_no&quot;: 3664899, &quot;hash&quot;: &quot;c66528d454dc621ca9b6e6f48889e4da87c160bcdf5e05263b7e390aa5e035a3&quot;, &quot;file_hash&quot;: null }, &quot;cursor&quot;: &quot;528993700537ec03116&quot; } ], &quot;pageInfo&quot;: { &quot;endCursor&quot;: &quot;528993700537ec03116&quot;, &quot;hasNextPage&quot;: true } } } } }  hasNextPage returned true, so the next page exists and we should continue paginating within the same seq_no range. If it is false, to continue pagination without losing any blocks, we can simply move the seq_no range forward. Note: To implement backward pagination use pageInfo.hasPreviousPage The full documentation about blocks pagination is available here. "},{"title":"Transactions pagination with Blockchain API​","type":1,"pageTitle":"GraphQL Block and Transaction Pagination: Best Practice","url":"/develop/graphql-pagination#transactions-pagination-with-blockchain-api","content":"Transaction pagination works exactly the same as block pagination - transactions are listed via cursor within a specified masterchain block seq_no range. The following sample paginates workchain 0 transactions in a given master_seq_no_range: query { blockchain { transactions( master_seq_no_range: { start: 2660661 end: 2670661 } workchain: 0 archive: true ) { edges { node { id now } cursor } pageInfo { endCursor hasNextPage } } } }  PageInfo.hasNextPage checks if there is additional data available in the seq_no range to form a next page. If it returns false, seq_no range should be moved forward to get the next batch of transactions. To implement backward pagination use pageInfo.hasPreviousPage The result of the sample above looks like this: { &quot;data&quot;: { &quot;blockchain&quot;: { &quot;transactions&quot;: { &quot;edges&quot;: [ { &quot;node&quot;: { &quot;id&quot;: &quot;transaction/e15b27cf27e34ea4f207d06b6bb8c1541626200fea6cc00be23e10efec49bd2a&quot;, &quot;now&quot;: 1598767530 }, &quot;cursor&quot;: &quot;528ad6800538067c11f00&quot; }, //... { &quot;node&quot;: { &quot;id&quot;: &quot;transaction/d95894791b0cdcaab0988de272fa620a4c456df865e0a79b4eab94fa2bcd2840&quot;, &quot;now&quot;: 1598782332 }, &quot;cursor&quot;: &quot;528be5b005381da811c00&quot; } ], &quot;pageInfo&quot;: { &quot;endCursor&quot;: &quot;528be5b005381da811c00&quot;, &quot;hasNextPage&quot;: true } } } } }  Use cursor, {first, after} or {last, before} filters to get neighboring pages of the same seq_no range: after/first - shows first number of items after (not including) specified cursor value.before/last- shows last number of items before (not including) specified cursor value. query { blockchain { transactions( master_seq_no_range: { start: 2660661 end: 2670661 } after: &quot;528be5b005381da811c00&quot; first: 10 workchain: 0 archive: true ) { edges { node { id now } cursor } pageInfo { endCursor hasNextPage } } } }  The full documentation about transaction pagination is available here. "},{"title":"Getting block seq_no range by time range​","type":1,"pageTitle":"GraphQL Block and Transaction Pagination: Best Practice","url":"/develop/graphql-pagination#getting-block-seq_no-range-by-time-range","content":"If you do not know the seq_no of masterchain blocks to create a range you can first obtain it by the time range, and then implement pagination the same way as described above. Use the following query: query { blockchain { master_seq_no_range( time_start: 1685166198 time_end: 1685266198 ) { start end } } }  Here time_start and time_end indicate the time range for which you will get the block master seq_no range. The output of the query looks like this: { &quot;data&quot;: { &quot;blockchain&quot;: { &quot;master_seq_no_range&quot;: { &quot;start&quot;: 28233606, &quot;end&quot;: 28266974 } } } }  Warning: Specifying a timestamp range does not guarantee that there will be no blocks outside of that range in the result set. This is because some thread blocks generated outside of the specified time range may be committed to a masterchain block generated within that time range. However, this pagination method allows us to conveniently retrieve all blocks/transactions. Neighboring ranges may be checked for blocks and transactions that might have escaped the result set. "},{"title":"Query Collection Comparison​","type":1,"pageTitle":"GraphQL Block and Transaction Pagination: Best Practice","url":"/develop/graphql-pagination#query-collection-comparison","content":"*Note: This is the How Not To Do It section.* A typical way to query blocks collection in GraphQL looks like this: query { blocks( filter: { gen_utime: { lt: 1686215295 } workchain_id: { eq: 0 } } limit: 50 orderBy: { path: &quot;gen_utime&quot; direction: DESC } ) { workchain_id id shard seq_no file_hash } }  Here block selection happens by generation unixtime (gen_utime). And this is the typical way to query transactions: query { transactions( filter: { now: { gt: 1567601735 } } orderBy: { path: &quot;now&quot; direction: DESC } limit: 5 ) { id now } }  Here transactions are filtered by now timestamp. If this is used for pagination and high or varied blockchain load occurs (shards split and merge intensively), blocks and transactions selected by time may end up lost - just as when getting master seq_no by timestamp in the section above, some thread blocks generated within that timestamp may not be included in the results. There is however no reliable way to check for these lost blocks/transactions and ensure they are retrieved, so this method should never be used for any tasks that require data completeness. Its primary use is analytics tasks. "},{"title":"Connect Wallet","type":0,"sectionRef":"#","url":"/develop/recipes/connect-wallet","content":"","keywords":""},{"title":"Check if the extension is available​","type":1,"pageTitle":"Connect Wallet","url":"/develop/recipes/connect-wallet#check-if-the-extension-is-available","content":"We always start our interaction with the wallet by checking if the user has a wallet installed: everscale-inpage-providersurf-keeper-provider import {hasEverscaleProvider} from 'everscale-inpage-provider'; const isEverWalletInstalled = await hasEverscaleProvider();  If the user doesn't have a wallet installed, ask him to install. "},{"title":"Initialize Provider​","type":1,"pageTitle":"Connect Wallet","url":"/develop/recipes/connect-wallet#initialize-provider","content":"Next, we initialize the provider and retrieve its current state: everscale-inpage-providersurf-keeper-provider import { ProviderRpcClient } from 'everscale-inpage-provider'; const ever = new ProviderRpcClient(); // We may want to await for the extension to be fully initialized // await ever.ensureInitialized(); // Get current provider state const currentProviderState = await ever.getProviderState(); The response should look like following (the values of parameters may change depending on version and selected network): { &quot;version&quot;: &quot;0.3.12&quot;, &quot;numericVersion&quot;: 3012, &quot;networkId&quot;: 31337, &quot;selectedConnection&quot;: &quot;localnet&quot;, &quot;supportedPermissions&quot;: [ &quot;basic&quot;, &quot;accountInteraction&quot; ], &quot;permissions&quot;: {}, &quot;subscriptions&quot;: {} }  "},{"title":"Login and logout​","type":1,"pageTitle":"Connect Wallet","url":"/develop/recipes/connect-wallet#login-and-logout","content":"Login flow is quite different for each wallet: everscale-inpage-providersurf-keeper-provider To login, we ask a user for permissions to interact with one of the accounts available in his wallet. Two permissions are supported. These are: basic - allows the site to retrieve data from the blockchain and use the API to decrypt transactions.accountInteraction - allows the page to prompt the user for transactions and perform other interactions such as signing a message. Asking the user for permission (connect the wallet): // Subscribe to new permissions (await ever.subscribe('permissionsChanged')).on('data', permissions = &gt; { // You can monitor changes in permissions there console.log('permissions from subscription', permissions); }); // The provider has several events to subscribe to // connected, disconnected, networkChanged, permissionsChanged, loggedOut // Or you can get new permissions there const permissions = await ever.requestPermissions({ permissions: ['basic', 'accountInteraction'] }); The response should look like following (may vary depending on the wallet address, public key, and wallet contract type) { &quot;accountInteraction&quot;: { &quot;address&quot;: &quot;0:3036eb00ab5e3e6824d564b53c4e37f999e8d3db2cb1d878db1d20ae3a5408b6&quot;, &quot;publicKey&quot;: &quot;8eea533b840a598af3975d139926ba7f3888d3226f8597732227fe0fbf3875ac&quot;, &quot;contractType&quot;: &quot;SafeMultisigWallet&quot; }, &quot;basic&quot;: true } You may want to provide “logout” and “change account” features in your app, using following interface: // To disconnect, you can use await ever.disconnect(); // or changeAccount await ever.changeAccount();  "},{"title":"NetworkId check​","type":1,"pageTitle":"Connect Wallet","url":"/develop/recipes/connect-wallet#networkid-check","content":"After we got the permissions, we can interact with the wallet and retrieve data from the blockchain. You may want to render different thing for differend networks (mainnet / testnet). Let’s assume our target contract is deployed in the testnet. We want to check the networkId to ensure, that we are connected correctly. everscale-inpage-provider // Subscribe to network changed event const networkSubscriber = await ever.subscribe('networkChanged'); networkSubscriber.on('data', (event) =&gt; { // track changes in the network id if (event.networkId === 2) { // We are on the testnet now } else { // Still not on the testnet } }); // You can use await networkSubscriber.unsubscribe(); to cancel the subscription const currentProviderState = await ever.getProviderState(); if (currentProviderState.networkId !== 2) { // Ask user to change the network } else { // Everything is okay }  "},{"title":"EVER SDK Quick Start","type":0,"sectionRef":"#","url":"/develop/recipes/ever-sdk-guides/ever-sdk-start","content":"","keywords":""},{"title":"Prerequisites​","type":1,"pageTitle":"EVER SDK Quick Start","url":"/develop/recipes/ever-sdk-guides/ever-sdk-start#prerequisites","content":"Node.js latest version installed Docker latest version installed "},{"title":"Prepare development environment​","type":1,"pageTitle":"EVER SDK Quick Start","url":"/develop/recipes/ever-sdk-guides/ever-sdk-start#prepare-development-environment","content":"Install EVERDEV CLI that will help you easily start local node, compile your contracts, install demo projects and create new empty projects. $ npm install -g everdev  "},{"title":"Start local node (SE)​","type":1,"pageTitle":"EVER SDK Quick Start","url":"/develop/recipes/ever-sdk-guides/ever-sdk-start#start-local-node-se","content":"We will run our test on local blockchain for testing (Evernode SE, start it with this command (docker should be launched). $ everdev se start  "},{"title":"Install demo application​","type":1,"pageTitle":"EVER SDK Quick Start","url":"/develop/recipes/ever-sdk-guides/ever-sdk-start#install-demo-application","content":"Create a working folder. Then create a node.js demo project with EVERDEV $ everdev js demo hello-wallet $ cd hello-wallet $ npm i  "},{"title":"What the script does​","type":1,"pageTitle":"EVER SDK Quick Start","url":"/develop/recipes/ever-sdk-guides/ever-sdk-start#what-the-script-does","content":"The script implements the following logic: Links the project with Node.js Ever-SDK binary. If you plan to use JS SDK in Web, link it with Wasm binary. Read more here.TONClient instance is created and initialized with Evernode SE (&quot;http://localhost&quot;, local blockchain) endpoint. See the list of other available endpoints.Future address is calculated from the code and data of the contract (data includes signing keys) Flag useGiver: true allows to sponsor deploy with Evernode SE giver that is hard coded as the default Account giver. You can re-assign it to your own giver. "},{"title":"Sample code​","type":1,"pageTitle":"EVER SDK Quick Start","url":"/develop/recipes/ever-sdk-guides/ever-sdk-start#sample-code","content":""},{"title":"Core API Implementation​","type":1,"pageTitle":"EVER SDK Quick Start","url":"/develop/recipes/ever-sdk-guides/ever-sdk-start#core-api-implementation","content":"(async () =&gt; { try { // Generate an ed25519 key pair const walletKeys = await client.crypto.generate_random_sign_keys(); // Calculate future wallet address. const walletAddress = await calcWalletAddress(walletKeys); // Send some tokens to `walletAddress` before deploy await getTokensFromGiver(walletAddress, 1_000_000_000); // Deploy wallet await deployWallet(walletKeys); // Get wallet's account info and print balance const accountState = await getAccount(walletAddress); console.log(&quot;Hello wallet balance is&quot;, accountState.balance) // Run account's get method `getTimestamp` let walletTimestamp = await runGetMethod('getTimestamp', walletAddress, accountState.boc ); console.log(&quot;`timestamp` value is&quot;, walletTimestamp) // Perform 2 seconds sleep, so that we receive an updated timestamp await new Promise(r =&gt; setTimeout(r, 2000)); // Execute `touch` method for newly deployed Hello wallet contract // Remember the logical time of the generated transaction let transLt = await runOnChain(walletAddress, &quot;touch&quot;); // Run contract's get method locally after account is updated walletTimestamp = await runGetMethodAfterLt('getTimestamp', walletAddress, transLt); console.log(&quot;Updated `timestamp` value is&quot;, walletTimestamp) // Send some tokens from Hello wallet to a random account // Remember the logical time of the generated transaction const destAddress = await genRandomAddress(); transLt = await sendValue(walletAddress, destAddress, 100_000_000, walletKeys); console.log('Normal exit'); process.exit(0); } catch (error) { if (error.code === 504) { console.error( [ 'Network is inaccessible. You have to start Evernode SE using `everdev se start`', 'If you run SE on another port or ip, replace http://localhost endpoint with', 'http://localhost:port or http://ip:port in index.js file.', ].join('\\n'), ); } else { console.error(error); process.exit(1); } } })(); async function calcWalletAddress(keys) { // Get future `Hello`Wallet contract address from `encode_message` result const { address } = await client.abi.encode_message(buildDeployOptions(keys)); console.log(`Future address of Hello wallet contract is: ${address}`); return address; } function buildDeployOptions(keys) { // Prepare parameters for deploy message encoding // See more info about `encode_message` method parameters here: // https://github.com/tonlabs/ever-sdk/blob/master/docs/reference/types-and-methods/mod_abi.md#encode_message const deployOptions = { abi: { type: 'Contract', value: HelloWallet.abi, }, deploy_set: { tvc: HelloWallet.tvc, initial_data: {}, }, call_set: { function_name: 'constructor', input: {}, }, signer: { type: 'Keys', keys, }, }; return deployOptions; } // Request funds from Giver contract async function getTokensFromGiver(dest, value) { console.log(`Transfering ${value} tokens from giver to ${dest}`); const params = { send_events: false, message_encode_params: { address: GIVER_ADDRESS, abi: abiContract(GIVER_ABI), call_set: { function_name: 'sendTransaction', input: { dest, value, bounce: false, }, }, signer: { type: 'Keys', keys: GIVER_KEYS, }, }, }; await client.processing.process_message(params); console.log('Success. Tokens were transfered\\n'); } async function deployWallet(walletKeys) { // Deploy `Hello wallet` contract // See more info about `process_message` here: // https://github.com/tonlabs/ever-sdk/blob/master/docs/reference/types-and-methods/mod_processing.md#process_message console.log('Deploying Hello wallet contract'); await client.processing.process_message({ send_events: false, message_encode_params: buildDeployOptions(walletKeys), }); console.log('Success. Contract was deployed\\n'); } async function runOnChain(address, methodName) { // Encode the message with external call const params = { send_events: false, message_encode_params: { address, abi: { type: 'Contract', value: HelloWallet.abi, }, call_set: { function_name: methodName, input: {}, }, signer: signerNone(), }, }; console.log(`Calling ${methodName} function`); const response = await client.processing.process_message(params); const { id, lt } = response.transaction; console.log('Success. TransactionId is: %s\\n', id); return lt; } // Sometimes it is needed to execute getmethods after on-chain calls. // This means that the downloaded account state should have the changes made by the on-chain call. // To ensure it, we need to remember the transaction lt (logical time) of the last call // and then wait for the account state to have lt &gt; the transaction lt. // Note that account.last_trans_lt is always bigger than transaction.lt because this field stores the end lt of transaction interval // For more information about transaction lt interval read TON Blockchain spec https://test.ton.org/tblkch.pdf P. 4.2.1 async function waitForAccountUpdate(address, transLt) { console.log('Waiting for account update'); const startTime = Date.now(); const account = await client.net.wait_for_collection({ collection: 'accounts', filter: { id: { eq: address }, last_trans_lt: { gt: transLt }, }, result: 'boc', }); const duration = Math.floor((Date.now() - startTime) / 1000); console.log(`Success. Account was updated, it took ${duration} sec.\\n`); return account; } async function getAccount(address) { // `boc` or bag of cells - native blockchain data layout. Account's boc contains full account state (code and data) that // we will need to execute get methods. const query = ` query { blockchain { account( address: &quot;${address}&quot; ) { info { balance(format: DEC) boc } } } }` const {result} = await client.net.query({query}) const info = result.data.blockchain.account.info return info } async function runGetMethod(methodName, address, accountState) { // Execute the get method `getTimestamp` on the latest account's state // This can be managed in 3 steps: // 1. Download the latest Account State (BOC) // 2. Encode message // 3. Execute the message locally on the downloaded state // Encode the message with `getTimestamp` call const { message } = await client.abi.encode_message({ // Define contract ABI in the Application // See more info about ABI type here: // https://github.com/tonlabs/ever-sdk/blob/master/docs/reference/types-and-methods/mod_abi.md#abi abi: { type: 'Contract', value: HelloWallet.abi, }, address, call_set: { function_name: methodName, input: {}, }, signer: { type: 'None' }, }); // Execute `getTimestamp` get method (execute the message locally on TVM) // See more info about run_tvm method here: // https://github.com/tonlabs/ever-sdk/blob/master/docs/reference/types-and-methods/mod_tvm.md#run_tvm console.log('Run `getTimestamp` get method'); const response = await client.tvm.run_tvm({ message, account: accountState, abi: { type: 'Contract', value: HelloWallet.abi, }, }); return response.decoded.output } async function runGetMethodAfterLt(methodName, address, transLt) { // Wait for the account state to be more or equal the spesified logical time const accountState = await waitForAccountUpdate(address, transLt).then(({ result }) =&gt; result.boc); const result = await runGetMethod(methodName, address, accountState); return result; } async function sendValue(address, dest, amount, keys) { // Encode the message with `sendValue` function call const sendValueParams = { send_events: false, message_encode_params: { address, // Define contract ABI in the Application // See more info about ABI type here: // https://github.com/tonlabs/ever-sdk/blob/master/docs/reference/types-and-methods/mod_abi.md#abi abi: { type: 'Contract', value: HelloWallet.abi, }, call_set: { function_name: 'sendValue', input: { dest, amount, bounce: false, }, }, signer: signerKeys(keys), }, }; console.log(`Sending ${amount} tokens to ${dest}`); // Call `sendValue` function const response = await client.processing.process_message(sendValueParams); console.log('Success. Target account will recieve: %d tokens\\n', response.fees.total_output); return response.transaction.lt; }  "},{"title":"AppKit API Implementation​","type":1,"pageTitle":"EVER SDK Quick Start","url":"/develop/recipes/ever-sdk-guides/ever-sdk-start#appkit-api-implementation","content":"async function main(client) { // Generate an ed25519 key pair for new account const keys = await TonClient.default.crypto.generate_random_sign_keys(); const helloAcc = new Account(HelloWallet, { signer: signerKeys(keys), client, }); const address = await helloAcc.getAddress(); console.log(`Future address of the contract will be: ${address}`); // Request contract deployment funds form a local Evernode SE giver // not suitable for other networks. // Deploy `hello` contract. await helloAcc.deploy({ useGiver: true }); console.log(`Hello contract was deployed at address: ${address}`); // Call `touch` function on-chain // On-chain execution can be done with `run` function. let response = await helloAcc.run(&quot;touch&quot;, {}); console.log(`touch execution transaction is ${response.transaction.id}`); // Read local variable `timestamp` with a get method `getTimestamp` // This can be done with `runLocal` function. The execution of runLocal is performed off-chain and does not // cost any gas. response = await helloAcc.runLocal(&quot;getTimestamp&quot;, {}); console.log(&quot;getTimestamp value:&quot;, response.decoded.output) // Send some money to the random address const randomAddress = &quot;0:&quot; + Buffer.from((await client.crypto.generate_random_bytes({length: 32})).bytes, &quot;base64&quot;).toString(&quot;hex&quot;); response = await helloAcc.run(&quot;sendValue&quot;, { dest: randomAddress, amount: 100_000_000, // 0.1 token bounce: true, // delivery will fail and money will be returned back because the random account does not exist. }); console.log(`The tokens were sent, but soon they will come back because bounce = true and destination address does not exist`); } (async () =&gt; { const client = new TonClient({ network: { // Local Evernode-SE instance URL here endpoints: [&quot;http://localhost&quot;] } }); try { console.log(&quot;Hello localhost!&quot;); await main(client); process.exit(0); } catch (error) { if (error.code === 504) { console.error(`Network is inaccessible. You have to start Evernode SE using \\`everdev se start\\`.\\n If you run SE on another port or ip, replace http://localhost endpoint with http://localhost:port or http://ip:port in index.js file.`); } else { console.error(error); } } client.close(); })();  "},{"title":"Run it!​","type":1,"pageTitle":"EVER SDK Quick Start","url":"/develop/recipes/ever-sdk-guides/ever-sdk-start#run-it","content":""},{"title":"Core API​","type":1,"pageTitle":"EVER SDK Quick Start","url":"/develop/recipes/ever-sdk-guides/ever-sdk-start#core-api","content":"Run: $ node core  You will see the result of core.js file execution. Core.js file demonstrades core ever-sdk api. It is the same for all ever-sdk bindings. node core Future address of Hello wallet contract is: 0:1863addf562c5ab98f3761787458e47406675379a4dc6eb36042ba84bde5cb8d Transfering 1000000000 tokens from giver to 0:1863addf562c5ab98f3761787458e47406675379a4dc6eb36042ba84bde5cb8d Success. Tokens were transfered Deploying Hello wallet contract Success. Contract was deployed Hello wallet balance is 986483999 Run `getTimestamp` get method `timestamp` value is { value0: '0x000000000000000000000000000000000000000000000000000000006373fbb4' } Calling touch function Success. TransactionId is: 1a34fbfc336ff8212793077c68bff9f49c6c3f270492afa55ca616ef40b22bec Waiting for account update Success. Account was updated, it took 0 sec. Run `getTimestamp` get method Updated `timestamp` value is { value0: '0x000000000000000000000000000000000000000000000000000000006373fbb6' } Sending 100000000 tokens to 0:9f98e8de89e19093145afe134017a783daf8bac5dee04b8810c57a348020764c Success. Target account will recieve: 99000000 tokens Normal exit  "},{"title":"Appkit API​","type":1,"pageTitle":"EVER SDK Quick Start","url":"/develop/recipes/ever-sdk-guides/ever-sdk-start#appkit-api","content":"Run: $ node appkit  You will see the result of appkit.js file execution. Appkit.js demonstrates high level Appkit package. Hello localhost! Future address of the contract will be: 0:5aab70b197897e47ee65faca0ebe24244fd1373d31de2ae39aca28029e0f3469 Hello contract was deployed at address: 0:5aab70b197897e47ee65faca0ebe24244fd1373d31de2ae39aca28029e0f3469 touch execution transaction is 495d0b02905ac541b54407283e52155fbfcbcc804a82ca40d5da96e433fe2f6b getTimestamp value: { value0: '0x000000000000000000000000000000000000000000000000000000006373fa68' } The tokens were sent, but soon they will come back because bounce = true and destination address does not exist  "},{"title":"Source code​","type":1,"pageTitle":"EVER SDK Quick Start","url":"/develop/recipes/ever-sdk-guides/ever-sdk-start#source-code","content":"You can find full source code of this sample here https://github.com/tonlabs/sdk-samples/tree/master/demo/hello-wallet "},{"title":"Full docs​","type":1,"pageTitle":"EVER SDK Quick Start","url":"/develop/recipes/ever-sdk-guides/ever-sdk-start#full-docs","content":"See original guide at https://docs.everos.dev/ever-sdk/quick_start Full EVER SDK documenation is available at https://docs.everos.dev/ever-sdk/ "},{"title":"Other EVER SDK Guides","type":0,"sectionRef":"#","url":"/develop/recipes/ever-sdk-guides/other-sdk-guides","content":"Other EVER SDK Guides This is a list of detailed guides for EVER SDK EVER SDK Installation Add SDK to your App EVER SDK Configuration Endpoint ConfigurationMessage ExpirationMessage RetryConfig Reference Work with contracts in EVER SDK Add Contract to your AppUse your own GiverDeploy ContractRun Contract on-chainRun ABI Get MethodRun Fift Get MethodQuery/Subscribe for messages(events)Decode Messages(Event)External SigningEmulate TransactionEstimate FeesValidate address, convert addressMonitor messagesTrace message processing with REMP Crypto fucntions in EVER SDK Mnemonics and Keys Queries and subscriptions in EVER SDK Use-casesHow to work with net modulenet.query syntaxData paginationSubscribe to UpdatesQuery CollectionAggregate Collection","keywords":""},{"title":"Add EVER to your backend","type":0,"sectionRef":"#","url":"/develop/recipes/backend-integration","content":"","keywords":""},{"title":"Introduction​","type":1,"pageTitle":"Add EVER to your backend","url":"/develop/recipes/backend-integration#introduction","content":"This document describes the various ways to accomplish the most important tasks of running a backend application that supports EVER. There are a few different ways to accomplish the necessary tasks: Blockchain access may be set up either through the Evercloud or through your own supernode - the DApp server.User account management can be accomplished either through the everdev command line tool or integrate into your backend with Ever SDK client libraries. Both of these approaches are compatible with either of the blockchain access setups. "},{"title":"Setting up Blockchain Access​","type":1,"pageTitle":"Add EVER to your backend","url":"/develop/recipes/backend-integration#setting-up-blockchain-access","content":""},{"title":"Using Evercloud​","type":1,"pageTitle":"Add EVER to your backend","url":"/develop/recipes/backend-integration#using-evercloud","content":"Using Evercloud allows you to work with TVM blockchains without having to run your own node. Everdev and SDK can connect to it, as if it were a regular node. It has the same API as a node, and provides all needed capabilities. This page lists the cloud endpoints. To get access credentials go through this guide. Whenever you have to specify a network endpoint in the examples given below, use the endpoints and credentials you receive in the Evercloud dashboard. Note: We recommend testing out the full setup on the developer network first. "},{"title":"Using DApp Server​","type":1,"pageTitle":"Add EVER to your backend","url":"/develop/recipes/backend-integration#using-dapp-server","content":"If you prefer to run your own node, you may set up your own DApp server. It is a client supernode, that may be set up on your own servers and provide full access to TVM networks. To connect to it with Everdev or SDK, it needs to have a domain name and a DNS record. You can specify its URL whenever you have to set the network in the examples given below. Get the setup scripts in this repository: https://github.com/tonlabs/evernode-ds 1. System Requirements​ Configuration\tCPU (cores)\tRAM (GiB)\tStorage (GiB)\tNetwork (Gbit/s)Recommended\t24\t128\t2000\t1 NVMe SSD disks are recommended for storage. For simplicity, all services are deployed on one host and the system requirements for it are high, so it makes sense to distribute services across different servers. After understanding this installation process, you can easily customize it for yourself. itgoldio/everscale-dapp-server: Consider this project if you prefer deployment via Ansible. 2.1 Prerequisites​ Host OS: Linux (all scripts tested on Ubuntu 20.04).DApp server is accessed via HTTPS, so your server must have a fully qualified domain name.\\ A self-signed certificate will be received on start-up and will be renewed automatically.Installed Git, Docker Engine, Docker CLI, Docker Compose v2 or later. 2.2 Configuration​ 2.2.1 Set variables Check configure.sh and set at least these environment variables: NETWORK_TYPEEVERNODE_FQDNLETSENCRYPT_EMAIL 2.2.2 Generate credentials to access the ArangoDB web interface Generate credentials (usernames and password) for basic authentication and update .htpasswd file. You can generate it by running htpasswd -nb &lt;name&gt; &lt;password&gt; 2.2.3 Run configuration script $ ./configure.sh  This script creates ./deploy directory 2.3 Deployment​ Run ./up.sh. After the script completes normally (it takes 30 min approx.), the node starts synchronizing its state, which can take several hours.\\ Use the following command to check the progress:  docker exec rnode /ton-node/tools/console -C /ton-node/configs/console.json --cmd getstats  Script output example: tonlabs console 0.1.286 COMMIT_ID: 5efe6bb8f2a974ba0e6b1ea3e58233632236e182 BUILD_DATE: 2022-10-17 02:32:44 +0300 COMMIT_DATE: 2022-08-12 00:22:07 +0300 GIT_BRANCH: master { &quot;sync_status&quot;: &quot;synchronization_finished&quot;, &quot;masterchainblocktime&quot;: 1665988670, &quot;masterchainblocknumber&quot;: 9194424, &quot;node_version&quot;: &quot;0.51.1&quot;, &quot;public_overlay_key_id&quot;: &quot;S4TaVdGitzTApe7GFCj8DbuRIkVEbg+ODzBxhQGIUG0=&quot;, &quot;timediff&quot;: 6, &quot;shards_timediff&quot;: 6, ----%&lt;--------------------- }  If the timediff parameter is less than 10 seconds, synchronization with masterchain is complete.\\&quot;sync_status&quot;: &quot;synchronization finished&quot; means synchronization with workchains is complete "},{"title":"Setting up Wallet Account​","type":1,"pageTitle":"Add EVER to your backend","url":"/develop/recipes/backend-integration#setting-up-wallet-account","content":"Currently we can recommend the SetcodeMultisig contract for use in user accounts. It is well tested and secure, supports multiple custodians, and can be set up to require several independent signatures for any transfers. Alternatively, you may use the Ever Wallet contract. It has some different features and capabilities. You can read about them and find the contract files in this repository. Note: Ever Wallet however is not currently supported by Everdev CLI tool, so only the SDK approach will work for it. If you choose it, you only need to examine the SDK sections with Ever Wallet samples. "},{"title":"Using CLI tool​","type":1,"pageTitle":"Add EVER to your backend","url":"/develop/recipes/backend-integration#using-cli-tool","content":"Everdev, the command line tool for development on the Everscale blockchain, allows to write scripts to deploy any smart contracts to the blockchain, call all contract methods, sign transactions, and generally manage an account. It works with both Evercloud and DApp server. 1. Install Everdev​ $ npm install -g everdev  It requires NPM to be installed. If you experience any problems with installation, check out our troubleshooting section. 2. Configure network connection​ Everdev has a built-in network tool to manage your networks and access credentials. Using Evercloud endpoints Add your Evercloud endpoint to everdev and make it default: everdev network add networkName &lt;your-evercloud-endpoint&gt; everdev network default networkName  Using DApp Server endpoint If you are setting up a connection via your own DApp server, user the following command to add it to the network list (it will be named dappserver). everdev network add dappserver &lt;your_dapp_server_endpoint&gt;  To set your dappserver network as default, use the following command: everdev network default dappserver  3. Set a giver contract on your network​ On Everscale, you need to sponsor a contract address in advance to be able to deploy the contract. Everdev provides a way to set an account of your choice as a giver for deployment operations, so you will not have to do a separate step of sending tokens to a new contract address every time you deploy something. This contract can some multisig wallet, for example your Surf account. Note: To work automatically, the giver contract should have only one custodian. To set it up, first save the custodian keys of your giver account into a signer that will be used to sign giver transactions (Learn more about the signer tool here): everdev signer add giver_sign signer_secret_key_or_seed_phrase_in_quotes  Then add the giver address specifying the signer to be used with it. everdev network giver network_name giver_address --signer giver_sign --type giver_type  Where giver_type is the type of the giver contract you selected (GiverV1 | GiverV2 | GiverV3 | SafeMultisigWallet | MsigV2| SetcodeMultisigWallet) We recommend using Multisig 2.0 as giver, for that use MsigV2 giver_type. 4. Get wallet account contract files​ We recommend using Multisig 2.0 contracts as a wallet. They can be found here. In this guide SetcodeMultisig specifically is used. Download the contract files and place them in the working folder. Direct links to its files are as follows: .tvc - Compiled contract code SetcodeMultisig.tvc direct link: https://github.com/EverSurf/multisig2/raw/main/build/SetcodeMultisig.tvc .abi.json - application binary interface, describing the functions of the contract SetcodeMultisig.abi.json direct link: https://raw.githubusercontent.com/EverSurf/multisig2/main/build/SetcodeMultisig.abi.json Execute the commands of the following steps from the directory with the contract files. 5. Create wallet account signer​ To generate your wallet account signer enter the following command: everdev signer generate wallet_signer  Or, if you already have a seed phrase, add it like this: everdev signer add &quot;your-seed-phrase-here&quot;  To deploy multisig wallet account you will need to specify the public key of the signer. To view it, use the following command: everdev signer info wallet_signer  The keys will be displayed in terminal (if you imported the seed phrase, it will be displayed here as well): { &quot;name&quot;: &quot;wallet_signer&quot;, &quot;description&quot;: &quot;&quot;, &quot;keys&quot;: { &quot;public&quot;: &quot;8f8779e7c1944b133a423df96d06ae770c996f19d63438dbf2f569a29529b248&quot;, &quot;secret&quot;: &quot;ce57d2666d0d2c737a03ca4e6cfa38c5ca088dbcef43eb0353896feca8aea2a5&quot; } }  Usually a single owner (with a single signer) per wallet account is optimal for any tasks that require automation. However, it is possible to set up accounts with multiple owners. In this case, each of the owners has to generate their own signer and provide their public keys to the deployer. Also, the signer used to deploy the account doesn't have to be among its owners. 6. Deploy the wallet account contract to blockchain​ Use the following command for a simple one-owner account: everdev contract deploy SetcodeMultisig.abi.json constructor --signer wallet_signer --input owners:[&lt;owner_public_key&gt;],reqConfirms:1,lifetime:3600 --value 1000000000  Where value parameter is the amount of nanotokens to be spent on deployment (can be omitted, in which case 10 tokens from giver will be spent) owner_public_key is usually the public key of wallet_signer in the form 0x.... lifetime - time in seconds that a transaction in multi-owner accounts will persits and be available for signing by other owners. For a simple multi owner account may be set to any value, as it will be executed immediately anyway. Example: everdev contract deploy SetcodeMultisig.abi.json constructor --signer wallet_signer --input owners:[0x8f8779e7c1944b133a423df96d06ae770c996f19d63438dbf2f569a29529b248],reqConfirms:1,lifetime:3600 --value 1000000000  For more complex cases (multiple owners etc.) view Everdev contract tool docs. Once the contract is deployed, its address will be displayed in terminal. everdev contract deploy SetcodeMultisig.abi.json constructor --signer wallet_signer --input owners:[0x3da1909b7a4bd11fd9a1d79ca9713a9a8645880e0a7a12f9691c68e95d56fe75],reqConfirms:1,lifetime:3600 --value 10000000000 Configuration Network: dev (devnet.evercloud.dev) Signer: wallet_signer (public 8f8779e7c1944b133a423df96d06ae770c996f19d63438dbf2f569a29529b248) Address: 0:95c35b94e98c1b5c7716a9129ed5bb0798c8c336465fd8d1eb0d385e3d969494 (calculated from TVC and signer public) Parameters of constructor: owners (uint256[]): [&quot;0x3da1909b7a4bd11fd9a1d79ca9713a9a8645880e0a7a12f9691c68e95d56fe75&quot;] reqConfirms (uint8): &quot;1&quot; lifetime (uint32): &quot;3600&quot; Deploying... Contract is deployed at address: 0:95c35b94e98c1b5c7716a9129ed5bb0798c8c336465fd8d1eb0d385e3d969494  "},{"title":"Using SDK​","type":1,"pageTitle":"Add EVER to your backend","url":"/develop/recipes/backend-integration#using-sdk","content":"You may integrate above described process of wallet account deployment into your backend code. The functionality is supported in SDK. Bindings for a large number of languages have been developed for SDK. Note, that similar to the Everdev approach described above, you have to sponsor a user account before deploying contract code. The sample assumes you use the devnet faucet of Evercloud Dashboard, where you can request test tokens to the contract address generated by the samples. In a production environment you may set up a giver to sponsor your contract deployment operations. An example of such a set up can be found in this sample. Multisig Wallet​ A sample is available in this repository and an overview is given below. The recommended SetcodeMultisig contract is used.  // 1. ------------------ Deploy multisig wallet -------------------------------- // // Generate a key pair for the wallet to be deployed const keypair = await client.crypto.generate_random_sign_keys(); // TODO: Save generated keypair! console.log('Generated wallet keys:', JSON.stringify(keypair)) console.log('Do not forget to save the keys!') const msigABI: string = readFileSync(path.resolve(__dirname, &quot;../contract/SetcodeMultisig.abi.json&quot;)).toString(&quot;utf8&quot;) const msigCode: string = readFileSync(path.resolve(__dirname, &quot;../contract/SetcodeMultisig.code.boc&quot;)).toString(&quot;base64&quot;) // We need to know the future address of the wallet account, // because its balance must be positive for the contract to be deployed // // Future address can be calculated from code and data of the contract // // For solidity contracts of version up to *** // initial data consists of pubkey + all static contract variables // and can be packed like this: const initData = (await client.abi.encode_boc({ params: [ { name: &quot;data&quot;, type: &quot;map(uint64,uint256)&quot; } ], data: { &quot;data&quot;: { 0: `0x`+keypair.public // 1: 1st-static-variable-value // 2: 2nd-static-variable-value }, } })).boc; console.log('Init data', initData); // Lets construct the initial state of the contract const stateInit = (await client.boc.encode_state_init({ code:msigCode, data:initData })).state_init; // Address is the TVM hash of the initial state + workchain id (we work in 0 workchain) const msigAddress = `0:`+(await client.boc.get_boc_hash({boc: stateInit})).hash; console.log('Address: ', msigAddress); console.log(`You can topup your wallet from dashboard at https://dashboard.evercloud.dev`) console.log(`Please send &gt;= ${MINIMAL_BALANCE} tokens to ${msigAddress}`) console.log(`awaiting...`) // Blocking here, waiting for account balance changes. // It is assumed that at this time you go to dashboard.evercloud.dev // and replenish this account. let balance: number let accType: number for (; ;) { // The idiomatic way to send a request is to specify // query and variables as separate properties. const getInfoQuery = ` query getBalance($address: String!) { blockchain { account(address: $address) { info { balance acc_type } } } } ` const resultOfQuery: ResultOfQuery = await client.net.query({ query: getInfoQuery, variables: { address: msigAddress } }); const accountInfo = resultOfQuery.result.data.blockchain.account.info; const nanotokens = parseInt(accountInfo.balance, 16) accType = accountInfo.acc_type; if (nanotokens &gt;= MINIMAL_BALANCE * 1e9) { balance = nanotokens / 1e9 break } // TODO: rate limiting await sleep(1000) } console.log(`Account balance is: ${balance.toString(10)} tokens. Account type is ${accType}`) console.log(`Deploying wallet contract to address: ${msigAddress} and waiting for transaction...`) // Encode the body with constructor call let body = (await client.abi.encode_message_body({ address: msigAddress, abi: { type: 'Json', value: msigABI }, call_set: { function_name: 'constructor', input: { owners: [`0x${keypair.public}`], reqConfirms: 1, lifetime: 3600 } }, is_internal:false, signer:{type: 'Keys', keys: keypair} })).body; let deployMsg = await client.boc.encode_external_in_message({ dst: msigAddress, init: stateInit, body: body }); let sendRequestResult = await client.processing.send_message({ message: deployMsg.message, send_events: false }); let transaction = (await client.processing.wait_for_transaction({ abi: { type: 'Json', value: msigABI }, message: deployMsg.message, shard_block_id: sendRequestResult.shard_block_id, send_events: false })).transaction; console.log('Contract deployed. Transaction hash', transaction?.id) assert.equal(transaction?.status, 3) assert.equal(transaction?.status_name, &quot;finalized&quot;)  Ever Wallet​ A sample is available in this repository and an overview is given below. The Ever Wallet contract is used.  // 1. ------------------ Deploy ever-wallet -------------------------------- // // Generate a key pair for the wallet to be deployed const keypair = await client.crypto.generate_random_sign_keys(); // TODO: Save generated keypair! console.log('Generated wallet keys:', JSON.stringify(keypair)) console.log('Do not forget to save the keys!') // To deploy a wallet we need its code and ABI files const everWalletCode: string = readFileSync(path.resolve(__dirname, &quot;../contract/Wallet.code.boc&quot;)).toString(&quot;base64&quot;) const everWalletABI: string = readFileSync(path.resolve(__dirname, &quot;../contract/everWallet.abi.json&quot;)).toString(&quot;utf8&quot;) const initData = (await client.abi.encode_boc({ params: [ { name: &quot;publicKey&quot;, type: &quot;uint256&quot; }, { name: &quot;timestamp&quot;, type: &quot;uint64&quot; } ], data: { &quot;publicKey&quot;: `0x`+keypair.public, &quot;timestamp&quot;: 0 } })).boc; console.log('Init data', initData); const stateInit = (await client.boc.encode_state_init({ code:everWalletCode, data:initData })).state_init; const everWalletAddress = `0:`+(await client.boc.get_boc_hash({boc: stateInit})).hash; console.log('Address: ', everWalletAddress); console.log(`You can topup your wallet from dashboard at https://dashboard.evercloud.dev`) console.log(`Please send &gt;= ${MINIMAL_BALANCE} tokens to ${everWalletAddress}`) console.log(`awaiting...`) // Blocking here, waiting for account balance changes. // It is assumed that at this time you go to dashboard.evercloud.dev // and replenish this account. let balance: number for (; ;) { // The idiomatic way to send a request is to specify // query and variables as separate properties. const getBalanceQuery = ` query getBalance($address: String!) { blockchain { account(address: $address) { info { balance } } } } ` const resultOfQuery: ResultOfQuery = await client.net.query({ query: getBalanceQuery, variables: { address: everWalletAddress } }) const nanotokens = parseInt(resultOfQuery.result.data.blockchain.account.info?.balance, 16) if (nanotokens &gt;= MINIMAL_BALANCE * 1e9) { balance = nanotokens / 1e9 break } // TODO: rate limiting await sleep(1000) } console.log(`Account balance is: ${balance.toString(10)} tokens`) console.log(`Making first transfer+deploy from ever-wallet contract to address: -1:7777777777777777777777777777777777777777777777777777777777777777 and waiting for transaction...`) // Here we construct body by ABI // and then add state init to the message for deploy let body = (await client.abi.encode_message_body({ address: everWalletAddress, abi: { type: 'Json', value: everWalletABI }, call_set: { function_name: 'sendTransaction', input: { dest: '-1:7777777777777777777777777777777777777777777777777777777777777777', value: '1000000000', // amount in nano EVER bounce: false, flags: 3, payload: '' } }, is_internal:false, signer:{type: 'Keys', keys: keypair} })).body; let deployAndTransferMsg = await client.boc.encode_external_in_message({ dst: everWalletAddress, init: stateInit, body: body }); let sendRequestResult = await client.processing.send_message({ message: deployAndTransferMsg.message, send_events: false }); let transaction = (await client.processing.wait_for_transaction({ abi: { type: 'Json', value: everWalletABI }, message: deployAndTransferMsg.message, shard_block_id: sendRequestResult.shard_block_id, send_events: false })).transaction; console.log('Contract deployed. Transaction hash', transaction.id) assert.equal(transaction.status, 3) assert.equal(transaction.status_name, &quot;finalized&quot;)  "},{"title":"Monitoring transactions​","type":1,"pageTitle":"Add EVER to your backend","url":"/develop/recipes/backend-integration#monitoring--transactions","content":"Lets assume we need to reliably know when customers receive or transfer funds from their wallets. Samples of transaction pagination and subscription are available in the samples repository. An overview of the relevant parts is given below. In these samples JS SDK is used. Bindings for a large number of languages have been developed for SDK. "},{"title":"Pagination​","type":1,"pageTitle":"Add EVER to your backend","url":"/develop/recipes/backend-integration#pagination","content":"The pagination sample queries and displays transactions in workchain 0 (workchain where simple transfers happen, -1 workchain is masterchain where you can find service transactions and validator transactions) from the beginning. We can get all the transaction and filter by account addresses on the backend side. Note: By default the Blockchain API queries, such as the one used here provide only data from the past 7 days. To retrieve older data, make sure to use the archive: true flag, as shown in the sample:  async function main(client: TonClient) { // In this example, we want the query to return 2 items per page. const itemsPerPage = 25 // Pagination connection pattern requires a cursor, which will be set latter let cursor: string = undefined // The idiomatic way to send a request is to specify // query and variables as separate properties. const transactionsQuery = ` query listTransactions($cursor: String, $count: Int) { blockchain { transactions( workchain: 0 archive: true first: $count after: $cursor ) { edges { node { id balance_delta account_addr # other transaction fields } } pageInfo { hasNextPage endCursor } } } }` for (; ;) { const queryResult: ResultOfQuery = await client.net.query({ query: transactionsQuery, variables: { count: itemsPerPage, cursor } }); const transactions = queryResult.result.data.blockchain.transactions; for (const edge of transactions.edges) { console.log(&quot;Transaction id:&quot;, edge.node.id); } if (transactions.pageInfo.hasNextPage === false) { break; } // To read next page we initialize the cursor: cursor = transactions.pageInfo.endCursor; // TODO: rate limiting await sleep(1000); } } console.log(&quot;Getting all transactions in workchain 0 from the beginning/&quot;) console.log(&quot;Most likely this process will never end, so press CTRL+C to interrupt it&quot;) main(client) .then(() =&gt; { process.exit(0) }) .catch(error =&gt; { console.error(error); process.exit(1); }) // This helper function is used for limiting request rate function sleep(ms: number) { return new Promise(r =&gt; setTimeout(r, ms)) }  "},{"title":"Subscription​","type":1,"pageTitle":"Add EVER to your backend","url":"/develop/recipes/backend-integration#subscription","content":"Subscription sample subscribes to new transactions of the listed accounts and lists them as they appear. async function main() { try { const client = new TonClient({ network: { endpoints: [endpoint] } }) const queryText = ` subscription my($list: [String!]!){ transactions( filter: {account_addr: { in: $list }} ) { id account_addr balance_delta } }` // use `client.net.unsubscribe({ handle })` to close subscription // eslint-disable-next-line @typescript-eslint/no-unused-vars const { handle } = await client.net.subscribe( { subscription: queryText, variables: { list: addressList } }, responseHandler, ); console.log(&quot;Subscribed to transactions of accounts:&quot;, JSON.stringify(addressList)) console.log(&quot;Press CTRL+C to interrupt it&quot;) } catch (error) { if (error.code === 504) { console.error('Network is inaccessible.'); } else { console.error(error); } process.exit(1); } } // eslint-disable-next-line @typescript-eslint/no-explicit-any function responseHandler(params: any, responseType: number) { // Tip: Always wrap the logic inside responseHandler in a try-catch block // or you will be surprised by non-informative errors due to the context // in which the handler is executed try { if (responseType === 100 /* GraphQL data received */) { if (params?.result) { console.log(params.result); } } else { // See full list of error codes here: // https://docs.everos.dev/ever-sdk/reference/types-and-methods/mod_net#neterrorcode console.error(params, responseType); } } catch (err) { console.log(err); } }  You may test out the demo application running this process on the developer network by cloning the sdk-samples repository, creating a project in https://dashboard.evercloud.dev, exporting the API endpoint as an environment variable: export ENDPOINT=https://devnet.evercloud.dev/&lt;your_project_id&gt;/graphql  and running the following command in the /demo/subscribe-transactions folder: npm run subscribe-tr  Note: Not all transactions that are successful are valid transfers and not all transactions that are aborted actually failed. Read here how to understand which transfers are successful transfers and which are not. "},{"title":"Withdrawing from wallet accounts​","type":1,"pageTitle":"Add EVER to your backend","url":"/develop/recipes/backend-integration#withdrawing-from-wallet-accounts","content":"The specific function that is used to withdraw the funds depends on the contract chosen for the wallet account. Examples provided below are applicable for the SetcodeMultisig contract and (in the case of the relevant SDK section, as only SDK currently supports it) Ever Wallet contract. "},{"title":"Using CLI tool​","type":1,"pageTitle":"Add EVER to your backend","url":"/develop/recipes/backend-integration#using-cli-tool-1","content":"Command line Everdev tool may be used to automate withdrawals from wallet account in your scripts. If the user made a mistake in the destination address, and has no control over it, these funds will be lost forever. If the account does not exist, and the user makes mistakes deploying it after the funds are transferred, they may end up being lost as well. So, to perform a simple transfer from a single-owner user account to any specified account, we should make sure that it is already deployed, by setting bounce flag to true. If the account does not exist, funds will return back. everdev contract run SetcodeMultisig.abi.json sendTransaction --address &lt;wallet_account_address&gt; --signer wallet_signer --input dest:recipient_address,value:50000000000,bounce:true,flags:3,payload:&quot;&quot;  &lt;wallet_account_address&gt; - address of the user account. Example: 0:7bf2b2ec80371601f854bff9ed0a1171714d922c8bfc86d39e67a7e3a41b2176 wallet_signer - name of the user account owner signer recipient_address - raw address of the recipient smart contract. Example: 255a3ad9dfa8aa4f3481856aafc7d79f47d50205190bd56147138740e9b177f3 value: - amount of tokens to transfer in nanotokens (Example: value:10000000000 sets up a transfer of 10 tokens). bounce - use true to transfer funds only to deployed accounts. flags - use 3 for a simple transfer. payload - use &quot;&quot; for simple transfer. Note: To transfer all funds from the account use sendTransaction method with flag 130 and value 0. everdev contract run SetcodeMultisig.abi.json --address &lt;wallet_account_address&gt; sendTransaction --signer wallet_signer --input dest:recipient_address,value:0,bounce:true,flags:130,payload:&quot;&quot;  Example of regular withdrawal transaction on a single-owner multisig: everdev contract run SetcodeMultisig.abi.json sendTransaction --signer wallet_signer --input dest:665a62042aff317ba3f32e36b712b0f4a9d35277dd76dc38c9762cc6421681cf,value:500000000000,bounce:false,flags:3,payload:&quot;&quot; Configuration Network: dev (devnet.evercloud.dev) Signer: wallet_signer (public 3da1909b7a4bd11fd9a1d79ca9713a9a8645880e0a7a12f9691c68e95d56fe75) Address: 0:95c35b94e98c1b5c7716a9129ed5bb0798c8c336465fd8d1eb0d385e3d969494 Parameters of sendTransaction: dest (address): &quot;665a62042aff317ba3f32e36b712b0f4a9d35277dd76dc38c9762cc6421681cf&quot; value (uint128): &quot;500000000000&quot; bounce (bool): &quot;false&quot; flags (uint8): &quot;3&quot; payload (cell): &quot;&quot; Running... Execution has finished with result: { &quot;transaction&quot;: { &quot;json_version&quot;: 8, &quot;id&quot;: &quot;cbeb7f8b1aa7ac89439d9c6772b699a7c042215cef090f206ecc8b21bb230fc9&quot;, &quot;boc&quot;: &quot;te6ccgECDwEAArcAA7d5XDW5TpjBtcdxapEp7VuweYyMM2Rl/Y0esNOF49lpSUAAAOakEwMsEkhiumuyPgwNDWXdmNBHsr9g6Y6XgsntCG/AQxbMH/mAAADmo/0T8BZCW1XwAFSAICQ36AUEAQIPDE/GHimDxEADAgBvyY9CQExRYUAAAAAAAAQAAAAAAARz+2ts0g+y9Ais9VbZ65O+4BourUTTYoPq+tvoLxFJpECQJNQAnUZPYxOIAAAAAAAAAABYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAAgnI1Aq0GL7DtfZycdkRDzfxJtFk47dtGidJveUmyV1aRWS0JxA5UCIBaO/paLFUAjm0/YFLGbVz5bUyQ5fEsfxqwAgHgCwYCAd0JBwEBIAgAdeAErhrcp0xg2uO4tUiU9q3YPMZGGbIy/saPWGnC8ey0pKAAABzUgmBlhshLar5JjsFmgAAAAAAAAABAAQEgCgCzSAErhrcp0xg2uO4tUiU9q3YPMZGGbIy/saPWGnC8ey0pKQAZlpiBCr/MXuj8y42txKw9KnTUnfddtw4yXYsxkIWgc9XRqUogAAYUWGAAABzUgmBlhMhLar5AAUWIASuGtynTGDa47i1SJT2rdg8xkYZsjL+xo9YacLx7LSkoDAwB4fRRR+puAACR3O0hyRMPrwVnVPX+pw1OSY/hvAY+6jc/0ST0CDjZIS4ccsC4fPFe5CZoyAH4UOealyQ5K/a8zQXPaGQm3pL0R/ZodecqXE6moZFiA4KehL5aRxo6V1W/nUAAAGHM0x8YGQltYcTHYLNgDQFjgAzLTECFX+YvdH5lxtbiVh6VOmpO+67bhxkuxZjIQtA54AAAAAAAAAAAAAAOjUpRAAQOAAA=&quot;, &quot;status&quot;: 3, &quot;status_name&quot;: &quot;finalized&quot;, &quot;storage&quot;: { &quot;storage_fees_collected&quot;: &quot;0x3f&quot;, &quot;status_change&quot;: 0, &quot;status_change_name&quot;: &quot;unchanged&quot; }, &quot;compute&quot;: { &quot;success&quot;: true, &quot;msg_state_used&quot;: false, &quot;account_activated&quot;: false, &quot;gas_fees&quot;: &quot;0xc53078&quot;, &quot;gas_used&quot;: 12923, &quot;gas_limit&quot;: 0, &quot;gas_credit&quot;: 10000, &quot;mode&quot;: 0, &quot;exit_code&quot;: 0, &quot;vm_steps&quot;: 352, &quot;vm_init_state_hash&quot;: &quot;0000000000000000000000000000000000000000000000000000000000000000&quot;, &quot;vm_final_state_hash&quot;: &quot;0000000000000000000000000000000000000000000000000000000000000000&quot;, &quot;compute_type&quot;: 1, &quot;compute_type_name&quot;: &quot;vm&quot; }, &quot;action&quot;: { &quot;success&quot;: true, &quot;valid&quot;: true, &quot;no_funds&quot;: false, &quot;status_change&quot;: 0, &quot;total_fwd_fees&quot;: &quot;0x1e8480&quot;, &quot;total_action_fees&quot;: &quot;0x145850&quot;, &quot;result_code&quot;: 0, &quot;tot_actions&quot;: 2, &quot;spec_actions&quot;: 0, &quot;skipped_actions&quot;: 0, &quot;msgs_created&quot;: 2, &quot;action_list_hash&quot;: &quot;39fdb5b66907d97a04567aab6cf5c9df700d1756a269b141f57d6df41788a4d2&quot;, &quot;tot_msg_size_cells&quot;: 2, &quot;tot_msg_size_bits&quot;: 1178 }, &quot;credit_first&quot;: true, &quot;aborted&quot;: false, &quot;destroyed&quot;: false, &quot;tr_type&quot;: 0, &quot;tr_type_name&quot;: &quot;ordinary&quot;, &quot;lt&quot;: &quot;0xe6a413032c1&quot;, &quot;prev_trans_hash&quot;: &quot;24862ba6bb23e0c0d0d65dd98d047b2bf60e98e9782c9ed086fc04316cc1ff98&quot;, &quot;prev_trans_lt&quot;: &quot;0xe6a3fd13f01&quot;, &quot;now&quot;: 1680192863, &quot;outmsg_cnt&quot;: 2, &quot;orig_status&quot;: 1, &quot;orig_status_name&quot;: &quot;Active&quot;, &quot;end_status&quot;: 1, &quot;end_status_name&quot;: &quot;Active&quot;, &quot;in_msg&quot;: &quot;b10b0866cb7320f9abac1ba6c5a09f7a60bb87b399142aa0a7dda28b086d9a40&quot;, &quot;ext_in_msg_fee&quot;: &quot;0x2798b8&quot;, &quot;out_msgs&quot;: [ &quot;ff491002eaeaf22e85055d5b055383d8aaaa030bcb5ae34a65b27f15de8e2e34&quot;, &quot;8f2f48998b041adbae47a3e8ee7541ee918299d316e07c7dbd221501a31b15d8&quot; ], &quot;account_addr&quot;: &quot;0:95c35b94e98c1b5c7716a9129ed5bb0798c8c336465fd8d1eb0d385e3d969494&quot;, &quot;workchain_id&quot;: 0, &quot;total_fees&quot;: &quot;0x10121bf&quot;, &quot;balance_delta&quot;: &quot;-0x746b5dd5ef&quot;, &quot;old_hash&quot;: &quot;3502ad062fb0ed7d9c9c764443cdfc49b45938eddb4689d26f7949b257569159&quot;, &quot;new_hash&quot;: &quot;2d09c40e5408805a3bfa5a2c55008e6d3f6052c66d5cf96d4c90e5f12c7f1ab0&quot; }, &quot;output&quot;: { &quot;transId&quot;: &quot;0&quot; }, &quot;out_messages&quot;: [ null ] }  Basic checks of the address format will be performed by the Everdev utility automatically, only addresses of a valid Everscale format will be accepted. (Optional) Multi-owner accounts and Confirm transaction​ Note, that if your user account has multiple custodians, the transaction has to be confirmed by the required number of signatures to be executed. This transaction ID should be communicated to other custodians, who should use it to confirm the transaction. To withdraw tokens from a multi-owner account use the following command: everdev contract run SetcodeMultisig.abi.json submitTransaction --address &lt;wallet_account_address&gt; --signer wallet_signer --input '{ &quot;dest&quot;: &quot;recipient_address&quot;, &quot;value&quot;:10000000000, &quot;bounce&quot;: false, &quot;allBalance&quot;: false, &quot;payload&quot;: &quot;&quot;, &quot;stateInit&quot;: null }'  &lt;wallet_account_address&gt; - address of the user account. Example: 0:7bf2b2ec80371601f854bff9ed0a1171714d922c8bfc86d39e67a7e3a41b2176 wallet_signer - name of the user account owner signer value: - amount of tokens to transfer in nanotokens (Example: value:10000000000 sets up a transfer of 10 tokens). bounce - use false to transfer funds to an already deployed account allBalance - used to transfer all funds in the wallet. Use false for a simple transfer. payload - use &quot;&quot; for simple transfer. stateInit - use null for a simple transfer. This will generate a transaction and display its transId that will have to be confirmed by other custodians. To confirm a transaction, use the following command: everdev contract run SetcodeMultisig.abi.json confirmTransaction --address &lt;wallet_account_address&gt; --signer wallet_signer2 --input transactionId:6954030467099431873  &lt;wallet_account_address&gt; - address of the user account. Example: 0:7bf2b2ec80371601f854bff9ed0a1171714d922c8bfc86d39e67a7e3a41b2176 wallet_signer2 - signer of another multisig custodian (not the one who initiated the transaction). transactionId – the ID of the transaction can be acquired from the custodian who created it. Mitigating risks of token loss due to user error​ The are two main cases regarding transfers to user accounts: a user may already have an active account to which they want to withdraw funds (set bounce to true), or they may want to withdraw funds to a completely new account, that doesn't exist at the time withdraw is requested (set bounce to false). The status of the account provided by the user may be checked with the following Everdev command: everdev contract info --address external_address  Example of existing account: everdev contract info --address 0:665a62042aff317ba3f32e36b712b0f4a9d35277dd76dc38c9762cc6421681cf Configuration Network: dev (devnet.evercloud.dev) Signer: owner_keys (public 5ff6b5ba62b52b25ef347984912937bffaf2df88605e4e56cb64b9b617a28fea) Address: 0:665a62042aff317ba3f32e36b712b0f4a9d35277dd76dc38c9762cc6421681cf Account: Active Balance: ≈ 51655 tokens (51655086754193 nano)  Example of account that doesn't exist yet: everdev contract info --address 0:6238e23f6987883b3d1a86e1c39c63ae2baf7f93603d0ea5dc9b6e91ef54a1ab Configuration Network: dev (devnet.evercloud.dev) Signer: owner_keys (public 5ff6b5ba62b52b25ef347984912937bffaf2df88605e4e56cb64b9b617a28fea) Address: 0:6238e23f6987883b3d1a86e1c39c63ae2baf7f93603d0ea5dc9b6e91ef54a1ab (calculated from TVC and signer public) Code Hash: 80d6c47c4a25543c9b397b71716f3fae1e2c5d247174c52e2c19bd896442b105 (from TVC file) Account: Doesn't exist  The possible results of this command are the following: Doesn't exist - account does not exist. It needs to be sponsored, then deployed, and only then will it be active. Uninit - account already has some funds on it but contract code has not been deployed yet. User needs to deploy it. Active - account already exists, and its code is deployed. In the first to cases, the service might first transfer a small portion of the requested amount (~1 EVER) and request that the user deploys their contract. Upon the user's confirmation that the account is deployed, its status may be rechecked, and if it became active, the remaining amount of requested funds may be safely transferred. If the account is already active, a small portion of the requested amount may be transferred to the user, and the user may be asked what amount they received (note: a small amount of the transfer, usually less than 0.05 EVER, will be spent on fees, so it's best to ask for the whole number of tokens transferred). If the amounts match, the rest of the requested funds may be transferred as well. "},{"title":"Using SDK​","type":1,"pageTitle":"Add EVER to your backend","url":"/develop/recipes/backend-integration#using-sdk-1","content":"You may integrate withdrawals from wallet account into your backend using SDK as well. In these samples JS SDK is used. Bindings for a large number of languages have been developed for SDK. Multisig Wallet​ A sample is available in this repository and an overview of the relevant part is given below. This example shows how to generate a withdrawal transaction from a Multisig wallet, using its sendTransaction method. Note, that if Multisig has multiple custodians, the transaction will have to be confirmed with the confirmTransaction method. In this example tokens are withdrawn from the user account to the account specified in dest. In a proper implementation, the account given by user should be used instead.  // 2.----------------------- Transfer tokens ------------------------ // // We send 0.5 tokens. Value is written in nanotokens const amount = 0.5e9 const dest = &quot;-1:7777777777777777777777777777777777777777777777777777777777777777&quot; console.log('Sending 0.5 token to', dest) // If you want to add a comment to your transfer, create payload with it: const comment = (await client.abi.encode_boc({ params: [ { name: &quot;op&quot;, type: &quot;uint32&quot; }, // operation { name: &quot;comment&quot;, type: &quot;bytes&quot; } ], data: { &quot;op&quot;: 0, // operation = 0 means comment &quot;comment&quot;: Buffer.from(&quot;My comment&quot;).toString(&quot;hex&quot;), } })).boc; // Encode the body with sendTransaction call and comment body = (await client.abi.encode_message_body({ address: msigAddress, abi: { type: 'Json', value: msigABI }, call_set: { function_name: 'sendTransaction', input: { dest: dest, value: amount, bounce: false, flags: 64, payload: comment // specify &quot;&quot; if no payload is provided } }, is_internal:false, signer:{type: 'Keys', keys: keypair} })).body; let msg = await client.boc.encode_external_in_message({ dst: msigAddress, body: body }); sendRequestResult = await client.processing.send_message({ message: msg.message, send_events: false }); transaction = (await client.processing.wait_for_transaction({ abi: { type: 'Json', value: msigABI }, message: msg.message, shard_block_id: sendRequestResult.shard_block_id, send_events: false })).transaction; console.log('Transfer completed. Transaction hash', transaction?.id) assert.equal(transaction?.status, 3) assert.equal(transaction?.status_name, &quot;finalized&quot;)  Ever Wallet​ A sample is available in this repository and an overview is given below. In this example tokens are withdrawn from the user account to the account specified in dest. In a proper implementation, the desired destination address should be used instead.  // 3.----------------- Make simple transfer ----------------------- // console.log(`Making simple transfer from ever-wallet contract to address: -1:7777777777777777777777777777777777777777777777777777777777777777 and waiting for transaction...`) // If you want to add a comment to your transfer, create payload with it: const comment = (await client.abi.encode_boc({ params: [ { name: &quot;op&quot;, type: &quot;uint32&quot; }, // operation { name: &quot;comment&quot;, type: &quot;bytes&quot; } ], data: { &quot;op&quot;: 0, // operation = 0 means comment &quot;comment&quot;: Buffer.from(&quot;My comment&quot;).toString(&quot;hex&quot;), } })).boc; // encode message body by ever-wallet ABI body = (await client.abi.encode_message_body({ address: everWalletAddress, abi: { type: 'Json', value: everWalletABI }, call_set: { function_name: 'sendTransaction', input: { dest: '-1:7777777777777777777777777777777777777777777777777777777777777777', value: '500000000', // amount in units (nano) bounce: false, flags: 3, payload: comment // specify &quot;&quot; if no payload is provided } }, is_internal:false, signer:{type: 'Keys', keys: keypair} })).body; let transferMsg = await client.boc.encode_external_in_message({ dst: everWalletAddress, body: body }); sendRequestResult = await client.processing.send_message({ message: transferMsg.message, send_events: false }); transaction = (await client.processing.wait_for_transaction({ abi: { type: 'Json', value: everWalletABI }, message: transferMsg.message, shard_block_id: sendRequestResult.shard_block_id, send_events: false })).transaction; console.log('Contract deployed. Transaction hash', transaction.id) assert.equal(transaction.status, 3) assert.equal(transaction.status_name, &quot;finalized&quot;)  Mitigating risks of token loss due to user error​ Similarly to the everdev approach, you can add the account status check prior to sending tokens. The are two main cases regarding transfers to user accounts: a user may already have an active account to which they want to withdraw funds, or they may want to withdraw funds to a completely new account, that doesn't exist at the time withdraw is requested. Here is an example of checking account status in SDK:  let balance: number let accType: number for (; ;) { // The idiomatic way to send a request is to specify // query and variables as separate properties. const getInfoQuery = ` query getBalance($address: String!) { blockchain { account(address: $address) { info { balance acc_type } } } } ` const resultOfQuery: ResultOfQuery = await client.net.query({ query: getInfoQuery, variables: { address: msigAddress } }) const nanotokens = parseInt(resultOfQuery.result.data.blockchain.account.info?.balance, 16) accType = resultOfQuery.result.data.blockchain.account.info?.acc_type; if (nanotokens &gt; MINIMAL_BALANCE * 1e9) { balance = nanotokens / 1e9 break } // TODO: rate limiting await sleep(1000) } console.log(`Account balance is: ${balance.toString(10)} tokens. Account type is ${accType}`)  In addition to checking account status prior to transferring tokens, for Ever Surf and Ever Wallet users account verification with a PIN code may be set up. In the examples above the following method of encoding a text comment into transaction payload is used.  // If you want to add a comment to your transfer, create payload with it: const comment = (await client.abi.encode_boc({ params: [ { name: &quot;op&quot;, type: &quot;uint32&quot; }, // operation { name: &quot;comment&quot;, type: &quot;bytes&quot; } ], data: { &quot;op&quot;: 0, // operation = 0 means comment &quot;comment&quot;: Buffer.from(&quot;My comment&quot;).toString(&quot;hex&quot;), } })).boc;  The result should be simply passed as payload parameter when generating multisig or Ever wallet transaction. A small amount of tokens can be sent with a PIN code encoded into payload. The user will be able to see this PIN code in their Ever Surf or Ever Wallet app. The rest of the requested amount may be sent to the user only once they provide the PIN code, ensuring they have full control of the account. "},{"title":"Work with REMP in EVER SDK","type":0,"sectionRef":"#","url":"/develop/recipes/ever-sdk-guides/remp","content":"","keywords":""},{"title":"Introduction​","type":1,"pageTitle":"Work with REMP in EVER SDK","url":"/develop/recipes/ever-sdk-guides/remp#introduction","content":"REMP (Reliable External Messaging Protocol) is a set of protocols and data structures that are designed to keep trace of incoming external messages and predict with a high probability whether a message will be processed successfully. REMP adds some additional guarantees/features for external messages processing: 1. Replay protection If a message is processed and added into an accepted block, then the same message (that is, the message with the same hash) will not be collated for some time period. If the message has some expiration time (corresponding to the time period), then this effectively makes efficient replay protection. 2. No messages are lost You only need to send the message once. If there will be a possibility to accept it and add it to a block, then it will be done. Message loss may occur only for blockchain overloading reasons. 3. One can trace the message processing. There are several checkpoints on the message processing path (when validators received the message, when message was added to a block, when the block was finalized, etc). Upon reaching certain checkpoints one can predict that the message will be successfully processed with a high accuracy - most messages can be considered to be processed when validators acknowledge that they were received (this happens in 100-200 ms; after that it’s highly unlikely that the message is declined). Thus, depending on the message importance one may trade efficiency for reliability in the software, choosing not to trace further processing results. On the other hand, if a transaction is really important, then you can wait till the block with the transaction result is issued. During validation, as the message passes through various stages (that is, changes some statuses), validator sends receipts about each. "},{"title":"Prerequisites​","type":1,"pageTitle":"Work with REMP in EVER SDK","url":"/develop/recipes/ever-sdk-guides/remp#prerequisites","content":"Create a project on dashboard.evercloud.dev if you don't have one.Remember its Development Network HTTPS endpoint.Pass this endpoint as a parameter when running the example. "},{"title":"Working with REMP statuses​","type":1,"pageTitle":"Work with REMP in EVER SDK","url":"/develop/recipes/ever-sdk-guides/remp#working-with-remp-statuses","content":"The sample sends a message to a predeployed test contract. (async () =&gt; { try { console.log('Sending messsage and waiting for REMP events.'); const { transaction } = await client.processing.process_message( { send_events: true, message_encode_params: { address: CONTRACT_ADDRESS, abi: abiContract(CONTRACT_ABI), call_set: { function_name: 'touch', }, signer: signerNone(), }, }, responseHandler, ); console.log( [ `The message has been processed.`, `${rempEventCnt} REMP events received`, `Transaction id: ${transaction.id}, status ${transaction.status_name}`, ].join('\\n'), ); client.close(); } catch (error) { if (error.code === 504) { console.error('Network is inaccessible.'); } else { console.error(error); } process.exit(1); }  After the message is sent all REMP events related to the message are received and printed, tracing the message processing by validators. Note: By REMP events one can predict with a high probability that the message will be processed successfully, before the processing is complete. Depending on message importance, you can choose to consider it processed as soon as the corresponding receipt arrives and not spend time and resources waiting for further status receipts. function responseHandler(params, responseType) { // Tip: Always wrap the logic inside responseHandler in a try-catch block // or you will be surprised by non-informative errors due to the context // in which the handler is executed try { if (responseType === 100 /* GraphQL data received */) { const { type, json, error } = params; assert.ok(type, 'Event always has type'); if (type.startsWith('Remp')) { rempEventCnt++; // All REMP event types starts with `Remp` // https://docs.everos.dev/ever-sdk/reference/types-and-methods/mod_processing#processingevent assert.ok(json || error, 'All REMP event has `json` or `error` property'); if (json) { // We print all REMP events. console.log(`\\tREMP event type: ${type}, kind: ${json.kind}`); // but you can pay attention to only a few kinds of events: if (json.kind === 'IncludedIntoBlock') { console.log('\\t^^^ this message is probably to be processed successfully'); } if (json.kind === 'IncludedIntoAcceptedBlock') { console.log( '\\t^^^ this message is highly likely to be processed successfully', ); } } if (error) { // Errors here indicate that there was a problem processing the REMP. // This does not mean that the message cannot be processed successfully, // it only means that the SDK just didn't get the next status at the expected time, see // TonClient config params: `first_remp_status_timeout`, `next_remp_status_timeout` // https://docs.everos.dev/ever-sdk/reference/types-and-methods/mod_client#networkconfig // // In this case, the SDK switches to the scenario of waiting for a standby transaction (sequential block reading). console.log( `\\tREMP event type: ${type}, code: ${error.code}, message: ${error.message}`, ); } } else { // In this example we are interested only in REMP events, so we skip // other events like `WillFetchFirstBlock`, `WillSend`, `DidSend`. // console.log(`Basic event ${type}`); } } else { // See full list of error codes here: // https://docs.everos.dev/ever-sdk/reference/types-and-methods/mod_net#neterrorcode console.log('ERROR', params, responseType); } } catch (err) { console.log(err); }  See the full example in sdk samples repository: https://github.com/tonlabs/sdk-samples/blob/master/core-examples/node-js/remp/index.js "},{"title":"Expected output​","type":1,"pageTitle":"Work with REMP in EVER SDK","url":"/develop/recipes/ever-sdk-guides/remp#expected-output","content":"node index.js https://devnet.evercloud.dev/your-project-id/graphql Sending messsage and waiting for REMP events. REMP event type: RempOther, kind: PutIntoQueue REMP event type: RempOther, kind: PutIntoQueue REMP event type: RempOther, kind: PutIntoQueue REMP event type: RempOther, kind: PutIntoQueue REMP event type: RempOther, kind: PutIntoQueue REMP event type: RempOther, kind: PutIntoQueue REMP event type: RempIncludedIntoBlock, kind: IncludedIntoBlock ^^^ this message is probably to be processed successfully REMP event type: RempOther, kind: Duplicate REMP event type: RempOther, kind: Duplicate REMP event type: RempOther, kind: Duplicate REMP event type: RempOther, kind: Duplicate REMP event type: RempOther, kind: Duplicate REMP event type: RempIncludedIntoAcceptedBlock, kind: IncludedIntoAcceptedBlock ^^^ this message is highly likely to be processed successfully The message has been processed. 13 REMP events received Transaction id: effed4849898e08d1fe5759532d34f23dbec061c5fd666604f817be82732cfb9, status finalized  "},{"title":"Sample Source code​","type":1,"pageTitle":"Work with REMP in EVER SDK","url":"/develop/recipes/ever-sdk-guides/remp#sample-source-code","content":"Full sample: https://github.com/tonlabs/sdk-samples/tree/master/core-examples/node-js/remp "},{"title":"See also​","type":1,"pageTitle":"Work with REMP in EVER SDK","url":"/develop/recipes/ever-sdk-guides/remp#see-also","content":"REMP Architecture documentation Guides for working with REMP in GraphQL API: https://docs.evercloud.dev/samples/graphql-samples/send-message https://docs.evercloud.dev/samples/graphql-samples/subscribe-for-remp-receipts Original REMP SDK guide: https://docs.everos.dev/ever-sdk/guides/work_with_contracts/trace-message-processing-with-remp Full EVER SDK documenation is available at https://docs.everos.dev/ever-sdk/ "},{"title":"Intro","type":0,"sectionRef":"#","url":"/develop/recipes/intro","content":"Intro In this series of examples we will figure out basic steps you need to follow to build a UI around any smart contract and perform various routines common for both frontend and backend parts of any application. We expect a reader to have basic experience with JS. For React developers, there is an example of a React App built around Everscale smart-contracts. Before we start, please make sure you've read through basic theory that we put under the Build section of this documentation, especially the Smart Contracts, ABI and Messages article. Also, be aware that we borrow some code samples from the full Everscale Development Guide, so don’t hesitate to check that out if you want to dive deeper into the context.","keywords":""},{"title":"Read data from blockchain","type":0,"sectionRef":"#","url":"/develop/recipes/read-data","content":"","keywords":""},{"title":"Invoke a get-method​","type":1,"pageTitle":"Read data from blockchain","url":"/develop/recipes/read-data#invoke-a-get-method","content":"ever-sdk-jseverscale-inpage-provider // Execute the get method `getTimestamp` on the latest account's state // This can be managed in 3 steps: // 1. Download the latest Account State (BOC) // 2. Encode message // 3. Execute the message locally on the downloaded state const [account, message] = await Promise.all([ // Download the latest state (BOC) // See more info about query method here // https://github.com/tonlabs/ever-sdk/blob/master/docs/mod_net.md#query_collection client.net.query_collection({ collection: 'accounts', filter: { id: { eq: address } }, result: 'boc' }) .then(({ result }) =&gt; result[0].boc) .catch(() =&gt; { throw Error(`Failed to fetch account data`) }), // Encode the message with `getTimestamp` call client.abi.encode_message({ abi, address, call_set: { function_name: 'getTimestamp', input: {} }, signer: { type: 'None' } }).then(({ message }) =&gt; message) ]); // Execute `getTimestamp` get method (execute the message locally on TVM) // See more info about run_tvm method here // https://github.com/tonlabs/ever-sdk/blob/master/docs/mod_tvm.md#run_tvm response = await client.tvm.run_tvm({ message, account, abi }); console.log('Contract reacted to your getTimestamp:', response.decoded.output);  "},{"title":"Fetch or subscribe to contract events​","type":1,"pageTitle":"Read data from blockchain","url":"/develop/recipes/read-data#fetch-or-subscribe-to-contract-events","content":"ever-sdk-jseverscale-inpage-provider // Query events result = await client.net.query({ query: `query MyQuery($address: String!, $cursor: String, $count: Int, $start_seq_no: Int, end_seq_no: Int) { blockchain { account(address: $address){ messages( master_seq_no_range: { start: $start_seq_no, end: $end_seq_no } first: $count, msg_type: [ExtOut, ExtIn, IntIn, IntOut], after: $cursor ) { edges { node { id, created_at } } pageInfo { endCursor hasNextPage } } } } }`, variables:{address, cursor, count, start_seq_no, end_seq_no} }); ... // Subscribe to events const messageSubscription = await TonClient.default.net.subscribe_collection({ collection: &quot;messages&quot;, filter: { dst: { eq: your-contract-address }, msg_type:{ in: [0,1,2] } }, result: &quot;boc&quot; }, &lt;callback function&gt; });  "},{"title":"Decode message​","type":1,"pageTitle":"Read data from blockchain","url":"/develop/recipes/read-data#decode-message","content":"ever-sdk-js const decoded = (await client.abi.decode_message({ abi: abiContract(HelloEventsContract.abi), message: boc, })); switch (decoded.body_type) { case MessageBodyType.Input: log_.push(`External inbound message, function &quot;${decoded.name}&quot;, fields: ${JSON.stringify(decoded.value)}` ); break; case MessageBodyType.Output: log_.push(`External outbound message (return) of function &quot;${decoded.name}&quot;, fields: ${JSON.stringify(decoded.value)}`); break; case MessageBodyType.Event: log_.push(`External outbound message (event) &quot;${decoded.name}&quot;, fields: ${JSON.stringify(decoded.value)}`); break; }  "},{"title":"Subscribe to updates​","type":1,"pageTitle":"Read data from blockchain","url":"/develop/recipes/read-data#subscribe-to-updates","content":"ever-sdk-js // Account updates const accountSubscription = await TonClient.default.net.subscribe_collection({ collection: &quot;accounts&quot;, filter: { id: { eq: address } }, result: &quot;balance&quot;, }, (params, responseType) =&gt; { if (responseType === ResponseType.Custom) { console.log(&quot;Account has updated. Current balance is &quot;, parseInt(params.result.balance)); } }); ... // Account messages const messageSubscription = await TonClient.default.net.subscribe_collection({ collection: &quot;messages&quot;, filter: { src: { eq: address }, OR: { dst: { eq: address }, } }, result: &quot;boc&quot;, }, async (params, responseType) =&gt; { try { if (responseType === ResponseType.Custom) { const decoded = (await TonClient.default.abi.decode_message({ abi: abiContract(your-contract-abi), message: params.result.boc, })); switch (decoded.body_type) { case MessageBodyType.Input: console.log(`External inbound message, function &quot;${decoded.name}&quot;, parameters: `, JSON.stringify(decoded.value)); break; case MessageBodyType.Output: console.log(`External outbound message, function &quot;${decoded.name}&quot;, result`, JSON.stringify(decoded.value)); break; case MessageBodyType.Event: console.log(`External outbound message, event &quot;${decoded.name}&quot;, parameters`, JSON.stringify(decoded.value)); break; } } } catch (err) { console.log('&gt;&gt;&gt;', err); } });  "},{"title":"Read arbitrary data from blockchain​","type":1,"pageTitle":"Read data from blockchain","url":"/develop/recipes/read-data#read-arbitrary-data-from-blockchain","content":"In most cases, the starting point for reading blockchain data is an account address. But sometimes you may want to perform arbitrary queries. For such cases, the fullnode GraphQL API is a perfect solution. There is a public Evercloud infrastructure for that. Head over to Evercloud Docs to read more. It is fully opensource, so you may want to deploy your own full node instance with Graph QL interface. You can also reconfigure it for your dApp needs. For example - build various custom indexes according to your smart contract system architecture. Head over to Graph QL Server repository to learn more details. "},{"title":"Links​","type":1,"pageTitle":"Read data from blockchain","url":"/develop/recipes/read-data#links","content":"Explore the full guides to reading blockchain data in Ever SDK here: https://docs.everos.dev/ever-sdk/guides/work_with_contracts/run_abi_get_method https://docs.everos.dev/ever-sdk/guides/work_with_contracts/work_with_events https://docs.everos.dev/ever-sdk/guides/work_with_contracts/decode_message https://docs.everos.dev/ever-sdk/guides/queries_and_subscriptions/subscribe_to_updates Advanced guide for working with Surf keeper provider is here. If you use everscale-inpage-provider, see more docs and guides here: https://docs.broxus.com "},{"title":"Advanced usage of Surf Keeper","type":0,"sectionRef":"#","url":"/develop/recipes/surf-wallet-advanced","content":"","keywords":""},{"title":"Surf Extension methods​","type":1,"pageTitle":"Advanced usage of Surf Keeper","url":"/develop/recipes/surf-wallet-advanced#surf-extension-methods","content":"connect​ Requests new permissions for current origin. Shows an approval window to the user. input: {}; output: { isConnected: boolean; // Flag shows connection status for the current origin address?: string; // Address of extension wallet publicKey?: string; // Hex encoded public key };  Example: const result = await rpc.connect();  connectStatus​ Returns the current connection status. input: {}; output: { isConnected: boolean; // Flag shows connection status for the current origin address?: string; // Address of extension wallet publicKey?: string; // Hex encoded public key };  Example: const result = await rpc.connectStatus();  disconnect​ Removes all permissions for current origin. input: { } output: { isConnected: boolean; // Flag shows connection status for the current origin; should return `false` as disconnect method execution result }  Example: const result = await rpc.disconnect();  sendMessage​ Sends an internal message from the user account. Shows an approval window to the user. input: { abi: string; // Contract abi address: string; // Address string net: EverscaleNetNameKey; // Name of network to send message in, i.e. 'mainnet' | 'devnet' callSet: { functionName: string; // Name of contract function to be sent to the contract input: Record&lt;string, any&gt;; // Input for the contract function header?: FunctionHeader; }; bounce: boolean; // Whether to bounce message back on error amount: string; // Amount of nano EVER to send action?: string; // Name of action to be performed by message send }; output: { // Result of send message result?: { shard_block_id: string; // The last generated shard block of the message destination account before the message was sent sending_endpoints: string[]; // The list of endpoints to which the message was sent }; error?: string; // String with some error details };  Example: const response = await rpc.sendMessage({ amount: '2000000000', // in nano-tokens, i.e. 2 tokens bounce: true, callSet: { functionName: 'addComment', input: { comment: 'Test comment', }, }, net: 'mainnet', action: 'Create comment', address: '0:8959ea111cc0c85d996df0d16e530d584d5366618cfed9ab6a1754828bb78479', abi: '{&quot;ABI version&quot;:2,&quot;version&quot;:&quot;2.3&quot;,&quot;header&quot;:[&quot;pubkey&quot;,&quot;time&quot;,&quot;expire&quot;]...', });  sendTransaction​ Sends transaction with provided params. input: { amount: string; // Amount of nano EVER to send bounce: boolean; // Whether to bounce message back on error comment: string; // Comment for the transaction to send it in payload net: EverscaleNetNameKey; // Name of network to send transaction in, i.e. 'mainnet' | 'devnet' to: string; // Address to send transaction to } output: { // Result of send transaction message result?: { shard_block_id: string; // The last generated shard block of the message destination account before the message was sent sending_endpoints: string[]; // The list of endpoints to which the message was sent }; error?: string; // String with some error details };  Example: const response = await rpc.sendTransaction({ amount: '10000000000', // in nano-tokens, i.e. 10 tokens bounce: true, comment: 'check it out!', net: 'devnet', to: '0:b76b532fbe72307bff243b401d6792d5d01332ea294a0310c0ffdf874026f2b9', });  signData​ Signs arbitrary data. input: { data: string; // Base64 encoded arbitrary bytes } output: { signature?: string; // Base64 encoded signature bytes (data is guaranteed to be 64 bytes long) error?: string; // String with error details };  Example: const response = await rpc.signData({ data: 'te6ccgEBAQEAKAAASw4E0p6AD5fz9JsGWfbBhP0Bwq9+jk0X3za9rhuI7A1H3DxC0QBw', });  subscribe​ Subscribes to data updates. input: { type: string; // Subscription type, for now only &quot;balance&quot; is available address: string; // Target address listener: (value: string) =&gt; void; // Subscription data update handler }; output: { remove: () =&gt; void; // Base64 encoded signature bytes (data is guaranteed to be 64 bytes long) };  Example: const response = rpc.subscribe({ type: 'balance', address: '0x000000..000', listener: val =&gt; console.log('Balance uodated: ', val), });  "},{"title":"Frameworks usage​","type":1,"pageTitle":"Advanced usage of Surf Keeper","url":"/develop/recipes/surf-wallet-advanced#frameworks-usage","content":"Here we gathered the most common patterns of @eversurf/surfkeeper-provider usage: React import { useEffect, useMemo, useState } from 'react'; import { Address, ConnectResponse, ProviderRpcClient, hasSurfKeeperProvider } from '@eversurf/surfkeeper-provider'; export type ExtensionState = { hasProvider: boolean; isConnecting: boolean; isConnected: boolean; isContractUpdating: boolean; isDisconnecting: boolean; isInitialized: boolean; isInitializing: boolean; } export type ExtensionData = { address: Address | undefined; publicKey: string | undefined; } const DEFAULT_EXTENSION_STATE: ExtensionState = { hasProvider: false, isConnecting: false, isConnected: false, isContractUpdating: false, isDisconnecting: false, isInitialized: false, isInitializing: false, } const DEFAULT_EXTENSION_DATA: ExtensionData = { address: undefined, publicKey: undefined } export interface IUseSurfKeeper { rpc: ProviderRpcClient, connect: () =&gt; Promise&lt;void&gt;, extensionState: ExtensionState, extensionData: ExtensionData } export const rpc = new ProviderRpcClient(); export const useSurfKeeper = (): IUseSurfKeeper =&gt; { const [extensionState, setExtensionState] = useState&lt;ExtensionState&gt;(DEFAULT_EXTENSION_STATE); const [extensionData, setExtensionData] = useState&lt;ExtensionData&gt;(DEFAULT_EXTENSION_DATA); const init = async () =&gt; { setExtensionState({ ...extensionState, isInitializing: true }); let hasProvider = false; try { hasProvider = await hasSurfKeeperProvider(); } catch (e) { console.log(&quot;hasSurfKeeperProvider error&quot;); } if (!hasProvider) { setExtensionState({ ...extensionState, hasProvider: false, isInitializing: false }); console.warn(&quot;Surf Keeper is not installed&quot;); } const connectResponse = await rpc.connectStatus(); if (connectResponse!.isConnected) { setExtensionState({ ...extensionState, isConnected: true, hasProvider: hasProvider, isConnecting: false, isInitialized: true, isInitializing: false, }); setExtensionData({ address: (connectResponse as unknown as ConnectResponse).address, publicKey: (connectResponse as unknown as ConnectResponse).publicKey }); } else { setExtensionState({ ...extensionState, isConnected: false, hasProvider: hasProvider, isConnecting: false, isInitialized: true, isInitializing: false, }); console.warn(&quot;Surf Keeper is not connected&quot;); } } const connect = async () =&gt; { const connectResponse = await rpc.connect(); if (connectResponse!.isConnected) { setExtensionState({ ...extensionState, isConnecting: false, isConnected: true, isInitialized: true, isInitializing: false, }); setExtensionData({ address: (connectResponse as unknown as ConnectResponse).address, publicKey: (connectResponse as unknown as ConnectResponse).publicKey }); return Promise.resolve(); } else { return Promise.reject(); } }; useEffect(() =&gt; { setExtensionState({ ...extensionState, isInitializing: true }); init(); }, []); return useMemo( () =&gt; ({ rpc: rpc, connect: connect, extensionState: extensionState, extensionData: extensionData }), [extensionState, extensionData], ); }; export default useSurfKeeper;  "},{"title":"Write data to blockchain","type":0,"sectionRef":"#","url":"/develop/recipes/write-data","content":"","keywords":""},{"title":"Send External Message​","type":1,"pageTitle":"Write data to blockchain","url":"/develop/recipes/write-data#send-external-message","content":"ever-sdk-js process_messageever-sdk-js encode_message -&gt; send_messageeverscale-inpage-provider // Encode the message with `touch` function call const params = { send_events: false, message_encode_params: { address, abi, call_set: { function_name: 'touch', input: {} }, // There is no pubkey key check in the contract // so we can leave it empty. Never use this approach in production // because anyone can call this function signer: { type: 'None' } } } // Call `touch` function let response = await client.processing.process_message(params); console.log(`Сontract run transaction with output ${response.decoded.output}, ${response.transaction.id}`);  "},{"title":"Encode and send Internal Message​","type":1,"pageTitle":"Write data to blockchain","url":"/develop/recipes/write-data#encode-and-send-internal-message","content":"everscale-inpage-provider // Create Contract wrapper using ABI and an address const example = new provider.Contract(contractABI, contractAddress); // Send the external message `touch` to the contract await example.methods.touch({}).send({ address: &lt;Address object&gt;, // you can get the address from AccountStorage, which is set up either manually or provided by the browser extension amount: &lt;nanotokens&gt; // you should attach non-zero value of native currency to pay at least foraward, compute and storage fees of destination contract. }); console.log('Message sent');  "},{"title":"Links​","type":1,"pageTitle":"Write data to blockchain","url":"/develop/recipes/write-data#links","content":"Explore the full guides to writing data to blockchain in Ever SDK here: https://docs.everos.dev/ever-sdk/guides/work_with_contracts/deploy https://docs.everos.dev/ever-sdk/guides/work_with_contracts/run_onchain Advanced guide for working with Surf keeper provider is here. If you use everscale-inpage-provider, see more docs and guides here: https://docs.broxus.com "},{"title":"Smart Contracts, ABI and Messages","type":0,"sectionRef":"#","url":"/develop/sc-abi-messages","content":"Smart Contracts, ABI and Messages Frontend developers used to build a UI around some machinery called “backend”, that can be accessed via an API. The common practice in software development is to have some schema definitions, usually built with tool called swagger. In blockchain development, the “backend” thing is called a smart contract. It is usually being built with Solidity language, and also has schema definition called an Abstract Binary Interface, or ABI. In most cases, a frontend developer doesn’t need to bother his mind with understanding the smart-contract code. But it is crucial to understand the ABI to interact with a smart contract. Let’s see how an ABI looks like, and what can we underfstand from it without reading the smart contract itself. ABI { // Major version of ABI standart &quot;ABI version&quot;: 2, // Full version of ABI // Can be – 2.0, 2.1, 2.2, 2.3 version: &quot;2.3&quot;, // Headers, specifying SDK which additional fields to attach to external message // Defined in the contract code, there are: // pragma AbiHeader time; // pragma AbiHeader pubkey; // pragma AbiHeader expire; header: [ &quot;time&quot;, &quot;pubkey&quot;, &quot;expire&quot; ], // Description of callable function signatures // both internal and external messages functions: [ { &quot;name&quot;: &quot;constructor&quot;, &quot;inputs&quot;: [], &quot;outputs&quot;: [] }, { &quot;name&quot;: &quot;get&quot;, &quot;inputs&quot;: [], &quot;outputs&quot;: [{&quot;name&quot;:&quot;value0&quot;,&quot;type&quot;:&quot;uint256&quot;}] }, { &quot;name&quot;: &quot;getInternal&quot;, &quot;inputs&quot;: [ {&quot;name&quot;:&quot;answerId&quot;,&quot;type&quot;:&quot;uint32&quot;} ], &quot;outputs&quot;: [ {&quot;name&quot;:&quot;value0&quot;,&quot;type&quot;:&quot;uint256&quot;} ] }, { &quot;name&quot;: &quot;set&quot;, &quot;inputs&quot;: [{&quot;name&quot;:&quot;_value&quot;,&quot;type&quot;:&quot;uint256&quot;}], &quot;outputs&quot;: [] } ], // A description of the events that a contract can create events: [ { &quot;name&quot;: &quot;VariableChanged&quot;, &quot;inputs&quot;: [{&quot;name&quot;:&quot;new_value&quot;,&quot;type&quot;:&quot;uint256&quot;}], &quot;outputs&quot;: [] } ], // A list of static variables that must be specified to deploy the contract data: [ {&quot;key&quot;:1,&quot;name&quot;:&quot;owner&quot;,&quot;type&quot;:&quot;address&quot;} // There are also three hidden variables that SDK will set by itself // _pubkey, _timestamp, _constructorFlag ], // a list of all variables, so that you can // download the contract state and decode it fields: [ {&quot;name&quot;:&quot;_pubkey&quot;,&quot;type&quot;:&quot;uint256&quot;}, // tvm.pubkey() {&quot;name&quot;:&quot;_timestamp&quot;,&quot;type&quot;:&quot;uint64&quot;}, // set by SDK {&quot;name&quot;:&quot;_constructorFlag&quot;,&quot;type&quot;:&quot;bool&quot;}, // set by SDK {&quot;name&quot;:&quot;owner&quot;,&quot;type&quot;:&quot;address&quot;}, {&quot;name&quot;:&quot;variable&quot;,&quot;type&quot;:&quot;uint256&quot;} ] } An ABI describes how we pack the data into a TOC (Tree Of Cells) - the fundamental internal data structure of Everscale blockchain. We need that to encode the message according to Everscale standard and send it to the blockchain. Any message have a body for the function call. Let's look at an example function from abi: { &quot;name&quot;: &quot;set&quot;, &quot;inputs&quot;: [{&quot;name&quot;:&quot;_value&quot;,&quot;type&quot;:&quot;uint256&quot;}], &quot;outputs&quot;: [] } In the Recipes section, we provide snippets for ever-sdk-js, surf-keeper-provider and everscale-inpage-provider libraries, where we use ABI to interact with smart-contracts. It’s important to understand what happens under the hood, so lets summarize: we want to encode the payload, construct the message to some contract and send it over the RPC to a blockhain. Usually you will connect your dApp to existing smart contract system, deployed on-chain by a smart-contract developer. We assume that you have an ABI an address of one or several contracts. In further examples we will learn how to perform common routines.","keywords":""},{"title":"TIP3 Integration Guide","type":0,"sectionRef":"#","url":"/develop/recipes/tip3-integration","content":"","keywords":""},{"title":"Glossary​","type":1,"pageTitle":"TIP3 Integration Guide","url":"/develop/recipes/tip3-integration#glossary","content":"Owner wallet - wallet with Ever tokens which is the creator of TokenRoot and can mint TIP3.2 tokens. Holder wallet - wallet with Ever tokens which is the owner of a TIP 3.2 Wallet. For example, a MultisigV2 can be a holder wallet. It alone can govern the TIP3.2 wallet. TIP 3.2 Wallet - account which contains TIP3.2 tokens belonging to the holder. Additional documentation: https://github.com/broxus/tip3/blob/c857c077b4e3eacc941c7af2b53f1afe5e6d338b/contracts/abstract/TokenWalletBase.tsol#L81 "},{"title":"Prepare your keys​","type":1,"pageTitle":"TIP3 Integration Guide","url":"/develop/recipes/tip3-integration#prepare-your-keys","content":"First, you need to get a key pair which will be used to govern your token operations. Here we will use Ever Wallet keys for mint operations. Create an account in Ever Wallet app. Save seed phrase to a file. Add a new account and choose Multisig wallet option. Transfer 10 tokens to it. Then transfer one token to any other account - the wallet will be fully deployed after the outgoing transfer. The balance will be uneven, since fees will be deducted. Save multisig wallet address. Save the ABI of Ever Wallet to your project: https://github.com/broxus/ever-wallet-contract/blob/master/dist/Wallet.abi.json Get the wallet key pair from the seed phrase: let phrase = &quot;word1 word2 word3 word4 ... (12 words)&quot;; const ownerKeyPair = await client.crypto.mnemonic_derive_sign_keys({phrase});  "},{"title":"How to mint TIP3.2 tokens​","type":1,"pageTitle":"TIP3 Integration Guide","url":"/develop/recipes/tip3-integration#how-to-mint-tip32-tokens","content":"Encode body of internal message from owner wallet to TokenRoot which calls the mint method. It will be sent through an owner wallet call. Use the abi.encode_message_body function and the ABI of the receiving TokenRoot contract (mint function) for it. const call_mint_payload = (await client.abi.encode_message_body({ abi: { type: 'Contract', value: TokenRoot.abi, }, call_set: { function_name: &quot;mint&quot;, input: { amount: your-token-ammount, recipient: recipient-holder-address deployWalletValue: 5000000000 // 5 evers for deploy remainingGasTo: multisigOwnerAddress, notify: false payload: &quot;te6ccgEBAQEAAgAAAA==&quot; // empty cell }, }, is_internal: true, signer: signerNone(), // internal messages have no signature })).body; Call Owner Wallet (wallet which is the creator of TokenRoot), passing in call parameters payload of internal call, Owner Wallet ABI and TokenRoot address: // Prepare input parameter for 'submitTransaction' method of multisig wallet const sendTransactionParams = { dest: TokenRootAddress, value: more-than-5-evers, // because we will use 5 evers for token wallet deploy bounce: true, flags: 3, payload: call_mint_payload, }; const process_message_params = { send_events: false, message_encode_params: { token_owner_wallet_address, abi: token_owner_wallet.abi, // multisig abi, for example call_set: { function_name: &quot;submitTransaction&quot;, input: submitTransactionParams, }, signer: { type: 'Keys' keys: ownerKeyPair } }, }; // Call `submitTransaction` function const sentTransactionInfo = await client.processing.process_message(params);  "},{"title":"How to get total TIP3.2 token supply​","type":1,"pageTitle":"TIP3 Integration Guide","url":"/develop/recipes/tip3-integration#how-to-get-total-tip32-token-supply","content":"To get total token supply, you can download tokenRoot account state. It is a boc or bag of cells - native blockchain data layout. Account's boc contains full account state (code and data) that you will need to execute get methods and get the required information.  const query = ` query { blockchain { account( address: &quot;${address}&quot; ) { info { balance(format: DEC) boc } } } }` const {result} = await client.net.query({query}) const accountState = result.data.blockchain.account.info.boc // Encoding message for local execution of get method. Get methods do not require // signature so we use signer None const { message } = await client.abi.encode_message({ abi: { type: 'Contract', value: TokenRoot.abi, }, address, // token root address call_set: { function_name: totalSupply, input: { answerId: 0 }, }, signer: { type: 'None' }, }); // Run get method const tvm_response = await client.tvm.run_tvm({ message, account: accountState, abi: { type: 'Contract', value: TokenRoot.abi, }, }); const getMethodResult = tvm_response.decoded.output;  "},{"title":"How to deploy a TIP 3.2 wallet​","type":1,"pageTitle":"TIP3 Integration Guide","url":"/develop/recipes/tip3-integration#how-to-deploy-a-tip-32-wallet","content":"You can deploy token wallet via tokenRoot contract via deployWallet function. It can be called from any token Holder wallet. In this example multisig V2 is used. const deploy_payload = (await client.abi.encode_message_body({ abi: { type: 'Contract', value: TokenRoot.abi, }, call_set: { function_name: &quot;deployWallet&quot;, input: { answer_id: 0, walletOwner: holder-wallet-address deployWalletValue: deploy-value }, }, is_internal: true, signer: signerNone(), // internal messages have no signature })).body;   // Prepare input parameter for 'submitTransaction' method of multisig wallet const sendTransactionParams = { dest: tip3-2-root, value: deployWalletValue+ a bit more, // because we will use 0.5 evers for token transfer bounce: true, flags: 3, payload: deploy_payload, //information about transfer and recipient is contained here }; const process_message_params = { send_events: false, message_encode_params: { address: holder_wallet_address, abi: holder_wallet.abi, // multisigV2 abi, for example call_set: { function_name: &quot;submitTransaction&quot;, input: submitTransactionParams, }, keys: { type: 'keyPair', keys: ownerKeyPair } }, }; // Call `submitTransaction` function const sentTransactionInfo = await client.processing.process_message(params);  "},{"title":"How to get TIP3.2 wallet address knowing holder address​","type":1,"pageTitle":"TIP3 Integration Guide","url":"/develop/recipes/tip3-integration#how-to-get-tip32-wallet-address-knowing-holder-address","content":"If you need to get the address of the TIP 3 wallet belonging to a certain holder account, the address of which you know, use the walletOf get method of TokenRoot, passing the holder address to it: https://github.com/broxus/tip3/blob/master/build/TokenRoot.abi.json#L162 // Download tokenRoot account state // `boc` or bag of cells - native blockchain data layout. // Account's boc contains full account state (code and data) that // we will need to execute get methods. const query = ` query { blockchain { account( address: &quot;${address}&quot; ) { info { balance(format: DEC) boc } } } }` const {result} = await client.net.query({query}) const accountState = result.data.blockchain.account.info.boc // Encoding message for local execution of get method. Get methods do not require // signature so we use signer None const { message } = await client.abi.encode_message({ abi: { type: 'Contract', value: TokenRoot.abi, }, address, // token root address call_set: { function_name: walletOf, input: { answerId: 0, walletOwner: ownerMultisigAddress }, }, signer: { type: 'None' }, }); // Run get method const tvm_response = await client.tvm.run_tvm({ message, account: accountState, abi: { type: 'Contract', value: TokenRoot.abi, }, }); const getMethodResult = tvm_response.decoded.output;  "},{"title":"How to get TIP3.2 wallet balance​","type":1,"pageTitle":"TIP3 Integration Guide","url":"/develop/recipes/tip3-integration#how-to-get-tip32-wallet-balance","content":"To get TIP3.2 wallet balance, download tokenWallet account state. It is aboc or bag of cells - native blockchain data layout.Account's boc contains full account state (code and data) that you will need to execute get methods and get the required information.  const query = ` query { blockchain { account( address: &quot;${address}&quot; ) { info { balance(format: DEC) boc } } } }` const {result} = await client.net.query({query}) const accountState = result.data.blockchain.account.info.boc // Encoding message for local execution of get method. Get methods do not require // signature so we use signer None const { message } = await client.abi.encode_message({ abi: { type: 'Contract', value: TokenWallet.abi, }, address, // wallet address call_set: { function_name: balance, input: { answerId: 0 }, }, signer: { type: 'None' }, }); // Run get method const tvm_response = await client.tvm.run_tvm({ message, account: accountState, abi: { type: 'Contract', value: TokenRoot.abi, }, }); const getMethodResult = tvm_response.decoded.output;  "},{"title":"How to make a TIP3.2 transfer​","type":1,"pageTitle":"TIP3 Integration Guide","url":"/develop/recipes/tip3-integration#how-to-make-a-tip32-transfer","content":"Call Holder Wallet of the sender, passing in call parameters payload with internal call parameters, Wallet ABI and address of the token holder (for example, multisig). "},{"title":"To TIP3.2 wallet address​","type":1,"pageTitle":"TIP3 Integration Guide","url":"/develop/recipes/tip3-integration#to-tip32-wallet-address","content":"Encode body of the internal message with a call of the transferToWallet function of sender TIP3.2 wallet. Use the abi.encode_message_body function and ABI of TokenWallet (transferToWallet function) for this. const transfer_payload = (await client.abi.encode_message_body({ abi: { type: 'Contract', value: TokenWallet.abi, }, call_set: { function_name: &quot;transferToWallet&quot;, input: { amount: amount-in-units, recipientTokenWallet: recipient-tip3-2-wallet-address remainingGasTo: holder-wallet-address // or tip32 wallet address notify: false payload: &quot;te6ccgEBAQEAAgAAAA==&quot; // empty cell }, }, is_internal: true, signer: signerNone(), // internal messages have no signature })).body; Send message with the request to transfer funds from TIP3.2 wallet to Holder Wallet: // Prepare input parameter for 'submitTransaction' method of multisig wallet const sendTransactionParams = { dest: tip3-2-wallet-address, // of the sender value: more-than-0.5-evers, // because we will use 0.5 evers for token transfer bounce: true, flags: 3, payload: transfer_payload, //information about transfer and recipient is contained here }; const process_message_params = { send_events: false, message_encode_params: { address: holder_wallet_address, abi: holder_wallet.abi, // multisigV2 abi, for example call_set: { function_name: &quot;submitTransaction&quot;, input: submitTransactionParams, }, keys: { type: 'keyPair', keys: ownerKeyPair } }, }; // Call `submitTransaction` function const sentTransactionInfo = await client.processing.process_message(params);  "},{"title":"To holder address​","type":1,"pageTitle":"TIP3 Integration Guide","url":"/develop/recipes/tip3-integration#to-holder-address","content":"Encode body of the internal message with a call of the transfer function of sender TIP3.2 wallet. Use the abi.encode_message_body function and ABI of TokenWallet (transfer function) for this. const transfer_payload = (await client.abi.encode_message_body({ abi: { type: 'Contract', value: TokenWallet.abi, }, call_set: { function_name: &quot;transfer&quot;, input: { amount: amount-in-units, recipient: recipient-holder-address deployWalletValue: deploy-value // &gt;0, if you want to deploy recipient wallet remainingGasTo: holder-wallet-address // or tip32 wallet address notify: false payload: &quot;te6ccgEBAQEAAgAAAA==&quot; // empty cell }, }, is_internal: true, signer: signerNone(), // internal messages have no signature })).body; Send message with the request to transfer funds from TIP3.2 wallet to Holder Wallet: // Prepare input parameter for 'submitTransaction' method of multisig wallet const sendTransactionParams = { dest: tip3-2-wallet-address, // of the sender value: more-than-0.5-evers, // because we will use 0.5 evers for token transfer bounce: true, flags: 3, payload: transfer_payload, //information about transfer and recipient is contained here }; const process_message_params = { send_events: false, message_encode_params: { holder_wallet_address, abi: holder_wallet.abi, // multisigV2 abi, for example call_set: { function_name: &quot;submitTransaction&quot;, input: submitTransactionParams, }, ownerKeyPair, }, }; // Call `submitTransaction` function const sentTransactionInfo = await client.processing.process_message(params);  "},{"title":"Everdev CLI Quick Start","type":0,"sectionRef":"#","url":"/develop/smart-contracts/everdev","content":"","keywords":""},{"title":"Guide overview​","type":1,"pageTitle":"Everdev CLI Quick Start","url":"/develop/smart-contracts/everdev#guide-overview","content":"This guide will help you get started with such essential Everscale tools as: Everdev CLISolidity CompilerLocal BlockchainEverscale Blockchain ExplorerGraphQL APIEvercloud dashboard You will learn how to: Create and compile your first Solidity contractRun Local blockchain for testingDeploy your first contractRun it on-chainRun a getter-functionMake a transferExplore contract data in Explorer and GraphQL playgroundSwitch to the developer networkConfigure Evercloud accessConfigure devnet giver "},{"title":"Table of Contents​","type":1,"pageTitle":"Everdev CLI Quick Start","url":"/develop/smart-contracts/everdev#table-of-contents","content":"Everdev CLI Quick Start Guide overviewTable of Contents Install everdev - single interface to access all the developer toolsCreate helloWorld contractCompile itRun Local BlockchainConfigure default networkConfigure Giver wallet that will sponsor deploy operationGenerate the keys for contract ownershipCalculate the contract addressDeployView contract information with ExplorerExplore contract information with GraphQLRun on-chainRun a getter functionTransfer some tokensSwitch to Development NetworkSet a giver contract on your network What's next? "},{"title":"Install everdev - single interface to access all the developer tools​","type":1,"pageTitle":"Everdev CLI Quick Start","url":"/develop/smart-contracts/everdev#install-everdev---single-interface-to-access-all-the-developer-tools","content":"$ npm install -g everdev  If you experience any problems with installation, check out our troubleshooting section. "},{"title":"Create helloWorld contract​","type":1,"pageTitle":"Everdev CLI Quick Start","url":"/develop/smart-contracts/everdev#create-helloworld-contract","content":"$ everdev sol create helloWorld  "},{"title":"Compile it​","type":1,"pageTitle":"Everdev CLI Quick Start","url":"/develop/smart-contracts/everdev#compile-it","content":"Using Solidity compiler: $ everdev sol compile helloWorld.sol  You can also use the Solidity compiler driver: $ everdev sold install $ export PATH=&quot;/home/&lt;username&gt;/.everdev/sold:$PATH&quot; $ sold helloWorld.sol  "},{"title":"Run Local Blockchain​","type":1,"pageTitle":"Everdev CLI Quick Start","url":"/develop/smart-contracts/everdev#run-local-blockchain","content":"Attention: Docker should be running. $ everdev se start  "},{"title":"Configure default network​","type":1,"pageTitle":"Everdev CLI Quick Start","url":"/develop/smart-contracts/everdev#configure-default-network","content":"Set Local Blockchain SE (Simple Emulator) as the default network: $ everdev network default se  "},{"title":"Configure Giver wallet that will sponsor deploy operation​","type":1,"pageTitle":"Everdev CLI Quick Start","url":"/develop/smart-contracts/everdev#configure-giver-wallet-that-will-sponsor-deploy-operation","content":"Here we use address and private key of SE High Load Giver. Note: it may be already configured if you make a clean install of the latest Everdev. Then you can skip this step. If you are updating from some old version, it is necessary. $ everdev signer add seGiver 172af540e43a524763dd53b26a066d472a97c4de37d5498170564510608250c3 $ everdev network giver se 0:ece57bcc6c530283becbbd8a3b24d3c5987cdddc3c8b7b33be6e4a6312490415 --signer seGiver  Attention! This giver is available only in SE. If you work in mainnet or devnet, you need to deploy your own giver - more details below. "},{"title":"Generate the keys for contract ownership​","type":1,"pageTitle":"Everdev CLI Quick Start","url":"/develop/smart-contracts/everdev#generate-the-keys-for-contract-ownership","content":"$ everdev signer generate owner_keys $ everdev signer default owner_keys $ everdev s l Signer Public Key Used -------------------- ---------------------------------------------------------------- --------------------------- seGiver 2ada2e65ab8eeab09490e3521415f45b6e42df9c760a639bcf53957550b25a16 se network giver signer EverNode SE Default Giver Keys owner_keys (Default) 3826202b129ea8c041b8d49a655512648fc94377d1958a7a4fc9f4b3051ecf7b  *Note that there are shortcuts for all the commands: s l = signer list :) **Don't forget to make the owner key default otherwise giver keys will be used as default. "},{"title":"Calculate the contract address​","type":1,"pageTitle":"Everdev CLI Quick Start","url":"/develop/smart-contracts/everdev#calculate-the-contract-address","content":"$ everdev c i helloWorld Configuration Network: se (http://localhost) Signer: owner_keys (public 3826202b129ea8c041b8d49a655512648fc94377d1958a7a4fc9f4b3051ecf7b) Address: 0:e74c4258496e79e62e014ca96911acbf5cb0e286fd55dd6f4e3da54e4197ddf5 (calculated from TVC and signer public) Code Hash: c517820144a4daf5a3414c9233556b2b0ad34cdd228f200ea68a4c0327e0bd29 (from TVC file) Account: Doesn't exist  You can see that the contract does not exist yet (is not deployed) but you can already see its future address. "},{"title":"Deploy​","type":1,"pageTitle":"Everdev CLI Quick Start","url":"/develop/smart-contracts/everdev#deploy","content":"Here we deploy the contract, sponsoring it with 10 Tokens (Everscale native currency has 9 decimals). The money for deploy are taken from the giver we configured in the previous steps. $ everdev contract deploy -v 10000000000 helloWorld Configuration Network: se (http://localhost) Signer: owner_keys (public 3826202b129ea8c041b8d49a655512648fc94377d1958a7a4fc9f4b3051ecf7b) Address: 0:e74c4258496e79e62e014ca96911acbf5cb0e286fd55dd6f4e3da54e4197ddf5 (calculated from TVC and signer public) Deploying... Contract has deployed at address: 0:e74c4258496e79e62e014ca96911acbf5cb0e286fd55dd6f4e3da54e4197ddf5  "},{"title":"View contract information with Explorer​","type":1,"pageTitle":"Everdev CLI Quick Start","url":"/develop/smart-contracts/everdev#view-contract-information-with-explorer","content":"Go to localhost and search for your contract address in search bar. Open your account page. You will need it later to see its transactions and messages, that we will produce in the next steps. "},{"title":"Explore contract information with GraphQL​","type":1,"pageTitle":"Everdev CLI Quick Start","url":"/develop/smart-contracts/everdev#explore-contract-information-with-graphql","content":"Go to localhost/graphql. Enter in the left pane and click Run button (replace the contract's address with the one you got in the previous steps). query { accounts( filter: { id: { eq: &quot;0:e74c4258496e79e62e014ca96911acbf5cb0e286fd55dd6f4e3da54e4197ddf5&quot; } } ) { acc_type_name balance code code_hash data } }  You will see: { &quot;data&quot;: { &quot;accounts&quot;: [ { &quot;acc_type_name&quot;: &quot;Active&quot;, &quot;balance&quot;: &quot;0x1db0832ba&quot;, &quot;code&quot;: &quot;te6ccgECEwEAAnkABCj/AIrtUyDjAyDA/+MCIMD+4wLyCxECARICoiHbPNMAAY4SgQIA1xgg+QFY+EIg+GX5EPKo3tM/AY4d+EMhuSCfMCD4I4ED6KiCCBt3QKC53pMg+GPg8jTYMNMfAfgjvPK50x8B2zz4R27yfAUDATQi0NcLA6k4ANwhxwDcIdMfId0B2zz4R27yfAMDQCCCEDtj1H67joDgIIIQaBflNbuOgOAgghBotV8/uuMCCwYEAlgw+EFu4wD4RvJzcfhm0fhC8uBl+EUgbpIwcN74Qrry4Gb4APgj+GrbPH/4ZwUPAHjtRNAg10nCAY4U0//TP9MA1wsf+Gp/+GH4Zvhj+GKOG/QFcPhqcAGAQPQO8r3XC//4YnD4Y3D4Zn/4YeICKCCCEFTWvRi64wIgghBoF+U1uuMCCAcBSts8+EqNBHAAAAAAAAAAAAAAAAA6BflNYMjOIc8LH8lw+wB/+GcQAnIw0ds8IcD/jikj0NMB+kAwMcjPhyDOjQQAAAAAAAAAAAAAAAANTWvRiM8WIc8UyXD7AN4w4wB/+GcJDwECiAoAFGhlbGxvV29ybGQCKCCCEDcxLkW64wIgghA7Y9R+uuMCDgwDSDD4QW7jAPpA1w1/ldTR0NN/39cMAJXU0dDSAN/R2zzjAH/4ZxANDwBU+EUgbpIwcN74Qrry4Gb4AFRxIMjPhYDKAHPPQM4B+gKAa89AyXD7AF8DAkAw+EFu4wDR+EUgbpIwcN74Qrry4Gb4APgj+GrbPH/4ZxAPAC74QsjL//hDzws/+EbPCwD4SgHLH8ntVAAu7UTQ0//TP9MA1wsf+Gp/+GH4Zvhj+GIBCvSkIPShEgAA&quot;, &quot;code_hash&quot;: &quot;c517820144a4daf5a3414c9233556b2b0ad34cdd228f200ea68a4c0327e0bd29&quot;, &quot;data&quot;: &quot;te6ccgEBAQEALwAAWTgmICsSnqjAQbjUmmVVEmSPyUN30ZWKek/J9LMFHs97AAABesq/uBawfEB6wA==&quot; } ] } }  You can specify any other fields in the result section that are available in GraphQL Schema. (Click Docs on the right side of your screen to explore it). What is GraphQL? This is the API of blockchain, to retrieve data from it and to send data into it. You can use this playground later, if you will need need to test some queries. "},{"title":"Run on-chain​","type":1,"pageTitle":"Everdev CLI Quick Start","url":"/develop/smart-contracts/everdev#run-on-chain","content":"Let's move on and run an on-chain method. $ everdev c run helloWorld Configuration Network: se (http://localhost) Signer: owner_keys (public 83cb989d99bce34dd7c04dd05a8a155f2a268d241ef8ec41c4c431cce0827f2d) Address: 0:25d101f07d7ef18260619c5d1cf2bc46173cb70c86129d6eed9ec46ed777e966 (calculated from TVC and signer public) Available functions: 1) renderHelloWorld 2) touch 3) sendValue 4) timestamp Select function (number):  Let's enter 3. You will see the transaction ID of the operation.  &quot;transaction&quot;: { &quot;json_version&quot;: 5, &quot;id&quot;: &quot;8087f774d4b8b4d4716cb31a74deea32550a04b40e853f55c64579fa3897108f&quot;, &quot;boc&quot;: &quot;te6ccgECBw...... ........................  You can also execute it inline like this:\\$ everdev c run helloWorld touch In the result you can see the transaction_id. Search for it on your Contract's page in Explorer and in GraphQL playground (use transactions collection instead of accounts). "},{"title":"Run a getter function​","type":1,"pageTitle":"Everdev CLI Quick Start","url":"/develop/smart-contracts/everdev#run-a-getter-function","content":"$ everdev c run-local helloWorld timestamp Configuration Network: se (http://localhost) Signer: owner_keys (public 3826202b129ea8c041b8d49a655512648fc94377d1958a7a4fc9f4b3051ecf7b) Address: 0:e74c4258496e79e62e014ca96911acbf5cb0e286fd55dd6f4e3da54e4197ddf5 (calculated from TVC and signer public) Execution has finished with result: { &quot;output&quot;: { &quot;timestamp&quot;: &quot;1626898677&quot; }, &quot;out_messages&quot;: [] }  "},{"title":"Transfer some tokens​","type":1,"pageTitle":"Everdev CLI Quick Start","url":"/develop/smart-contracts/everdev#transfer-some-tokens","content":"$ everdev c run helloWorld sendValue Configuration Network: se (http://localhost) Signer: owner_keys (public 3826202b129ea8c041b8d49a655512648fc94377d1958a7a4fc9f4b3051ecf7b) Address: 0:e74c4258496e79e62e014ca96911acbf5cb0e286fd55dd6f4e3da54e4197ddf5 (calculated from TVC and signer public) Parameters of sendValue: dest (address): 0:b5e9240fc2d2f1ff8cbb1d1dee7fb7cae155e5f6320e585fcc685698994a19a5 amount (uint128): 1000000000 bounce (bool): true Running... Execution has finished with result: { &quot;transaction&quot;: { &quot;json_version&quot;: 5, &quot;id&quot;: &quot;550731bb26e5054387a781257e077dbdd769367f16b19bfa529c20475e2a08f6&quot;, &quot;boc&quot;: &quot;te6ccgECCwEAAkwAA7V+dMQlhJbnnmLgFMqWkRrL9csOKG/VXdb049pU5Bl931AAAAAAAAADdx7fDdz4W9u1NnBVF9To555bwxWhiXk8pjgn1OO6cR6wAAAAAAAAAzYPiDAAADRxN2doBQQBAg8MSMYbFBYEQAMCAG/Jh6EgTBRYQAAAAAAAAgAAAAAAAmHZXn3oj36iIsmePH9xls7+ruVE+XB4H24a  Attention! Contracts take value in nanotokens, so in this step we transferred 1 token.Bounce = true means that if the recipient does not exist, money will be returned back. If you plan to transfer money for deploy, specify Bounce = false! Again, now you can find this transaction in Explorer or GraphQL API. "},{"title":"Switch to Development Network​","type":1,"pageTitle":"Everdev CLI Quick Start","url":"/develop/smart-contracts/everdev#switch-to-development-network","content":"The Development Network, aka devnet is the Everscale test network with free test tokens that has an identical configuration to mainnet. You can test your contracts in a live environment on it. To access devnet, you need to create an account and a project on https://dashboard.evercloud.dev/. Follow this guide to do it. You will get your personal project ID, optional secret key and an endpoint of the following format:\\https://devnet.evercloud.dev/projectID/graphql To set devnet up as the default network in everdev, do the following: everdev network default dev  Go to your Evercloud dashboard, find your &quot;Project Id&quot; and &quot;Secret&quot; (optional) on the &quot;Security&quot; tab, and pass them as parameters: everdev network credentials network_name --project &lt;Project Id&gt; --access-key &lt;Secret&gt;  Example: everdev network credentials dev --project 01234567890123456789012345678901 --access-key 98765432109876543210987654321098  "},{"title":"Set a giver contract on your network​","type":1,"pageTitle":"Everdev CLI Quick Start","url":"/develop/smart-contracts/everdev#set-a-giver-contract-on-your-network","content":"While working with SE network, you already have a preset giver. In Devnet you need to configure your own. This contract can be some multisig wallet, for example your Surf account (don't forget to switch it to devnet too!). To get test tokens to your future giver, go to your Evercloud dashboard, open the Endpoints tab of your project, and click the faucet button next to Development Network. Specify the address and you will get some free test tokens. To set the giver up in everdev, first get your giver keys ready. In Surf it is your seed phrase. Save the keys of your giver account into a signer that will be used to sign giver transactions: everdev signer add giver_sign signer_secret_key_or_seed_phrase_in_quotes  Then add the giver address specifying the signer to be used with it. everdev network giver dev giver_address --signer giver_sign --type giver_type  Where giver_type is the type of the giver contract you selected (GiverV1 | GiverV2 | GiverV3 | SafeMultisigWallet | SetcodeMultisigWallet) - for Surf use SetcodeMultisigWallet. Now you can do all the steps of this guide on devnet and see your transactions on your GraphQL playground at https://devnet.evercloud.dev/projectID/graphql and ever.live! "},{"title":"What's next?​","type":1,"pageTitle":"Everdev CLI Quick Start","url":"/develop/smart-contracts/everdev#whats-next","content":"Also take a look at our blockchain basics page that will help you understand the core concepts of Everscale:)If you want to integrate your application with Everscale - dive into our SDK Quick Start!If you want to explore the GraphQL API more, here is the documentation!If you are an exchange - check out our exchange guide! We hope this guide was helpful to you! If you have any difficulties/questions/suggestions/etc. please write to out telegram channel. "},{"title":"Locklift Environment setup","type":0,"sectionRef":"#","url":"/develop/smart-contracts/locklift-setup","content":"","keywords":""},{"title":"Locklift​","type":1,"pageTitle":"Locklift Environment setup","url":"/develop/smart-contracts/locklift-setup#locklift","content":"To improve the development experience, you will need tools and utilities to compile, deploy and test your Everscale contracts. Let's consider Locklift as an example tool. It is a development environment like Hardhat or Truffle and it uses the specified TON Solidity Compiler to build all project contracts. With Locklift, you get: Network management for working with any networks (main, test, local, ...)Automated contract testingHandy wrappers around Everscale smart contractsCustom givers supportKeys managementExternal script runner that executes scripts within a specified environment To install Locklift, run the following command line: npm install -g locklift  "},{"title":"Local node​","type":1,"pageTitle":"Locklift Environment setup","url":"/develop/smart-contracts/locklift-setup#local-node","content":"info You need to have a docker runtime to continue with this. If Locklift is like a Hardhat development environment tool, then local-node is Ganache- like a local blockchain that is designed for dApp debugging and testing. To run local- node you need to follow this command: docker run -d --name local-node -e USER_AGREEMENT=yes -p80:80 tonlabs/local-node  The container exposes the specified 80 port with Nginx which proxies requests to /graphql to GraphQL API. Check out the local explorer at http://localhost/ and GraphQL playground at http://localhost/graphql Once we are all set, the next thing to do is to initialize your first project. "},{"title":"Initialize new project​","type":1,"pageTitle":"Locklift Environment setup","url":"/develop/smart-contracts/locklift-setup#initialize-new-project","content":"Run the following command line: locklift init --path sample-project  This command initializes a new Locklift project, filled with samples: ├── locklift.config.ts ├── tsconfig.json ├── package.json ├── package-lock.json │ ├── contracts │ └── Sample.tsol ├── scripts │ └── 1-deploy-sample.ts ├── test │ └── sample-test.ts  You can see that your smart contract Sample.tsol appeared in the sample-project/contracts directory. "},{"title":"Configuration​","type":1,"pageTitle":"Locklift Environment setup","url":"/develop/smart-contracts/locklift-setup#configuration","content":"The configuration file is called locklift.config.ts. Here's how the basic layout for local node looks like (note, that your config may contain more networks, but the way they are configured is the same): Default locklift.config.ts layout import { LockliftConfig } from &quot;locklift&quot;; import { FactorySource } from &quot;./build/factorySource&quot;; declare global { const locklift: import(&quot;locklift&quot;).Locklift&lt;FactorySource&gt;; } const LOCAL_NETWORK_ENDPOINT = process.env.NETWORK_ENDPOINT || &quot;http://localhost/graphql&quot;; const DEV_NET_NETWORK_ENDPOINT = process.env.DEV_NET_NETWORK_ENDPOINT || &quot;https://devnet-sandbox.evercloud.dev/graphql&quot;; const VENOM_TESTNET_ENDPOINT = process.env.VENOM_TESTNET_ENDPOINT || &quot;https://jrpc-testnet.venom.foundation/rpc&quot;; const VENOM_TESTNET_TRACE_ENDPOINT = process.env.VENOM_TESTNET_TRACE_ENDPOINT || &quot;https://gql-testnet.venom.foundation/graphql&quot;; // Create your own link on https://dashboard.evercloud.dev/ const MAIN_NET_NETWORK_ENDPOINT = process.env.MAIN_NET_NETWORK_ENDPOINT || &quot;https://mainnet.evercloud.dev/XXX/graphql&quot;; const config: LockliftConfig = { compiler: { // Specify path to your TON-Solidity-Compiler // path: &quot;/mnt/o/projects/broxus/TON-Solidity-Compiler/build/solc/solc&quot;, // Or specify version of compiler version: &quot;0.62.0&quot;, // Specify config for extarnal contracts as in exapmple // externalContracts: { // &quot;node_modules/broxus-ton-tokens-contracts/build&quot;: ['TokenRoot', 'TokenWallet'] // } }, linker: { // Specify path to your stdlib // lib: &quot;/mnt/o/projects/broxus/TON-Solidity-Compiler/lib/stdlib_sol.tvm&quot;, // // Specify path to your Linker // path: &quot;/mnt/o/projects/broxus/TVM-linker/target/release/tvm_linker&quot;, // Or specify version of linker version: &quot;0.15.48&quot;, }, networks: { local: { // Specify connection settings for https://github.com/broxus/everscale-standalone-client/ connection: { id: 1, group: &quot;localnet&quot;, type: &quot;graphql&quot;, data: { endpoints: [LOCAL_NETWORK_ENDPOINT], latencyDetectionInterval: 1000, local: true, }, }, // This giver is default local-node giverV2 giver: { // Check if you need provide custom giver address: &quot;0:ece57bcc6c530283becbbd8a3b24d3c5987cdddc3c8b7b33be6e4a6312490415&quot;, key: &quot;172af540e43a524763dd53b26a066d472a97c4de37d5498170564510608250c3&quot;, }, tracing: { endpoint: LOCAL_NETWORK_ENDPOINT, }, keys: { // Use everdev to generate your phrase // !!! Never commit it in your repos !!! // phrase: &quot;action inject penalty envelope rabbit element slim tornado dinner pizza off blood&quot;, amount: 20, }, }, // ... (configs for other networks go here)  For the avoidance of doubt, it’s important that we go through each of the parameters: compiler.version - the version of the solidity compiler binary linker.version - the version of the TVM-linker binary networks - specify which networks are available for deployment and testing. networks.[NETWORK_NAME].keys.phrase - if you leave this field value empty - a new random seed will be generated each time you're running locklift. Or specify it explicitly - fill the phrase field with a mnemonic phrase. "},{"title":"Build​","type":1,"pageTitle":"Locklift Environment setup","url":"/develop/smart-contracts/locklift-setup#build","content":"You can run tests and start to develop your amazing projects. To do this, you need to run the following command. The command uses the specified TON Solidity compiler and TVM linker to build all project contracts: npx locklift build  Now, let’s proceed with testing the sample contract. "},{"title":"Run Tests​","type":1,"pageTitle":"Locklift Environment setup","url":"/develop/smart-contracts/locklift-setup#run-tests","content":"This command runs the project Mocha tests, test folder by default. The locklift object will be set up and included automatically, you don't need to import it manually. npx locklift test -n local  "},{"title":"Invoke Scripts​","type":1,"pageTitle":"Locklift Environment setup","url":"/develop/smart-contracts/locklift-setup#invoke-scripts","content":"There is a common practice to keep various scripts within the same environment where the samrt contracts and tests live. Such scripts may perform deployment, configuration, data collection or and smart-contract upgrade routines. Let's run the sample deployment script within locklift environment (make sure your local node container is up and running) npx locklift run -s scripts/1-deploy-sample.ts -n local  If you succeeded with all steps above, you should see the address, where the Sample.tsol is deployed. "},{"title":"Deploy TIP-3 Token","type":0,"sectionRef":"#","url":"/develop/smart-contracts/use-fungible-tokens","content":"","keywords":""},{"title":"Install Dependencies​","type":1,"pageTitle":"Deploy TIP-3 Token","url":"/develop/smart-contracts/use-fungible-tokens#install-dependencies","content":"To install dependencies, add TIP-3 implementation repository as a devDependencies in the corresponding section of the package.json file. { &quot;devDependencies&quot;: { &quot;tip3&quot;: &quot;git://github.com/broxus/tip3#v5&quot; } }  Then run following command to install dependency: npm i  Specify installed contracts to the externalContracts section of locklift.config.ts, by providing a path to contracts artifacts (.abi.json files, .tvc files, etc., most commonly placed in a build folder of smart contracts projects) and contract names array. const config: LockliftConfig = { compiler: { // ... externalContracts: { &quot;node_modules/tip3/build&quot;: [&quot;TokenRoot&quot;, &quot;TokenWallet&quot;], }, }, // ... }  "},{"title":"Compile Contract​","type":1,"pageTitle":"Deploy TIP-3 Token","url":"/develop/smart-contracts/use-fungible-tokens#compile-contract","content":"Next, the contracts need to be compiled to ensure that artifacts are created. To do this, run the following: npx locklift build  "},{"title":"Deploy​","type":1,"pageTitle":"Deploy TIP-3 Token","url":"/develop/smart-contracts/use-fungible-tokens#deploy","content":"After compiling the contract, we move to deploy. Firstly, we make a new deploy script in the scripts directory for the TokenRoot contract: scripts/01-deploy-token-root.ts import { Address, getRandomNonce, toNano, zeroAddress } from &quot;locklift&quot; import BigNumber from &quot;bignumber.js&quot; async function main() { const signer = (await locklift.keystore.getSigner(&quot;0&quot;))! // Address of initial token supply recipient (write your own) const initialSupplyTo = new Address(&quot;0:7542...&quot;) // Address of token owner (write your own) const rootOwner = new Address(&quot;0:7542...&quot;) // Name of the token const name = &quot;First Everscale Token&quot; // Symbol of the token const symbol = &quot;FET&quot; // How many token will be issued instantly after deploy const initialSupply = 0 // The number of decimals the token uses const decimals = 18 // If true, disables token minting const disableMint = false // If true, disables token burning by root const disableBurnByRoot = false // If true, pauses token burning const pauseBurn = false /* Returns compilation artifacts based on the .sol file name or name from value config.externalContracts[pathToLib]. */ const TokenWallet = locklift.factory.getContractArtifacts(&quot;TokenWallet&quot;) /* Deploy the TIP-3 Token Root contract. @params deployWalletValue: Along with the deployment of the root token, the wallet will be automatically deployed to the owner. This is the amount of EVERs that will be sent to the wallet. */ const { contract: tokenRoot } = await locklift.factory.deployContract({ contract: &quot;TokenRoot&quot;, publicKey: signer.publicKey, initParams: { // this field should be zero address if deploying with public key (see source code) deployer_: zeroAddress, randomNonce_: getRandomNonce(), rootOwner_: rootOwner, name_: name, symbol_: symbol, decimals_: decimals, walletCode_: TokenWallet.code, }, constructorParams: { initialSupplyTo: initialSupplyTo, initialSupply: new BigNumber(initialSupply).shiftedBy(decimals).toFixed(), deployWalletValue: toNano(1), mintDisabled: disableMint, burnByRootDisabled: disableBurnByRoot, burnPaused: pauseBurn, remainingGasTo: zeroAddress, }, value: toNano(5), }); console.log(${name}: ${tokenRoot.address}) } main() .then(() =&gt; process.exit(0)) .catch(e =&gt; { console.log(e) process.exit(1) });  Finally, we can deploy a new token to local network. For this, make sure the local node is running, if not - run the following command: docker run -d --name local-node -e USER_AGREEMENT=yes -p80:80 tonlabs/local-node  Then run the deploy script: npx locklift run -s ./scripts/01-deploy-token.ts -n local  If you succeeded with all steps above, you should see the address, where the TokenRoot contract is deployed. "},{"title":"Tutorial: Tokensale","type":0,"sectionRef":"#","url":"/develop/smart-contracts/tokensale","content":"Tutorial: Tokensale Let's write a simple, step-by-step tokensale contract. For this we need an Everscale development environment. If you don't have it installed yet, please follow this link. In case you do, please proceed with locklift init. npx locklift init --path my-first-crowdsale Now, we need TIP-3 sources. Let’s add them. package.json { &quot;devDependencies&quot;: { &quot;tip3&quot;: &quot;git://github.com/broxus/tip3#v5&quot;, ... }, } locklift.config.ts compiler: { ... externalContracts: { &quot;node_modules/tip3/build&quot;: [&quot;TokenRoot&quot;, &quot;TokenWallet&quot;], }, } Well done! Now it's the time to proceed with our tokensale contract. Create a Tokensale.sol file in your contracts folder. Let's firstly arrange pragmas and imports. Tokensale.sol pragma ever-solidity &gt;= 0.61.2; pragma AbiHeader expire; pragma AbiHeader pubkey; import &quot;tip3/contracts/interfaces/IAcceptTokensTransferCallback.sol&quot;; import &quot;tip3/contracts/interfaces/ITokenRoot.sol&quot;; import &quot;tip3/contracts/interfaces/ITokenWallet.sol&quot;; We will use some interfaces from the TIP-3 implementation. Let's define our contract state and constructor. Tokensale.sol contract Tokensale { uint16 static _nonce; // Some random value to affect on contract address address static _owner; // Tokensale owner. Will receive all transfers address public _distributedTokenRoot; // TIP3 TokenRoot address for deploying wallet for Tokensale. This token will be distributed address public _distributedTokenWallet; // TIP3 wallet for Tokensale for sending purchased tokens uint256 public _supply; // How much tokens will be distributed (with decimals) uint128 public _rate; // How much tokens buyer will receive for 1 nanoever (1*10^9) constructor( address distributedTokenRoot, uint256 supply, uint128 rate, address sendRemainingGasTo ) public { tvm.accept(); // This action is required to process external messages that bring no value - deploy as we have. tvm.rawReserve(1 ever, 0); // we will always reserve 1 ever on this contract _distributedTokenRoot = distributedTokenRoot; _rate = rate; _supply = supply; // fundamental mechanic of dapps working with tip3 - deploy it's own wallet to operate with. check tip3 specs for more info ITokenRoot(distributedTokenRoot).deployWallet { value: 0.2 ever, flag: 1, callback: Tokensale.onTokenWallet // this callback will be called by TokenRoot after deploying wallet for tokensale } ( address(this), 0.1 ever ); // sending remaining gas after setups sendRemainingGasTo.transfer({ value: 0, flag: 128, bounce: false }); } } Let's delve a bit into some mechanics of this piece of code. The first thing that you should look at is gas management. Look at these two lines: tvm.rawReserve(1 ever, 0); sendRemainingGasTo.transfer({ value: 0, flag: 128, bounce: false }); The first line reserves 1 EVER in this contract. Practically, it generates an outbound message carrying reserve nanoevers to oneself so that the next actions performed would not be able to spend more evers than the remainder. The second line is a best practice for gas management in Everscale. You should always send the remaining gas to the message sender or another given address. Pay attention to value and flag parameters of transfer function. Flag 128 means that this transfer will carry all remaining non-reserved gas! To sum up, we have the following flow: Reserving some initial contract balance for an always active state. Perform contract logic (may be checking inbound value in case needed). Send remaining gas with 128 flag to the message sender or another pointed address. The next important logic of our constructor code is deploying a wallet for the contract on-chain. Tokensale.sol ... ITokenRoot(distributedTokenRoot).deployWallet { value: 0.2 ever, flag: 1, callback: Tokensale.onTokenWallet // this callback will be called by TokenRoot after deploying wallet for tokensale } ( address(this), 0.1 ever ); ... This action generates an outbound message to TokenRoot contract by calling a deployWallet function. This function is responsible. It means that it will generate an internal outbound message by calling a function that was passed in a callback parameter (onTokenWallet in our case). Let's implement this function for our Tokensale contract. From TIP-3 source code we know that deployWallet returns only one parameter - deployed wallet address. So, just store it in our state. Tokensale.sol ... function onTokenWallet(address value) external { require ( msg.sender.value != 0 &amp;&amp; msg.sender == _distributedTokenRoot, // check, that calling was from TokenRoot we need 101 // some error code for this require ); tvm.rawReserve(1 ever, 0); _distributedTokenWallet = value; // store deployed tip3 wallet address _owner.transfer({ value: 0, flag: 128, bounce: false }); // sending remaining gas after setups } ... That's all. When we deploy the Tokensale contract, deployWallet will be called too and the returned value will be stored in our contract state. All we need is a function to sell our tokens. Tokensale.sol ... function buyTokens(uint128 deposit) external view { tvm.rawReserve(1 ever, 0); // 1 ever is a technical value for fee...remaining gas will be returned after tokens transfer (from tip3 wallet) if (deposit &gt; msg.value + 1 ever) { // if we using require, we are frozing incoming value in this contract, so just return it msg.sender.transfer({ value: 0, flag: 128, bounce: false }); } else { uint128 purchase = _rate * deposit; if (purchase &gt; _supply) { msg.sender.transfer({ value: 0, flag: 128, bounce: false}); } else { TvmCell empty; // here we just operate with deployed in constructor wallet. owner should provide token supply on this wallet before sales! ITokenWallet(_distributedTokenWallet).transfer{ value: 0, flag: 128 }( purchase, msg.sender, 0.1 ever, // this parameter allows to deploy wallet for user, if it's not deployed yet. (fee takes from message so will be payed by user) msg.sender, false, empty ); } } } ... Notice that we don't use require instruction to check incoming value. If we use require, the user's deposit will not be returned to the sender and will stay in the contract. So anyone can take this as a remaining gas, according to gas management (because these evers won't be reserved). Best practice - when you check something incoming (evers, other TIP-3 tokens), you should use if instead of require. The next mechanic is already familiar to you. Tokensale just calls its own deployed in the constructor wallet to transfer tokens for a buyer. Of course, you should transfer supply tokens to the tokensale wallet before the sale starts :) ITokenWallet(_distributedTokenWallet).transfer{ value: 0, flag: 128 }( purchase, msg.sender, 0.1 ever, // this parameter allows to deploy wallet for user, if it's not deployed yet. (fee takes from message so will be payed by user) msg.sender, false, empty ); Pay attention to value and flag. Again 0 and 128. This allows us to delegate sending of the remaining gas to the TokenWallet contract (of course if you are sure, that delegate performs this action). We send all remaining non-reserved gas to TokenWallet, and, after its own actions, TokenWallet will return the remaining gas where required. (4th parameter of transfer function). So, let's check our final contract code Tokensale.sol pragma ever-solidity &gt;= 0.61.2; pragma AbiHeader expire; pragma AbiHeader pubkey; import &quot;tip3/contracts/interfaces/IAcceptTokensTransferCallback.sol&quot;; import &quot;tip3/contracts/interfaces/ITokenRoot.sol&quot;; import &quot;tip3/contracts/interfaces/ITokenWallet.sol&quot;; contract Tokensale { uint16 static _nonce; // some random value to affect on contract address address static _owner; // tokensale owner. will receive all transfers address public _distributedTokenRoot; // TIP3 TokenRoot address for deploying wallet for Tokensale. This token will be distributed address public _distributedTokenWallet; // TIP3 wallet for Tokensale for sending purchased tokens uint256 public _supply; // How much tokens will be distributed (with decimals) uint128 public _rate; // How much tokens buyer will receive for 1 nanoever (1*10^9) constructor( address distributedTokenRoot, uint256 supply, uint128 rate, address sendRemainingGasTo ) public { tvm.accept(); tvm.rawReserve(1 ever, 0); // we will always reserve 1 ever on this contract _distributedTokenRoot = distributedTokenRoot; _rate = rate; _supply = supply; // fundamental mechanic of dapps working with tip3 - deploy it's own wallet to operate with. check tip3 specs for more info ITokenRoot(distributedTokenRoot).deployWallet { value: 0.2 ever, flag: 1, callback: Tokensale.onTokenWallet // this callback will be called by TokenRoot after deploying wallet for tokensale } ( address(this), 0.1 ever ); // sending remaining gas after setups sendRemainingGasTo.transfer({ value: 0, flag: 128, bounce: false }); } function onTokenWallet(address value) external { require ( msg.sender.value != 0 &amp;&amp; msg.sender == _distributedTokenRoot, 101 ); tvm.rawReserve(1 ever, 0); _distributedTokenWallet = value; // store deployed tip3 wallet address _owner.transfer({ value: 0, flag: 128, bounce: false }); // sending remaining gas after setups } function buyTokens(uint128 deposit) external view { tvm.rawReserve(1 ever, 0); // 1 ever is a technical value for fee...remaining gas will be returned after tokens transfer (from tip3 wallet) if (deposit &gt; msg.value + 1 ever) { // if we using require, we are frozing incoming value in this contract, so just return it msg.sender.transfer({ value: 0, flag: 128, bounce: false }); } else { uint128 purchase = _rate * deposit; if (purchase &gt; _supply) { msg.sender.transfer({ value: 0, flag: 128, bounce: false}); } else { TvmCell empty; // here we just operate with deployed in constructor wallet. owner should provide token supply on this wallet before sales! ITokenWallet(_distributedTokenWallet).transfer{ value: 0, flag: 128 }( purchase, msg.sender, 0.1 ever, // this parameter allows to deploy wallet for user, if it's not deployed yet. (fee takes from message so will be payed by user) msg.sender, false, empty ); } } } } All you need now is to write some tests with locklift support. There are some simple tests and deploy scripts available in the following repo.","keywords":""},{"title":"Developer Tools Overview","type":0,"sectionRef":"#","url":"/develop/tools-overview","content":"","keywords":""},{"title":"Wallets​","type":1,"pageTitle":"Developer Tools Overview","url":"/develop/tools-overview#wallets","content":"Ever SurfEver Wallet "},{"title":"API​","type":1,"pageTitle":"Developer Tools Overview","url":"/develop/tools-overview#api","content":"Evercloud (docs) - Evercloud provides TVM networks developers with scalable GraphQL endpoints. Supports Everscale mainnet, devnet, fld-testnet, TON mainnet, Venom testnet. "},{"title":"Blockchain Explorers​","type":1,"pageTitle":"Developer Tools Overview","url":"/develop/tools-overview#blockchain-explorers","content":"Ever Live (devnet fld rfld)Everscan (devnet) "},{"title":"Tools for developers​","type":1,"pageTitle":"Developer Tools Overview","url":"/develop/tools-overview#tools-for-developers","content":"TON Solidity Compiler (reference) - Port of the Solidity smart-contract compiler generating TVM bytecode for TON blockchain. Can be installed within Everdev or Locklift environments as well, or compiled manually. Everdev CLI (Quick start | docs) - Everdev is a Node.js package with CLI interface that allows to set up developer environment and develop on TVM compatible blockchains (Everscale, Venom, TON, Gosh, etc). Locklift - development environment, analogous to Hardhat. Bytie - smart contracts interaction playground and useful devtools "},{"title":"TON Solidity Compiler IDE integrations​","type":1,"pageTitle":"Developer Tools Overview","url":"/develop/tools-overview#ton-solidity-compiler-ide-integrations","content":"VSCode TON Solidity Compiler plugin 1VSCode TON Solidity Compiler plugin 2JetBrains TON Solidity Compiler plugin "},{"title":"Libraries for developers​","type":1,"pageTitle":"Developer Tools Overview","url":"/develop/tools-overview#libraries-for-developers","content":"JavaScript Ever SDK (docs) - Client Library built for Everscale, Venom blockchain, TON, Gosh for Web, Node.js and React Native platformsRust Ever SDK - Rust Client Library (core) for DApp development in TVM blockchains (Everscale, TON, Venom Blockchain, etc). Bindings to multiple languages available.Surf Keeper JS ProviderEVER Wallet JS ProviderAlternative NodeJS Client "},{"title":"Node-related repos​","type":1,"pageTitle":"Developer Tools Overview","url":"/develop/tools-overview#node-related-repos","content":"Evernode dApp Server - a community (open source) version of Evernode Platform (client supernode with GraphQL API) for TVM blockchains that exposes GraphQL API.Local Node - local blockchain for contract and Dapp testing, exposing GraphQL API. Can be installed and managed within Everdev environmentLight Node - Lightweight node implementationEverscale Node - Validator and Full Node implementationNodekeeper - All-in-one node management tooleverscale-network - minimal implementation of the Everscale network protocol "},{"title":"TVMCell Data structures","type":0,"sectionRef":"#","url":"/develop/tvmcell-data-structure","content":"TVMCell Data structures Everything in Everscale is stored in cells. A cell is a data structure containing: up to 1023 bits of data (not bytes!)up to 4 references to other cells Bits and references are not intermixed (they are stored separately). Circular references are forbidden: for any cell, none of its descendant cells can have this original cell as reference. Thus, all cells constitute a directed acyclic graph (DAG). A cell is an opaque object optimized for compact storage. In particular, it deduplicates data: if there are several eqivalent sub-cells referenced in different branches, their content is only stored once. However, opaqueness means that a cell cannot be modified or read directly. Thus, there are 2 additional flavors of the cells: Builder for partially constructed cells, for which fast operations for appending bitstrings, integers, other cells and references to other cells can be defined.Slice for 'dissected' cells representing either the remainder of a partially parsed cell or a value (subcell) residing inside such a cell and extracted from it via a parsing instruction.Continuation for cells containing op-codes (instructions) for internal use in TVM Any object in Everscale (message, message queue, block, whole blockchain state, contract code and data) serializes to a cell. The process of serialization is described by a TL-B scheme: a formal description of how this object can be serialized into Builder or how to parse an object of a given type from the Slice. TL-B for cells is the same as TL or ProtoBuf for byte-streams.","keywords":""},{"title":"Glossary","type":0,"sectionRef":"#","url":"/overview/concepts","content":"","keywords":""},{"title":"Accounts​","type":1,"pageTitle":"Glossary","url":"/overview/concepts#accounts","content":"This is the place for storing EVERs . Besides storage, users with an account are able to deposit and transfer Ever. The account record stores account address and account balance. Accounts are ultimately stored in TVM. For more information about Accounts please consult this page. "},{"title":"Blockchain​","type":1,"pageTitle":"Glossary","url":"/overview/concepts#blockchain","content":"The chain of all blocks that have been added to the Everscale network throughout the history of the network. Each block has a reference to the previous block. Thus, it permits us to maintain a sequence of all blocks in the chain. "},{"title":"Blocks​","type":1,"pageTitle":"Glossary","url":"/overview/concepts#blocks","content":"There is a very high number of transactions on the Everscale network. Due to this, transactions are grouped in blocks. Each block counts hundreds of transactions. "},{"title":"Ever​","type":1,"pageTitle":"Glossary","url":"/overview/concepts#ever","content":"Ever is the native cryptocurrency of Everscale. Besides being an investment opportunity for users, it has multiple uses inside as well as outside the Everscale network. "},{"title":"Everscale​","type":1,"pageTitle":"Glossary","url":"/overview/concepts#everscale","content":"Decentralised blockchain network that comprises many leading applications and services. Everscale has powerful developer tools, such as compilers for Solidity and C++, API, an SDK that includes client libraries for 13 programming languages and other convenient instruments designed for developers to build outstanding blockchain applications. "},{"title":"Messages​","type":1,"pageTitle":"Glossary","url":"/overview/concepts#messages","content":"All interactions in Everscale are performed via messages. External inbound messages help deploy and call contracts from outside. Internal messages allow contracts to communicate with each other. External outbound messages are the events the contracts produce for the outside world. Use them to implement some off-chain logic - subscribe for these messages and perform some off-chain actions whenever you receive them. For example, simple value transfer can be initiated with an external inbound message (by a human or some service) or with internal message from another contract. This message will produce a transaction (read below) and an internal message with value transfer. For detailed information about Messages please consult this page "},{"title":"Nodes​","type":1,"pageTitle":"Glossary","url":"/overview/concepts#nodes","content":"Nodes are ordinary computers on which the Everscale program is running. Each node is connected to other nodes, which allows to come to a consensus, which is a special mechanism by which information about the correctness of transactions on the network is checked. The Everscale network is the aggregate of all Everscale nodes and their communications. "},{"title":"Shards​","type":1,"pageTitle":"Glossary","url":"/overview/concepts#shards","content":"Shards in Everscale are used for solving the classical issue faced by blockchains, which is low throughput. Sharding is merely partitioning of data in a database, in our case in the Everscale blockchain. Due to sharding, Everscale achieved one of the highest transactions per second rate available out there. For detailed information about how sharding works please consult this page. "},{"title":"Smart contracts​","type":1,"pageTitle":"Glossary","url":"/overview/concepts#smart-contracts","content":"SMs are a kind of algorithm, or program that runs on Everscale or other blockchains, like Ethereum, which was the first to come up with the idea of smart contracts. They work in accordance with a prescribed set of rules that are programmed by developers. When all conditions prescribed in the contract are met, the contract is executed. For more information about smart contracts please consult this page "},{"title":"TVM​","type":1,"pageTitle":"Glossary","url":"/overview/concepts#tvm","content":"TVM is the virtual machine used to execute smart-contract code in the masterchain and in the basic workchain. Any user can request the execution of arbitrary code on the TVM. For more information about TVM please consult this page "},{"title":"Transactions​","type":1,"pageTitle":"Glossary","url":"/overview/concepts#transactions","content":"A transaction is the result of a contract execution. In general, a transaction is generated with one incoming message (external or internal) and can generate several outcoming messages (external or internal) as a result. Any user can broadcast a transaction request to the Everscale network from a node. "},{"title":"Transaction Executorexecu​","type":1,"pageTitle":"Glossary","url":"/overview/concepts#transaction-executorexecu","content":"Takes results of TVM, calculates fees, checks balance and other things. Used by validators to validate blocks. Can also be used on the client side to debug contract execution. For detailed information about Transaction executor please consult this page "},{"title":"Documentation overview","type":0,"sectionRef":"#","url":"/overview/contents","content":"","keywords":""},{"title":"Welcome​","type":1,"pageTitle":"Documentation overview","url":"/overview/contents#welcome","content":"This is the introductory section where you can learn Everscale’s basic concepts, infinite scalability as well as comparisons with Ethereum, Cosmos and Avalanche. Infinite scalabilityDifferences from EVMThe LoreGlossary "},{"title":"Build​","type":1,"pageTitle":"Documentation overview","url":"/overview/contents#build","content":"Get familiar with Everscale’s developer tools and start building. Also, please find the guides to install the IDE and write your first smart contract with Everscale. IntroDeveloper Tools OverviewSmart ContractsRecipes for Backend and Frontend devs "},{"title":"Validator and full node infrastructure​","type":1,"pageTitle":"Documentation overview","url":"/overview/contents#validator-and-full-node-infrastructure","content":"Learn Everscale’s validation in case you want to be a validator or just familiarize yourself with the technology. Validator and Full Node Infrastructure "},{"title":"Specifications​","type":1,"pageTitle":"Documentation overview","url":"/overview/contents#specifications","content":"Learn about incoming external messages tracing via the REMP protocol. Also, study Everscale's token standards, DePools and others. StandardsABIdePool Specification "},{"title":"Architecture​","type":1,"pageTitle":"Documentation overview","url":"/overview/contents#architecture","content":"Learn Everscale's peer-to-peer protocols. Among others, they are used to propagate new blocks as well as send and collect transaction candidates. NetworkingConsensusTL-B and BoCTVMNetwork FeesGas CalculationExecutorLogical Time and Message Delivery GuaranteesAccountMessageTransactionWorkchainsMultithreading and Message Queues "},{"title":"Tutorial: Voting system","type":0,"sectionRef":"#","url":"/develop/smart-contracts/voting-system","content":"Tutorial: Voting system Most leading blockchain networks implement decentralized voting systems. Everscale is no exception to this widespread practice. Let us move directly to an example of how such a system works in practice. We will use a similar TIP-3 mechanic: having a root contract (Vote) and personal Wallets (Ballots). Every participant deploys a ballot for itself that has a vote function, which will call the callback of the Vote contract and pass the vote result into. Nevertheless, what if we want to provide voting rights only for some specific users? In this case, we will have to add an activate function in our Ballot contract, that will be called externally and only by our vote creator (external calls may be signed). No further ado. Let's start with familiar command npx locklift init --path my-smv As mentioned, we need to implement two smart contracts. There are no external dependencies for this guide. Start with the Vote contract. Vote.sol pragma ever-solidity &gt;= 0.61.2; pragma AbiHeader expire; pragma AbiHeader pubkey; import &quot;./Ballot.sol&quot;; contract Vote { uint16 static _nonce; TvmCell static _ballotCode; uint256 _managerPublicKey; uint32 _acceptedCount; uint32 _rejectedCount; constructor( uint256 managerPublicKey, address sendRemainingGasTo ) public { tvm.accept(); tvm.rawReserve(0.1 ever, 0); _managerPublicKey = managerPublicKey; sendRemainingGasTo.transfer({ value: 0, flag: 128, bounce: false }); } } Next function we need - deployBallot. It realizes the popular &quot;deploy contract from contract&quot; mechanic well-described here. We should just use tvm.buildStateInit function, fill varInit section with future values of our Ballot contract static variables and use the keyword new for deploying. Vote.sol pragma ever-solidity &gt;= 0.61.2; ... contract Vote { ... function deployBallot(address owner, address sendRemainingGasTo) external view { tvm.rawReserve(0.1 ever, 0); TvmCell ballotStateInit = tvm.buildStateInit({ contr: Ballot, // varInit section has an affect for target contract address calculation varInit: { _vote: address(this), _managerPublicKey: _managerPublicKey, _owner: owner }, code: _ballotCode // we store it in state }); new Ballot{ stateInit: ballotStateInit, value: 0, flag: 128 }( sendRemainingGasTo ); } ... } Well, the votes will be stored in our Vote contract. That's why we need a special function, that can be called only by Ballot contract. Ballot contract will call this function and pass a vote (accept or reject). But how we can define a function, that can be called only by contracts with concrete code (by contracts, that were deployed by Vote contract)? It can't be any easier. The address of any contract can be definitely calculated if you know state init variables, a public key and contract code: Vote.sol pragma ever-solidity &gt;= 0.61.2; ... contract Vote { ... // this function will be called by ballots, but how we can know - is calling ballot a fake or not? function onBallotUsed(address owner, address sendRemainingGasTo, bool accept) external { tvm.rawReserve(0.1 ever, 0); // if you know init params of contract you can pretty simple calculate it's address TvmCell ballotStateInit = tvm.buildStateInit({ contr: Ballot, varInit: { _vote: address(this), _managerPublicKey: _managerPublicKey, _owner: owner }, code: _ballotCode }); // so address is a hash from state init address expectedAddress = address(tvm.hash(ballotStateInit)); // and now we can just compare msg.sender address with calculated expected address // if its equals - calling ballot has the same code, that Vote stores and deploys if (msg.sender == expectedAddress) { if (accept) { _acceptedCount++; } else { _rejectedCount++; } sendRemainingGasTo.transfer({value: 0, flag: 128, bounce: false}); } else { msg.sender.transfer({ value: 0, flag: 128, bounce: false }); } } ... } That is the way out! TokenWallets of TIP-3 implementation work the same way to transfer tokens (one wallet calls another wallet's acceptTransfer function). The last thing we need is a getDetails view function to return the results of our vote function getDetails() external view returns (uint32 accepted, uint32 rejected) { return (_acceptedCount, _rejectedCount); } Bring it all together Vote.sol pragma ever-solidity &gt;= 0.61.2; pragma AbiHeader expire; pragma AbiHeader pubkey; import &quot;./Ballot.sol&quot;; contract Vote { uint16 static _nonce; TvmCell static _ballotCode; uint256 _managerPublicKey; uint32 _acceptedCount; uint32 _rejectedCount; constructor( uint256 managerPublicKey, address sendRemainingGasTo ) public { tvm.accept(); tvm.rawReserve(0.1 ever, 0); _managerPublicKey = managerPublicKey; sendRemainingGasTo.transfer({ value: 0, flag: 128, bounce: false }); } function deployBallot(address owner, address sendRemainingGasTo) external view { tvm.rawReserve(0.1 ever, 0); TvmCell ballotStateInit = tvm.buildStateInit({ contr: Ballot, varInit: { _vote: address(this), _managerPublicKey: _managerPublicKey, _owner: owner }, code: _ballotCode }); new Ballot{ stateInit: ballotStateInit, value: 0, flag: 128 }( sendRemainingGasTo ); } // this function will be called by ballots, but how we can know - is calling ballot a fake or not? function onBallotUsed(address owner, address sendRemainingGasTo, bool accept) external { tvm.rawReserve(0.1 ever, 0); // if you know init params of contract you can pretty simple calculate it's address TvmCell ballotStateInit = tvm.buildStateInit({ contr: Ballot, varInit: { _vote: address(this), _managerPublicKey: _managerPublicKey, _owner: owner }, code: _ballotCode }); // so address is a hash from state init address expectedAddress = address(tvm.hash(ballotStateInit)); // and now we can just compare msg.sender address with calculated expected address // if its equals - calling ballot has the same code, that Vote stores and deploys if (msg.sender == expectedAddress) { if (accept) { _acceptedCount++; } else { _rejectedCount++; } sendRemainingGasTo.transfer({value: 0, flag: 128, bounce: false}); } else { msg.sender.transfer({ value: 0, flag: 128, bounce: false }); } } function getDetails() external view returns (uint32 accepted, uint32 rejected) { return (_acceptedCount, _rejectedCount); } } Now let's deal with Ballot contract. There is no something special in state and constructor: Ballot.sol pragma ever-solidity &gt;= 0.61.2; pragma AbiHeader expire; pragma AbiHeader pubkey; import &quot;./interfaces/IVote.sol&quot;; contract Ballot { address static _vote; uint256 static _managerPublicKey; // we have a static for owner...so our logic would be like &quot;allow this address to vote&quot; // we can store a static here for ballot number, and our logic would been &quot;allow that ballot to vote&quot; address static _owner; bool _activated; // have ballot already been activated bool _used; // have ballot already been used (vote) constructor(address sendRemainingGasTo) public { // we are reserving another 0.1 here for paying for future external call // all another reserves will be on 0.1 only tvm.rawReserve(0.1 ever + 0.1 ever, 0); if (msg.sender != _vote) { selfdestruct(msg.sender); } _activated = false; _used = false; } } Let's talk about the activation mechanic. In constructor, we already reserved little more EVERs. We made it with the purpose, that fee for the external call will be paid from the contract balance. That way of gas management allows us to transfer external calls fee-paying to user responsibility. But activate method shouldn't be called by somebody unauthorized, so we just use require keyword by comparing msg.pubkey and _managerPublicKey stored in state init. Of course, you need to call tvm.accept() function. Simply put, this call allows the contract to use its own balance for executive pay. Ballot.sol pragma ever-solidity &gt;= 0.61.2; ... import &quot;./interfaces/IVote.sol&quot;; contract Ballot { ... // this function will be called by external message, so contract will pay for this call // this mechanic exists for moving commision paying to user responsibility // in consctructor we reserver a little more EVERs, so here we just will use them (with returning remains) // useful mechaninc for your dapp function activate() external { require(msg.pubkey() == _managerPublicKey, 200); tvm.accept(); // allow to use contract balance for paying this function execution _activated = true; tvm.rawReserve(0.1 ever, 0); _owner.transfer({ value: 0, flag: 128, bounce: false }); } ... } Let's implement the main function of our Ballot - vote. Pay attention to imports. We have import &quot;./interfaces/IVote.sol&quot;. It's just an interface for calling our Vote contract (just like for EVM if you know what I mean). interfaces/IVote.sol pragma ever-solidity &gt;= 0.61.2; pragma AbiHeader expire; interface IVote { function onBallotUsed(address owner, address sendRemainingGasTo, bool accept) external; } Let us now return to vote function Ballot.sol pragma ever-solidity &gt;= 0.61.2; ... import &quot;./interfaces/IVote.sol&quot;; contract Ballot { ... function vote(address sendRemainingGasTo, bool accept) external { require(msg.sender == _owner, 201); // remember the library for error codes :) require(_activated &amp;&amp; !_used, 202); tvm.rawReserve(0.1 ever, 0); // just call our vote contract IVote(_vote).onBallotUsed{ value: 0, flag: 128, bounce: true }(_owner, sendRemainingGasTo, accept); _used = true; } ... } That's all. Vote contract will check our Ballot address by calculating it, as you remember, and the vote will be accepted. But what if Vote calls will fail because of some reason (low gas attached or yet network problem!)? Our Ballot will be marked as used (_used state variable will be set as true, and we can't call vote once again). To solve this problems, TVM has bounce messages and onBounce function for handling them. Let's deal with it by example Ballot.sol pragma ever-solidity &gt;= 0.61.2; ... import &quot;./interfaces/IVote.sol&quot;; contract Ballot { ... // onBounce function! // if our vote contract will reject message, it sends a bounce message to this callback. We should return _used flag to false! onBounce(TvmSlice bounce) external { uint32 functionId = bounce.decode(uint32); // IVote.onBallotUsed send us a bounce message if (functionId == tvm.functionId(IVote.onBallotUsed) &amp;&amp; msg.sender == _vote) { tvm.rawReserve(0.1 ever, 0); _used = false; // reset _used flag to false } } ... } That's it. Now let's bring it all together. Ballot.sol pragma ever-solidity &gt;= 0.61.2; pragma AbiHeader expire; pragma AbiHeader pubkey; import &quot;./interfaces/IVote.sol&quot;; contract Ballot { address static _vote; uint256 static _managerPublicKey; // we have a static for owner...so our logic would be like &quot;allow this address to vote&quot; // we can store a static here for ballot number, and our logic would been &quot;allow that ballot to vote&quot; address static _owner; bool _activated; // have ballot already been activated bool _used; // have ballot already been used (vote) constructor(address sendRemainingGasTo) public { // we are reserving another 0.1 here for paying for future external call // all another reserves will be on 0.1 only tvm.rawReserve(0.1 ever + 0.1 ever, 0); if (msg.sender != _vote) { selfdestruct(msg.sender); } _activated = false; _used = false; sendRemainingGasTo.transfer({ value: 0, flag: 128, bounce: false }); } // this function will be called by external message, so contract will pay for this call // this mechanic exists for moving commision paying to user responsibility // in consctructor we reserver a little more EVERs, so here we just will use them (with returning remains) // useful mechaninc for your dapp function activate() external { require(msg.pubkey() == _managerPublicKey, 200); tvm.accept(); // allow to use contract balance for paying this function execution _activated = true; tvm.rawReserve(0.1 ever, 0); _owner.transfer({ value: 0, flag: 128, bounce: false }); } function vote(address sendRemainingGasTo, bool accept) external { require(msg.sender == _owner, 201); require(_activated &amp;&amp; !_used, 202); tvm.rawReserve(0.1 ever, 0); // just call our vote contract IVote(_vote).onBallotUsed{ value: 0, flag: 128, bounce: true }(_owner, sendRemainingGasTo, accept); _used = true; } // onBounce function! // if our vote contract will reject message, it sends a bounce message to this callback. We should return _used flag to false! onBounce(TvmSlice bounce) external { uint32 functionId = bounce.decode(uint32); // IVote.onBallotUsed send us a bounce message if (functionId == tvm.functionId(IVote.onBallotUsed) &amp;&amp; msg.sender == _vote) { tvm.rawReserve(0.1 ever, 0); _used = false; } } } Do not forget about tests and scripts. We won't show any scripts in this guideline just because there is no something special in them. All source code with deploy script and simple test suites are available in repo. The next section will show you some enhancements for this code.","keywords":""},{"title":"Differences from EVM","type":0,"sectionRef":"#","url":"/overview/differences-from-evm","content":"","keywords":""},{"title":"Sharding​","type":1,"pageTitle":"Differences from EVM","url":"/overview/differences-from-evm#sharding","content":"From the very beginning, Eth 2.0 planned to develop a genuine sharding protocol. It envisaged cross-shared transactions and hundreds of shards. Later, the number of shards was reduced to 32, and now the idea was completely abandoned (at least for the near future). Instead, the decision was made in favor of rollups. The arguments explaining why rollups are not the right solution due to their centralisation and low security are a topic for a separate article. Generally speaking, they are no more than different networks that rely on some security measures from L1. They are also extremely inconvenient for the end users. It is very difficult to implement normal sharding in the Ethereum network due to its inherent synchronous architecture. Aslo, it is troublesome to make synchronous cross-chain transactions, and absolutely impossible to make it so that there is a large throughput. And if each shard exists independently, then this is not much better than rollups are. In Everscale, the asynchronous architecture was designed from scratch. All contracts communicate with each other via messages. Therefore, the only thing needed for sharding to work is the synchronization of message queues between shards. At the same time, since Everscale was developed by blockchain maximalists, they went even further. That is to say, they developed not just a form of classical sharding, but infinite sharding. "},{"title":"Modus operandi​","type":1,"pageTitle":"Differences from EVM","url":"/overview/differences-from-evm#modus-operandi","content":"Currently, Everscale is comprised of two global shards called workchains: Master-workchain (masterchain) for synchronization and governance, and the main workchain for smart contracts. The main workchain can be partitioned into N shards (from 1 to 256 shards). Each shard has its own group of validators. This sub-group is responsible for executing transactions in its own shard. At the same time, it constantly downloads blocks from all other shards of its workchain. A block in Everscale is not just a list of transactions that need to be completed in order to achieve changes in the state. Instead, a block is: A list of messages for which transactions were executed, removing them from the incoming queue.New messages that entered the outgoing queue after message processing.Changes in smart contract states that resulted from message processing. That is, in order for the validator from shard X to maintain the current state of shard Y, it does not need to execute all the transactions that were in the block of shard Y. It simply downloads the block and rolls up the changes that have occurred in the message queue and smart contract states. "},{"title":"Sharding in Everscale is not merely data sharding, but computational resources sharding​","type":1,"pageTitle":"Differences from EVM","url":"/overview/differences-from-evm#sharding-in-everscale-is-not-merely-data-sharding-but-computational-resources-sharding","content":"In case there are too many transactions in the last N block of some particular shard, then the shard is simply divided into two. This is done in accordance with the address range of smart contracts, with some transactions going to one shard while the rest to the other. The resulting shards, in turn, can also be divided into two more. In order for this to work, Everscale also decided to abandon the idea of radical decentralization. The number of validators in the network will be in the number of thousands, not hundreds of thousands like on Ethereum network. Everscale validators are professional players with big stakes and expensive servers. Currently, the validator requirements are: 48 CPUs, 128 RAM and 1TB SDD + 1 GB network bandwidth. Having such sharding capabilities, Everscale achieves a huge network throughput. Importantly, this is accomplished without any damages to customer satisfaction. That is to say, the customer does not have to switch between shards himself, or constantly transfer tokens from one rollup to another. It is important to mention that there is also a big security issue arising. As the number of shards increases, there are fewer instruments to watch over each one of them. Therefore, in the event of a high block mining rate, it may lead to the collusion of the validators of a single shard. This, in turn, could end with someone creating the original message that carries the money not belonging to the originator of the contract. A new consensus mechanism (SMFT) that is currently under development solves this issue. Basically, it takes advantage of the current architecture of Everscale where validators share computation among themselves. This way, all validators always have the data of all shards. It means that each newly issued block can be validated independently. Let’s see how it actually works. Please note that the text below describes the principle of work, not the exact algorithm. Each validator comes up with a random number and sends its hash to other validators.After all shards have created a block, but before the rest of the shards accept it, all validators must take the hash of this block, mix it with a random number, and if the remainder of dividing the resulting number by N is zero, then the validator must check this block, and send validators of -1 governance shard-chain a “yes” or “no”.If there is at least one ‘’no’’, then the verification of this block by the rest of the validators starts. In the case of an invalid block, not only the validators who created this block will be terminated, but also those who said “yes” or remained silent.Before creating the next block, everyone reveals their guessed number and guesses a new one.Thus, shard validators never know which and how many other validators will validate their block. It is a very nice and elegant solution. "},{"title":"Large amount of data and its long tail issue​","type":1,"pageTitle":"Differences from EVM","url":"/overview/differences-from-evm#large-amount-of-data-and-its-long-tail-issue","content":"The original idea of blockchain was that there is a chain of blocks from the very beginning (genesis) to the latest block. And there is always the possibility to synchronize from the genesis block to the latest one, to check that everything runs well. However, already for a long time on Ethereum, full-nodes begin to synchronize with some kind of snapshot from the recent past, and not from the genesis block. Many Ethereum maximalists are still not ready to accept the idea that storing the entire history of blocks is wrong. They believe that history should be stored forever. It entails that there is a need for special protocols to allow users to always check some particular piece of information from history. However, it can be argued that even the Ethereum dev team has abandoned this idea. In the Ethereum 2.0 roadmap, there is the section called “History expiry” stating that full-nodes should not store the history of blocks for more than a year. The history of blocks is critically important for rollups. That is, if a rollup operator terminates its operation, then you need the entire history of its transactions in order to withdraw your money from it, on L1. This is one of the reasons why rollups are a questionable solution. Starting with Eth 2.0, we can only say that the history of blocks is probably stored at least somewhere. It is assumed that the history will be stored by blockchain explorers. The Ethereum devs team are also thinking about some new techniques for storing history. So far there are none. There is also an understanding that we can only choose from one of the following two options: high throughput or storage history. To add, there is also a concept called &quot;Log events&quot;. It was created to simplify the development of Web3 solutions. However, due to the fact that full-nodes or blockchain providers (infura) are as well required to store an infinitely increasing amount of information, the requests to them are very slow. This, too, has already been de facto recognized as a mistake. However, due to the large number of dApps already delivered by Ethereum, it will be difficult for them to refuse this concept. But that's only half the problem. There is also the issue of blockchain state growth. If someone recorded something on the blockchain, at least once, for example, buying a memcoin for 0.001. Then, even if the price of the memcoin goes to zero, the validators will still be required to store the information about your purchase forever. That is, you pay for the record once, but it will be stored forever. And here comes the interesting economics - blockchains are forced to limit the rate of recording transactions artificially so that the size of the blockchain state does not grow faster than data storage becomes cheaper. As a result, users are forced to compete with each other for the right to record data on the blockchain via an auction. Subsequently, it makes the transaction fees increase all the time. This issue has also been de facto acknowledged by the Ethereum team, so that they introduced &quot;State expiry” in the Ethereum 2.0 roadmap. But of course they can't completely solve this problem without breaking backwards compatibility. So far, it is proposed to remove contracts from the state that have not been accessed for N years (for example, 10), with the possibility of recovery. Some other blockchains also explore ways to solve this issue. For example, in Near blockchain, the smart contract must lock N tokens each time it registers new information in the state. The issuer of the smart contract can set the conditions on it, so that the user can delete his information and receive the tokens back. This is definitely only a half-measure. Not all issuers of smart contracts set this condition, and even those who do, do not think about the mechanism of how to return tokens in case the cost of transactions changes in the future. Other blockchains simply remove smart contracts with fewer N tokens on the balance from the state. Everscale never looks for easy and uncostly ways to solve blockchain issues. Therefore, the highlighted problem was resolved with the maximum efficiency and accuracy possible. In the Everscale blockchain, each contract is required to pay rent for storing its data in the state. This rent corresponds to the size of the data. When the money runs out, the contract is deleted with the possibility of recovery, and then deleted completely. Thanks to this, Everscale achieves absolutely controlled behavior, when each smart contract decides for itself how long it will exist. Users do not have to compete with each other for the right to record data, and we get a huge throughput in terms of the number of transactions processed per second. Some other aspects distinguishing Everscale from Ethereum On Everscale, in contrast to Ethereum: Calls between contracts are asynchronous and not atomicContracts cannot run getter methods on other contractsContract code is not immutable and can be updatedThe gas price is constant. Gas wars are impossible. However, transactions may take longer due to threads synchronizationThere are limits on data structure size per contract, for instance, token and NFT standardsEverything is a smart contract, even a simple wallet. A single public key can correspond to a different walletsData structures and memory model differences. Iterable mappings and other TVM specific types "},{"title":"Infinite scalability","type":0,"sectionRef":"#","url":"/overview/infinite-scalability","content":"","keywords":""},{"title":"The Approach to Infinite Scalability​","type":1,"pageTitle":"Infinite scalability","url":"/overview/infinite-scalability#the-approach-to-infinite-scalability","content":"info Everscale scales the network via a combination of both data sharding (workchains) and execution sharding (threads). The Everscale network is split into data shards called workchains. Each election cycle, the global set of validators rotate and are assigned to a workchain. Validators store data and process transactions only for their assigned workchain. As long as validators download blocks of other workchains and update their state based on the changes that occurred, all workchains can run in conjunction. As of now, Everscale is comprised of two global shards: the masterchain and the main workchain. Everscale’s architecture can potentially accommodate up to 2^32 workchains. Each newly created workchain can have its own configuration parameters, virtual machine and native currency,  The masterchain is for the synchronization of messages and transaction execution. That is to say, for a multi-chain network to securely operate, the nodes need to reach consensus. On Everscale, all workchain block proofs are posted to the masterchain. The blocks of the masterchain contain the latest block hashes of all other chains in the network. The main workchain, on the other hand, consists of smart contracts and is used for transactions. Each workchain, on its part, is split into execution shards called threads. Threads contain a chunk of the network’s total number of smart contracts. Validators rotate through the assigned threads and process the transactions only in their thread. The number of threads varies from 1 to 256, depending on the network activity. Such a multithreading approach allows for parallel execution of smart contracts by subgroups of validators that share the same data.  The need to resort to such a technical solution was dictated by several constraints. Namely, the first one arises when there is a need to send a lot of messages between servers. At a certain point, the internet connection could run out. Although data sharding solves this issue, it leaves the second problem, the lack of processing power. For this reason, multithreading, in the form of parallel execution, is fundamental for network scalability. "},{"title":"Everscale’s threading in a nutshell.​","type":1,"pageTitle":"Infinite scalability","url":"/overview/infinite-scalability#everscales-threading-in-a-nutshell","content":"In case of a significant increase in the network load, some shards can be assigned to the neighboring validators.The shards (workchains) offer low transaction fees while at the same time providing the security of Everscale (masterchain).Each election cycle the global set of validators rotate and are assigned to a shard (workchain).In the near future, there will be the possibility to deploy multiple multi-threaded shards (workchains). At the start of 2023, Everscale is still one of the few infinitely scalable blockchains. It is technically ready to process millions of transactions per second, far outpacing both centralized services, like Visa, and decentralized projects that still research different ways to increase their throughput. "},{"title":"The Lore","type":0,"sectionRef":"#","url":"/overview/lore","content":"The Lore Everscale’s chronicle 2017 Pavel Durov develops the concept of TON - Telegram Open Network. The project is inextricably linked with Telegram Messenger, with plans to integrate the Gram cryptocurrency. 2018 TON virtual machine is delivered.-TON blockchain is launched. The network is 70% ready and most of the components are finalized. 2019 EverX (ex. TON Labs) launches the first EVER blockchain with proof of authority consensus algorithm (PoA).EverX launches the alpha version of TON OS.TON test portals for developers with official project specifications are opened - https://test.ton.org/, and https://test.ton.org/testnet/ TON network explorer is available, displaying the first hundreds of working nodes of the network. The U.S. Securities and Exchange Commission (SEC) demands a ban on the issuance of Gram. The SEC, in its report, recognizes Gram as security (not a commodity or utility token) and that Gram issue itself violates securities laws.EverX launches its own TON testnet. 2020 The SEC interrogates Pavel Durov about TON ICO. The interrogation tooks place in Dubai, UAE. The American regulator is trying to find out why Durov launched the ICO, how much money he spent on Telegram and TON, and why the Gram token is not a security. Durov replied that the money was needed to buy equipment and maintain the blockchain platform, and that Gram was a utility token, not a security.Telegram challenges the U.S. court ban on transferring Gram tokens to investors. The court of the Southern District of New York State in a preliminary decision agrees with the SEC's opinion that the project's cryptocurrency is a security. The U.S. authorities claim that investors purchased coins to sell on the secondary market to earn money.Pavel Durov announced on his Telegram channel that he is closing the TON blockchain project. According to Pavel Durov, Telegram's participation in TON development is over. He urged users not to trust money or data to projects that use the name of the messenger or the platform.EverX participates in the community launch of the Free TON blockchain as the core developer.Free TON Community, composed of developers and potential TON users, launches the Free TON blockchain platform. Instead of Gram, participants get tokens called TON Crystal. To become a community member, you need to sign the Free TON Declaration of Decentralization. 2021 Everscale achieves world record throughput - 64 000 transactions per second.-Free TON announces the ecosystem rebrand to Everscale. The new brand identity comes as the network prepares to migrate from C++ to the Rust programming language, enabling unmatched scalability and throughput capable of bringing the world on-chain. 2022 REMP (reliable external messaging protocol) is released ahead of schedule. The protocol is included in the Everscale SDK.The introduction of a set of economic measures to help EVER get into the top 10 by Coinmarketcap.The partnership with DA5 to launch the Philippine blockchain remittance service - marking the first step in Everscale’s rollout of products on the Asian market.The establishment of new development priorities - CBDCs and enterprise solutions. Everscale aims to achieve a high market share in these promising niches. 2023 The partnership with Venom - a blockchain licensed by Abu Dhabi Global Market (ADGM). More partnerships, integrations and technical upgradings coming.","keywords":""},{"title":"Smart Contracts ABI v2.3 Specification","type":0,"sectionRef":"#","url":"/spec/abi","content":"","keywords":""},{"title":"Introduction​","type":1,"pageTitle":"Smart Contracts ABI v2.3 Specification","url":"/spec/abi#introduction","content":"In Everscale client to contract and contract to contract interaction occurs through external and internal messages respectively. ABI specification describes the structure of body of these messages. ABI stored as JSON serves as an interface for smart contracts and is used when calling contract methods externally or on-chain. The goal of the ABI specification is to design ABI types that are cheap to read to reduce gas consumption and gas costs. Some types are optimized for storing without write access. "},{"title":"Message body​","type":1,"pageTitle":"Smart Contracts ABI v2.3 Specification","url":"/spec/abi#message-body","content":""},{"title":"External Inbound Messages​","type":1,"pageTitle":"Smart Contracts ABI v2.3 Specification","url":"/spec/abi#external-inbound-messages","content":"Message body with encoded function call has the following format: Maybe(Signature) + Enc(Header) +Function ID + Enc(Arguments) First comes an optional signature. It is prefixed by one bit flag that indicates the signature presence. If it is 1, then in the next 512 bit a signature is placed, otherwise the signature is omitted. Then comes the encoded header parameters set (same for all functions). It is followed by 32 bits of function ID identifying which contract functions are called. The function ID comes within the first 32 bits of the SHA256 hash of the function signature. The highest bit is set to 0 for function ID in external inbound messages, and to 1 for external outbound messages. Function parameters are next. They are encoded in compliance with the present specification and stored either in the root cell or the next one in the chain. note An encoded parameter cannot be split between different cells "},{"title":"External Outbound Messages​","type":1,"pageTitle":"Smart Contracts ABI v2.3 Specification","url":"/spec/abi#external-outbound-messages","content":"External outbound messages are used to return values from functions or to emit events. Return values are encoded and put into the message response: Function ID+Enc(Return values) Function ID's highest bit is set to 1. Events are encoded as follows: Event ID + Enc(event args) Event ID - 32 bits of SHA256 hash of the event function signature with highest bit set to 0. "},{"title":"Internal Messages​","type":1,"pageTitle":"Smart Contracts ABI v2.3 Specification","url":"/spec/abi#internal-messages","content":"Internal messages are used for contract-to-contract interaction; they have the following body format: Function ID + Enc(Arguments) Function ID - 32 bits function id calculated as first 32 bits SHA256 hash of the function signature. The highest bit of function ID is 0. Internal messages contain only function calls and no responses. "},{"title":"Message Body Signing​","type":1,"pageTitle":"Smart Contracts ABI v2.3 Specification","url":"/spec/abi#message-body-signing","content":"The message body can be protected with a cryptographic signature to identify a user outside the blockchain. In this case, an External inbound message that calls the function carries a user private key signature. This requirement applies only to External inbound messages because Internal inbound messages are generated within the blockchain, and src address can be used to identify the caller. If a user does not want to sign a message, bit 0 should be placed to the root cell start and signature omitted. The message body signature is generated from the representation hash of the bag of cells following the signature prepended with src address. "},{"title":"Signing Algorithm​","type":1,"pageTitle":"Smart Contracts ABI v2.3 Specification","url":"/spec/abi#signing-algorithm","content":"ABI serialization generates bag of cells containing header parameters, function ID and function parameters. 591 free bits are reserved in the root cell for destination address (the maximum size of address).The root cell data is prepended with actual destination address data without padding to maximum size.Representation hash of the bag is signed using the Ed25519 algorithm.Address data is removed from the root cell and replaced with bit 1 followed by 512 bits of the signature. note This functionality is added since ABI v2.3 and supported staring with 0.64.0 version of the Solidity compiler. "},{"title":"Function Signature (Function ID)​","type":1,"pageTitle":"Smart Contracts ABI v2.3 Specification","url":"/spec/abi#function-signature-function-id","content":"The following syntax is used for defining a signature: function namelist of input parameter types (input list) in parenthesislist of return values types (output list) in parenthesisABI version Single comma is used to divide each input parameter and return value type from one another. Spaces are not used. Parameter and return value names are not included. The function name, input and output lists are not separated and immediately follow each other. If a function has no input parameters or does not return any values, the corresponding input or output lists are empty (empty parenthesis). Function ID may be indicated in ABI separately. Then the first bit stays the same regardless of incoming/outgoing message. "},{"title":"Function Signature Syntax​","type":1,"pageTitle":"Smart Contracts ABI v2.3 Specification","url":"/spec/abi#function-signature-syntax","content":"function_name(input_type1,input_type2,...,input_typeN)(output_type1,output_type2,...,output_typeM)v2 "},{"title":"Signature Calculation Syntax​","type":1,"pageTitle":"Smart Contracts ABI v2.3 Specification","url":"/spec/abi#signature-calculation-syntax","content":"SHA256(&quot;function_name(input_type1,input_type2,...,input_typeN)(output_type1,output_type2,...,output_typeM)v2&quot;) "},{"title":"Sample Implementation​","type":1,"pageTitle":"Smart Contracts ABI v2.3 Specification","url":"/spec/abi#sample-implementation","content":"Function func(int64 param1, bool param2) -&gt; uint32 Function Signature func(int64,bool)(uint32)v2 Function Hash sha256(&quot;func(int64,bool)(uint32)v2&quot;) = 0x1354f2c85b50aa84c2f65ebb8cec69aba0aa3269c21e03e142e014e84ea59649 function ID then is 0x1354f2c8 for function call and 0x9354f2c8 for function response "},{"title":"Event ID​","type":1,"pageTitle":"Smart Contracts ABI v2.3 Specification","url":"/spec/abi#event-id","content":"Event ID is calculated in the same way as the function ID except for cases when the event signature does not contain the list of return values types: event(int64,bool)v2 "},{"title":"Header parameter types​","type":1,"pageTitle":"Smart Contracts ABI v2.3 Specification","url":"/spec/abi#header-parameter-types","content":"time: message creation timestamp. Encoded as 64 bit Unix time in milliseconds. expire: Unix time (in seconds, 32 bit) after that message should not be processed by contract. pubkey: public key from key pair used for signing the message body. This parameter is optional. Note: Header may also contain any of standard function parameter types described below to be used in custom checks. "},{"title":"Function parameter types​","type":1,"pageTitle":"Smart Contracts ABI v2.3 Specification","url":"/spec/abi#function-parameter-types","content":"int&lt;N&gt;: two’s complement signed N bit integer. Big-endian encoded signed integer stored in the cell-data. uint&lt;N&gt;: unsigned N bit integer. Big-endian encoded unsigned integer stored in the cell-data. varint&lt;N&gt;: variable-length signed integer. Bit length is between log2(N) and 8 * (N-1), where N is equal to 16 or 32. varuint&lt;N&gt;: variable-length unsigned integer with bit length equal to 8 * N, where Nis equal to 16 or 32 e.g. Processed like varint&lt;N&gt;. bool: equivalent to uint1. tuple (T1, T2, ..., Tn): tuple that includes T1, ..., Tn, n&gt;=0 types encoded in the following way: Enc(X(1)) Enc(X(2)) ..., Enc(X(n)); where X(i) is value of T(i) for i in 1..n Tuple elements are encoded as independent values so they can be placed in different cells map(K,V) is a dictionary of V type values with K type key. Dictionary is encoded as HashmapE type (one bit put into cell data as dictionary root and one reference with data is added if the dictionary is not empty). cell: a type for defining a raw tree of cells. Stored as a reference in the current cell. Must be decoded with LDREF command and stored as-is. Note: this type is useful to store payloads as a tree of cells analog to contract code and data in the form of StateInit structure of message structure. address is an account address in Everscale blockchain. Encoded as MsgAddress struct (see TL-B schema in blockchain spec). bytes: an array of uint8 type elements. The array is put into a separate cell. fixedbytes&lt;N&gt;: a fixed-size array of N uint8 type elements. Encoding is equivalent to bytes string - a type containing UTF-8 string data, encoded like bytes. optional - value of optional type optional(innerType) can store a value of innerType or be empty. itemType[] is a dynamic array of itemType type elements. It is encoded as a TVM dictionary. uint32 defines the array elements count placed into the cell body. HashmapE (see TL-B schema in TVM spec) struct is then added (one bit as a dictionary root and one reference with data if the dictionary is not empty). The dictionary key is a serialized uint32 index of the array element, and the value is a serialized array element as itemType type. T[k] is a static size array of T type elements. Encoding is equivalent to T[] without elements count. "},{"title":"Encoding of function ID and its arguments​","type":1,"pageTitle":"Smart Contracts ABI v2.3 Specification","url":"/spec/abi#encoding-of-function-id-and-its-arguments","content":"Function ID and the function arguments are located in the chain of cells. The last reference of each cell (except for the last cell in the chain) refers to the next cell. After adding the current parameter in the current cell we must presume an invariant (rule that stays true for the object) for our cell: number of unassigned references in the cell must be not less than 1 because the last reference is used for storing the reference on the next cell. The last cell in the chain can use all 4 references to store argument's values. When we add a specific value of some function argument to the cell we assume that it takes the max bit and max ref size for a particular argument type (see types reference section). Only if the current parameter (by max bit or max ref size) does not fit into the current cell do we create a new cell and insert the parameter in the new cell. But if the current argument and all the following arguments fit into the current cell by max size, then we push the parameters in the cell. The serialized argument value takes up only the necessary bits and refs size without aligning to max sizes of its type. In the end we connect the created cells in the chain of cells by assigning the last reference in each cell to next cell. Below are some examples: function f(address a, address b) public;  Here we create 2 cells. In the first cell there is function id and a. There may be not more than 32+591=623 bits (591 bits is the maximum size of 'address'). So it is not more than 1023 bits. The next parameter b thus can't fit into the first cell. In the second cell there is only b. function f(mapping(uint=&gt;uint) a, mapping(uint=&gt;uint) b, mapping(uint=&gt;uint) c, mapping(uint=&gt;uint) d)  map type takes up maximum 1 bit and 1 ref so all parameters can fit into one cell: function ID, a, b c, d. struct A { string a; string b; string c; string d; } function f(A a, uint32 e) public;  Same as the previous example, this fits in one cell because string takes 32 bits and 1 ref. function f(string a, string b, string c, string d, uint32 e) public  Function ID, a, b, c are located in the first cell. d and e fit in the first cell by max size. That's why we push all parameters in the fist cell. function f(string a, string b, string c, string d, uint e, uint f, uint g, uint h) public  uint in Solidity is equal to uint256. We use 3 cells. In the first cell there are function Id, a, b, c. In the second - d, e, f, g. In the third - h. "},{"title":"Encoding header for external messages​","type":1,"pageTitle":"Smart Contracts ABI v2.3 Specification","url":"/spec/abi#encoding-header-for-external-messages","content":"External message's body contains function call header in addition to function ID and arguments. Header has up to 3 optional parameters and mandatory signature. Function ID and function parameters are put after header parameters. Maximum header size is calculated as follows (no references used). maxHeader = 591 + (hasPubkey ? 1 + 256 : 0) + (hasTime ? 64 : 0) + (hasExpire ? 32 : 0);  591 bits are reserved for message destination address to use it while signing the body. Let's look at some examples of header encoding. Assume that header contains time and expire parameters. It requires 591 + 64 + 32 = 687 bits function f(address a, address b) public;  Now we have to use 3 cells. In the first cell we put header and function ID. Parameter a can not fit in first cell so it goes to second and b is put in the third cell. function f(mapping(uint=&gt;uint) a, mapping(uint=&gt;uint) b, mapping(uint=&gt;uint) c, mapping(uint=&gt;uint) d)  Here header and all arguments fit in the first cell. After signing it will contain 645 bits and 4 refs. "},{"title":"ABI JSON​","type":1,"pageTitle":"Smart Contracts ABI v2.3 Specification","url":"/spec/abi#abi-json","content":"The contract interface is stored as a JSON file called contract ABI. It includes all public functions with data described by ABI types. Below is a structure of an ABI file in TypeScript notation: type Abi = { version: string, header?: HeaderParam[], functions: Function[], events?: Event[], data?: Data[], fields?: Param[], } type HeaderParam = Param | string type Function = { name: string, inputs?: Param[], outputs?: Param[], id?: number, } type Event = { name: string, inputs?: Param[], id?: number, } type Data = Param &amp; { key: number, } type Param = { name: string, type: string, components?: Param[], }  "},{"title":"Header​","type":1,"pageTitle":"Smart Contracts ABI v2.3 Specification","url":"/spec/abi#header","content":"This section describes additional parameters of functions within the contract. Header-specific types are specified as strings with the type name. Other types are specified as function parameter type (see Functions)) { &quot;header&quot;: [ &quot;header_type&quot;, { &quot;name&quot;: &quot;param_name&quot;, &quot;type&quot;: &quot;param_type&quot; } ] }  Example { &quot;header&quot;: [ &quot;time&quot;, &quot;expire&quot;, { &quot;name&quot;: &quot;custom&quot;, &quot;type&quot;: &quot;int256&quot; } ] }  "},{"title":"Functions​","type":1,"pageTitle":"Smart Contracts ABI v2.3 Specification","url":"/spec/abi#functions","content":"Specifies each interface function signature, including its name, input, and output parameters. Functions specified in the contract interface can be called from other contracts or from outside the blockchain via ABI call. Functions section has the following fields: { &quot;functions&quot;: [ { &quot;name&quot;: &quot;method_name&quot;, &quot;inputs&quot;: [ {&quot;name&quot;: &quot;func_name&quot;, &quot;type&quot;: &quot;ABI_type&quot;}, ], &quot;outputs&quot;: [], &quot;id&quot;: &quot;0xXXXXXXXX&quot;, //optional } ] }  name: function name;inputs: an array of objects, each containing: name: parameter name;type: the canonical parameter type.components: used for tuple types, optional. id: an optional uint32 id parameter can be added. This id will be used as a Function ID instead of automatically calculated. PS: the last case can be used for contracts that are not ABI-compatible.outputs: an array of objects similar to inputs. It can be omitted if the function does not return anything; "},{"title":"Events​","type":1,"pageTitle":"Smart Contracts ABI v2.3 Specification","url":"/spec/abi#events","content":"This section specifies the events used in the contract. An event is an external outbound message with ABI-encoded parameters in the body. { &quot;events&quot;: [ { &quot;name&quot;: &quot;event_name&quot;, &quot;inputs&quot;: [], &quot;id&quot;: &quot;0xXXXXXXXX&quot;, //optional }, ] }  inputs have the same format as for functions. "},{"title":"Data​","type":1,"pageTitle":"Smart Contracts ABI v2.3 Specification","url":"/spec/abi#data","content":"This section covers the contract global public variables. Data is typically used when deploying multiple identical contracts with the same deployer keys. It affects the contract address, and thus varying data results in unique addresses for identical contracts. { &quot;data&quot;: [ { &quot;name&quot;: &quot;var_name&quot;, &quot;type&quot;: &quot;abi_type&quot;, &quot;key&quot;: &quot;&lt;number&gt;&quot; // index of variable in contract data dictionary }, ] }  "},{"title":"Fields​","type":1,"pageTitle":"Smart Contracts ABI v2.3 Specification","url":"/spec/abi#fields","content":"This section describes internal structure of the smart contracts data. Data structure is described as a list of variables' names with corresponding data types. It includes contract state variables and some internal contract specific hidden variables. They are listed in the order in which they are stored in the data field of the contract. Example for a Solidity contract BankClient: Contract state variables: contract BankClient { uint public creditLimit = 0; // allowed credit limit; uint public totalDebt = 0; // contract total debt; uint public balance = 0; // contract balance; uint public value = 0; // inbound message value. }  Fields section of the abi file: { &quot;fields&quot;: [ {&quot;name&quot;:&quot;_pubkey&quot;,&quot;type&quot;:&quot;uint256&quot;}, {&quot;name&quot;:&quot;_timestamp&quot;,&quot;type&quot;:&quot;uint64&quot;}, {&quot;name&quot;:&quot;_constructorFlag&quot;,&quot;type&quot;:&quot;bool&quot;}, {&quot;name&quot;:&quot;creditLimit&quot;,&quot;type&quot;:&quot;uint256&quot;}, {&quot;name&quot;:&quot;totalDebt&quot;,&quot;type&quot;:&quot;uint256&quot;}, {&quot;name&quot;:&quot;balance&quot;,&quot;type&quot;:&quot;uint256&quot;}, {&quot;name&quot;:&quot;value&quot;,&quot;type&quot;:&quot;uint256&quot;} ] }  "},{"title":"Types Reference​","type":1,"pageTitle":"Smart Contracts ABI v2.3 Specification","url":"/spec/abi#types-reference","content":"time​ Header parameter type. time is the message creation timestamp. Used for replay attack protection, encoded as 64 bit Unix time in milliseconds. Usage\tValue\tExamples\tMax bit size\tMax ref sizeCell\t64 bit, big endian 64 bits\t0 refs JSON object\tstring with hex or decimal representation\t&quot;1685634471&quot;  Rule: the contract should store the timestamp of the last accepted message. The initial timestamp is 0. When a new message is received, the contract should do the following check: last_time &lt; new_time &lt; now + interval, where last_time - last accepted message timestamp (loaded from c4 register), new_time - inbound external message timestamp (loaded from message body), now - current block creation time (just as NOW TVM primitive), interval - 30 min. The contract should continue execution if these requirements are met. Otherwise, the inbound message should be rejected. expire​ Header parameter type. Unix time (in seconds, 32 bit) after which message should not be processed by contract. It is used for indicating lost external inbound messages. Usage\tValue\tExamples\tMax bit size\tMax ref sizeCell\t32 bit, big endian 32 bits\t0 refs JSON object\tstring with hex or decimal representation\t&quot;3600&quot;  Rule: if contract execution time is less then expire time, then execution is continued. Otherwise, the message is expired, and the transaction aborts itself (by ACCEPT primitive). The client waits for message processing until the expire time. If the message wasn't processed during that interval it is considered to be expired. pubkey​ Header parameter type. Public key from key pair used for signing the message body. This parameter is optional. The client decides if they need to set the public key or not. It is encoded as bit 1 followed by 256 bit of public key if parameter provided, or by bit 0 if it is not. Usage\tValue\tExamples\tMax bit size\tMax ref sizeCell\t1 bit, 0 or 1 + 256 bit key if if first bit=1 257 bit\t0 refs JSON object\tstring hexadecimal representation of byte array\t&quot;33a2ed7a92bb55b3aabe1185d0107d48 faa798246c95ed76f262d857c3d1227b&quot;  int&lt;N&gt;​ Fixed-sized signed integer, where N is a decimal bit length. Examples: int8, int32, int256. Usage\tValue\tExamples\tMax bit size\tMax ref sizeCell\tN bit, big endian N bits\t0 refs JSON (returns)\tstring with hex or decimal representation\t&quot;0x12&quot;, &quot;100&quot; JSON (accepts)\tnumber or string with hex or decimal representation\t12, &quot;0x10&quot;, &quot;100&quot;  uint&lt;N&gt;​ Fixed-sized unsigned integer, where N is a decimal bit length e.g., uint8, uint32, uint256. Processed like int&lt;N&gt;. varint&lt;N&gt;​ Variable-length signed integer. Bit length is between log2(N) and 8 * (N-1), where N is equal to 16 or 32, e.g. varint16, varint32. Usage\tValue\tExamples\tMax bit size\tMax ref sizeCell\t4 (N=16) of 5 (N=32) bits that encode byte length of the number len followed by len * 8 bit number in big endian varint16 type — 124 bits, varint32 type — 253 bits, etc.\t0 refs JSON (returns)\tstring with hex or decimal representation\t&quot;0x12&quot;, &quot;100&quot; JSON (accepts)\tnumber or string with hex or decimal representation\t12, &quot;0x10&quot;, &quot;100&quot;  varuint&lt;N&gt;​ Variable-length unsigned integer with bit length equal to 8 * N, where Nis equal to 16 or 32 e.g., varint16, varint32. Processed like varint&lt;N&gt;. bool​ Boolean type. Usage\tUsage\tExamples\tMax bit size\tMax ref sizeCell\t1 bit, 0 or 1 1 bit\t0 refs JSON (returns)\ttrue, false JSON (accepts)\ttrue, false, 0, 1, &quot;true&quot;, &quot;false&quot;\t0, true, &quot;false&quot;  tuple​ Struct type, consists of fields of different types. All fields should be specified as an array in the components section of the type. structure (aka tuple) type is considered as a sequence of its types when we encode the function parameters. That's why tuple type doesn't have max bit or max ref size. Nested tuple's also are considered as a sequence of its types. For example: struct A { uint8 a; uint16 b; } struct B { uint24 d; A a; uint32 d; }  structure B is considered as a sequence of uint24, uint8, uint16, uint32 types. For example, for structure S: struct S { uint32 a; uint128 b; uint64 c; }  parameter s of type S would be described like: { &quot;components&quot;: [ {&quot;name&quot;:&quot;a&quot;,&quot;type&quot;:&quot;uint32&quot;}, {&quot;name&quot;:&quot;b&quot;,&quot;type&quot;:&quot;uint128&quot;}, {&quot;name&quot;:&quot;c&quot;,&quot;type&quot;:&quot;uint64&quot;} ], &quot;name&quot;:&quot;s&quot;, &quot;type&quot;:&quot;tuple&quot; }  Usage\tValue\tExamplesCell\tchain of cells with tuple data types encoded consistently (without splitting value between cells) JSON object\tdictionary of struct field names with their values\t{&quot;a&quot;: 1, &quot;b&quot;: 2, &quot;c&quot;: 3} map(&lt;keyType&gt;,&lt;valueType&gt;)​ Hashtable mapping keys of keyType to values of the valueType, e.g., map(int32, address). Key may be any of int&lt;N&gt;/uint&lt;N&gt; types with N from 1 to 1023 or address of std format. Usage\tValue\tExamples\tMax bit size\tMax ref sizeCell\t1 bit (0 - for empty mapping, otherwise 1) and ref to the cell with dictionary 1 bit\t1 ref JSON object\tdictionary of keys and values\t{&quot;0x1&quot;:&quot;0x2&quot;}, {&quot;2&quot;:&quot;3&quot;,&quot;3&quot;:&quot;55&quot;}  There are some specifics when working with &quot;big&quot; structures as values in mappings. Read below how to implement them correctly. cell​ TVM Cell type. Usage\tValue\tExamples\tMax bit size\tMax ref sizeCell\tstored in a ref 0 bit\t1 ref JSON object\tcell serialized into boc and encoded in base64\t&quot;te6ccgEBAQEAEgAAH/////////////////////g=&quot;  address​ Contract address in type address, can be any of the existing variants (although not all may be supported by the compilator you are using). Important notes: All hexadecimal values represented in lower case.Bitstrings are represented in hexadecimal variable length form with _ suffix if length is not multiple of 4. When length is multiple of 4 bitstring is always encoded without _ suffix. Format &quot;&quot; // None &quot;:A...A&quot; // External &quot;[N..N:]W:A...A&quot; // Internal  where: W is a decimal signed representation for workchain_id.A...A is a string representation of bitstring (see important nodes above);N...N is a string representation of bitstring with anycast rewrite prefix. Serialization Internal addresses are serialised as: std when workchain id is 8-bit and address is 256-bitvar otherwise. Size Maximum size allocated for address is 591 bits: see https://github.com/ton-blockchain/ton/blob/master/crypto/block/block.tlb#L107 anycast_info$_ depth:(#&lt;= 30) { depth &gt;= 1 } rewrite_pfx:(bits depth) = Anycast; addr_var$11 anycast:(Maybe Anycast) addr_len:(## 9) workchain_id:int32 address:(bits addr_len) = MsgAddressInt; 2 + // 11 1 + 5 + 30 + // anycast 9 + // addr_len 32 + // workchain_id:int32 512 // address = 591  Usage\tValue\tExamples\tMax bit size\tMax ref sizeCell\t2 bits of address type, 1 bit of anycast, wid - 8 bit signed integer and address value - 256 bit unsigned integer 591 bits\t0 refs JSON object\tstring\t&quot;123:000000000000000000000000000000 000000000000000000000000000001e0f3&quot;  bytes​ An array of uint8 type elements. The array is put into a separate cell. In the case of array overflow, the maximum cell-data size it's split into multiple sequential cells. Note: contract stores this type as-is without parsing. For high-speed decoding, cut reference from body slice as LDREF. This type is helpful if some raw data must be stored in the contract without write or random access to elements. Analog of bytes in Solidity. In C lang can be used as void*. Usage\tValue\tExamples\tMax bit size\tMax ref sizeCell\tcell with data stored in a ref 0 bit\t1 ref JSON object\tbinary daya represented as hex string\t&quot;313233&quot;  fixedbytes&lt;N&gt;​ Where N is a decimal byte length from 1 to 32. It is denoted in abi as uint&lt;M&gt;, where M is a bit length and M = 8 * N. Processed like int&lt;N&gt;. string​ UTF-8 String data. Encoded like bytes. In JSON is represented as a sting. Usage\tValue\tExamples\tMax bit size\tMax ref sizeCell\tcell with data stored in a ref 0 bit\t1 ref JSON object\tstring data\t&quot;hello&quot;  optional(innerType)​ Value of optional type optional(innerType) can store a value of innerType or be empty. Example: optional(string). The optional type is a large if maxBitSize(InnerType) + 1 &gt; 1023 || maxRefSize(InnerType) &gt;= 4. Large optional values are always stored as a reference. The optional bit itself is stored on the main branch. Small optional values are stored in the same cell with the optional bit. Usage\tValue\tExamples\tMax bit size\tMax ref sizeCell\t1 bit flag (1 - value is stored, otherwise 0) and the value itself (according to innerType) if it presents 1 bit if optional is large, 1 bit + maxBitQty(T), maxRefQty(T) otherwise\t1 ref if optional is large, 0 refs otherwise JSON object\taccording to innerType or null if it is empty\t&quot;hello&quot;  itemType[]​ Array of the itemType values. Example: uint256[] Usage\tValue\tExamples\tMax bit size\tMax ref sizeCell\t32 unsigned bit length of the array, 1 bit flag (0 if array is empty, otherwise 1) and dictionary of keys and values where key is 32 unsigned bit index and value is itemType 33 bit\t1 ref JSON object\tlist of itemType values in []\t[1, 2, 3], [&quot;hello&quot;, &quot;world&quot;]  There are some specifics when working with &quot;big&quot; structures as values in arrays. Read below how to implement them correctly. "},{"title":"\"Big\" structures as values in mappings and arrays​","type":1,"pageTitle":"Smart Contracts ABI v2.3 Specification","url":"/spec/abi#big-structures-as-values-in-mappings-and-arrays","content":"When working with &quot;big&quot; structures in mappings and arrays data may be written in two possible ways - either into cell or into reference, depending on the size: if (12 + len(key) + maxValueBitLength &lt;= 1023) then write data into cell else write data to reference. 12 = 2 + 10 ≥ 2 + log2(keyLength).  See https://github.com/ton-blockchain/ton/blob/master/crypto/block/block.tlb#L30 "},{"title":"Reference​","type":1,"pageTitle":"Smart Contracts ABI v2.3 Specification","url":"/spec/abi#reference","content":"ABI changelog specificationsABI implementationABI parserABI serializer "},{"title":"DeBot Specifications","type":0,"sectionRef":"#","url":"/spec/debot-specifications","content":"","keywords":""},{"title":"Objective​","type":1,"pageTitle":"DeBot Specifications","url":"/spec/debot-specifications#objective","content":"Provide a secure and convenient environment to work with smart-contracts emulate calling smart-contract functions locally on the client;debug blockchain transactions;interact with smart-contracts deployed in the blockchain. "},{"title":"Basic terms​","type":1,"pageTitle":"DeBot Specifications","url":"/spec/debot-specifications#basic-terms","content":"DeBot — a smart contract facilitating conversation-like flow communication with a target smart contract;Target smart contract — a smart contract for which DeBot is created. DeBot is an interface to this smart contract;DeBot protocol — a set of rules describing the communication between browser and DeBot: how to call DeBot functions and how to interpret its answers;DeBot engine (DEngine) — a program component that executes DeBot and parses its answer using DeBot protocol;DeBot browser — a program, which creates instances of DEngine for executed DeBot and renders the user interface. "},{"title":"Architecture​","type":1,"pageTitle":"DeBot Specifications","url":"/spec/debot-specifications#architecture","content":" DeBot platform consists of the following elements: DeBot smart contract;DeBot browser;Target smart contract(s). One target smart contract can have several DeBot and vise versa. DeBot is deployed to the blockchain. DeBot browser runs on client. It downloads DeBot code and runs it inside the DEngine. "},{"title":"Proof of State​","type":1,"pageTitle":"DeBot Specifications","url":"/spec/debot-specifications#proof-of-state","content":"Transactions can be verified by running DeBot locally and comparing the result of execution to the account state in the blockchain. "},{"title":"DeBot Interfaces​","type":1,"pageTitle":"DeBot Specifications","url":"/spec/debot-specifications#debot-interfaces","content":""},{"title":"Motivation​","type":1,"pageTitle":"DeBot Specifications","url":"/spec/debot-specifications#motivation","content":"DeBot is a smart contract and smart contracts are isolated from each other and from the blockchain, their capabilities are limited by the commands of the virtual machine on which they are executed. But DeBot must have more possibilities. DeBot need to: receive input from users;query info about other smart contracts;query transactions and messages;receive data from external subsystems (like file system) and external devices (like NFC, camera and so on);call external function libraries that allow to do operations that are not supported by VM. For example, work with json, convert numbers to string and vice versa, encrypt/decrypt/sign data. To cover all these needs we should design different DeBot Interfaces (DInterfaces) which can be used in DeBot and which must be supported in DeBot Browsers. These interfaces should match the requirements: comprehensive — interfaces should describe all types of communication accessible on modern devices;universal — interfaces should be abstract from certain OS and hardware;atomic — every communication channel should be separately described in the interface for further flexible resource access management;convenient — even low-skilled developers should be able to use this interface in their DeBot. In this model DeBot Engine should act like a proxy between DeBot Browser and DeBot. But it can have builtin implementation of very basic DInterfaces (e.g. working with json). Also, we need to describe the manifest for DeBot. DeBot developer will describe all needed interfaces in this manifest and the DeBot Browser will check it before running DeBot. We need this manifest to keep users secure and private when using DeBot. "},{"title":"Description​","type":1,"pageTitle":"DeBot Specifications","url":"/spec/debot-specifications#description","content":"Every DeBot must declare which DInterfaces it will use. For this purpose it must have getRequiredInterfaces() function which returns array of required interfaces. Every interface must have an id which is an unsigned 256-bit integer and an address which is used in DeBot as a destination address of internal messages. Address must be a standard Everscale address consisting of DEBOT_WC (equal to 0xDB) as a workchain_id part and interface id as address part (see &quot;Telegram Open Network Blockchain&quot;specification, section 3.1.2 for details about TL-B scheme for address). For example, in solidity getRequiredInterfaces can be implemented like this: // Base contract for all DeBot abstract contract Debot { i32 constant DEBOT_WC = - 31; function getRequiredInterfaces() virtual returns (uint256[] interfaces); } contract DebotA is Debot { function getRequiredInterfaces() override returns (uint256[] interfaces) { return [ID_TERMINAL, ID_MENU, ...]; } }  "},{"title":"How to use DInterface in DeBot​","type":1,"pageTitle":"DeBot Specifications","url":"/spec/debot-specifications#how-to-use-dinterface-in-debot","content":"To use an interface DeBot should import source file with DInterface declaration and call its methods as any other smart contract methods in Everscale — by sending internal messages to interface address. Before running the DeBot, DeBot Browser should provide callbacks for DEngine to receive all requests to DInterfaces. Requests are packed into internal messages. When Browser receives a message from DEngine it should unpack the message, decode its body, call DInterface function, pack results to internal message and return it to DEngine using Dengine.send(msg). interface BrowserCallbacks { // Message from Debot to Browser with encoded DInterface call send(message: string): Promise&lt;void&gt; // Request from DEngine to approve some action (for example, send mesage to blockchain) approve(action: {}): boolean // Request from DeBot to call another DeBot invoke(debotAddress: string, message: string): Promise&lt;void&gt; }  "},{"title":"DeBot Start​","type":1,"pageTitle":"DeBot Specifications","url":"/spec/debot-specifications#debot-start","content":"Befor starting DeBot should also provide metadata, which includes its name, version, authorship information, description, language and ABI. This is accomplished through the getDebotInfo() mandatory function. Along with getRequiredInterfaces() this function is defined in the base contract Debot.sol. // Base contract for all DeBots abstract contract Debot { /// @notice ACTION structure struct Action { // String that describes action step, should be printed to user string desc; // Name of debot function that runs this action string name; // Action type uint8 actionType; // Action attributes. // Syntax: &quot;attr1,attr2,attr3=value,...&quot;. // Example: &quot;instant,fargs=fooFunc,sign=by-user,func=foo&quot; string attrs; // Context to transit to uint8 to; // Action internal data TvmCell misc; } struct Context { uint8 id; // Context ordinal string desc; // message to be printed to the user Action[] actions; // list of actions } string s_dabi; /* * Public debot interface */ /// @notice Returns list of interfaces used by DeBot. function getRequiredInterfaces() public view virtual returns (uint256[] interfaces); /// @notice Used for error handling for external messages if error code &gt;= 400 (TVM) and &lt; 500 (PROCESSING) function getErrorDescription(uint32 error) public pure virtual returns (string desc); /// @notice Invoked by DeBot Browser at debot startup. Returns array of debot contexts. function fetch() public virtual returns (Context[] contexts); /// @notice DeBot entry point. function start() public virtual; /// @notice Returns DeBot metadata. /// @return name String with name of debot, e.g. &quot;DePool&quot;. /// @return version Semver version of debot, that will be converted to string like &quot;x.y.z&quot;. /// @return publisher String with info about who has deployed debot to blokchain, e.g. &quot;TON Labs&quot;. /// @return caption (10-20 ch.) String with short description, e.g. &quot;Work with Smthg&quot;. /// @return author String with name of author of DeBot, e.g. &quot;Ivan Ivanov&quot;. /// @return support Everscale address of author for questions and donations. /// @return hello String with first messsage with DeBot description. /// @return language (ISO-639) String with debot interface language, e.g. &quot;en&quot;. /// @return dabi String with debot ABI. function getDebotInfo() public functionID(0xDEB) view virtual returns( string name, string version, string publisher, string caption, string author, address support, string hello, string language, string dabi, bytes icon ); /// @notice Allow to set debot ABI. Do it before using debot. function setABI(string dabi) public { require(tvm.pubkey() == msg.pubkey(), 100); tvm.accept(); s_dabi = dabi; } /// @notice Returns DeBot ABI. /// @dev Deprecated. Remove later. https://github.com/tonlabs/TON-SDK/blob/dc0631a726295c4e7190361c417214c301ec4e01/ton_client/src/debot/dengine.rs#L175 function getDebotOptions() public view returns ( uint8 options, string debotAbi, string targetAbi, address targetAddr ) { debotAbi = s_dabi; targetAbi = &quot;&quot;; targetAddr = address(0); options = 1; } } contract MyDeBot is Debot { function getErrorDescription(uint32 error) public pure override returns (string desc) { tvm.log(format(&quot;getErrorDescription: {}&quot;, error)); desc = format(&quot;some description about code {}&quot;, error); // TODO description error codes } function fetch() public override returns (Context[] contexts) { tvm.log(&quot;fetch&quot;); // TODO fetch Context } function start() public override { tvm.log(&quot;start&quot;); // TODO start } function getDebotInfo() public functionID(0xDEB) view override returns( string name, string version, string publisher, string caption, string author, address support, string hello, string language, string dabi, bytes icon ) { tvm.log(&quot;getDebotInfo&quot;); name = &quot;MyDeBot&quot;; version = &quot;1.0.0-alpha.0&quot;; publisher = &quot;Everscale&quot;; caption = &quot;My first DeBot&quot;; author = &quot;Everscale&quot;; support = address.makeAddrStd(0, 0x0); hello = &quot;Hello first user!&quot;; language = &quot;en&quot;; dabi = s_dabi; icon = &quot;&quot;; } function getRequiredInterfaces() public view override returns (uint256[] interfaces) { tvm.log(&quot;getRequiredInterfaces&quot;); // TODO add dependency interfaces } }  Run debug log: npx tonos-cli debot --debug fetch &lt;ADDRESS&gt; 19:43:58 [DEBUG] (1) ton_client::debot::dengine: running getRequiredInterfaces, addr 0:5225bff6b13f40518f523c18c7af8dcc46a3369845d98cc7df4e36acca5f8490 19:43:58 [INFO] getRequiredInterfaces 19:43:58 [DEBUG] (1) ton_client::debot::dengine: running getDebotInfo, addr 0:5225bff6b13f40518f523c18c7af8dcc46a3369845d98cc7df4e36acca5f8490 19:43:58 [INFO] getDebotInfo 19:43:58 [DEBUG] (1) ton_client::debot::dengine: run_debot_external getDebotOptions, args: {} 19:43:58 [DEBUG] (1) ton_client::debot::dengine: running getDebotOptions, addr 0:5225bff6b13f40518f523c18c7af8dcc46a3369845d98cc7df4e36acca5f8490 19:43:58 [DEBUG] (1) ton_client::debot::dengine: run_debot_external fetch, args: {} 19:43:58 [DEBUG] (1) ton_client::debot::dengine: running fetch, addr 0:5225bff6b13f40518f523c18c7af8dcc46a3369845d98cc7df4e36acca5f8490 19:43:58 [INFO] fetch DeBot Info: Name : MyDeBot Version: 1.0.0-alpha.0 Author : Everscale Publisher: Everscale Support: 0:0000000000000000000000000000000000000000000000000000000000000000 Description: My first DeBot Hello first user! Run the DeBot (y/n)? y 19:44:02 [DEBUG] (1) ton_client::debot::dengine: running getRequiredInterfaces, addr 0:5225bff6b13f40518f523c18c7af8dcc46a3369845d98cc7df4e36acca5f8490 19:44:02 [INFO] getRequiredInterfaces 19:44:02 [DEBUG] (1) ton_client::debot::dengine: running getDebotInfo, addr 0:5225bff6b13f40518f523c18c7af8dcc46a3369845d98cc7df4e36acca5f8490 19:44:02 [INFO] getDebotInfo 19:44:02 [DEBUG] (1) ton_client::debot::dengine: run_debot_external getDebotOptions, args: {} 19:44:02 [DEBUG] (1) ton_client::debot::dengine: running getDebotOptions, addr 0:5225bff6b13f40518f523c18c7af8dcc46a3369845d98cc7df4e36acca5f8490 19:44:02 [DEBUG] (1) ton_client::debot::dengine: run_debot_external fetch, args: {} 19:44:02 [DEBUG] (1) ton_client::debot::dengine: running fetch, addr 0:5225bff6b13f40518f523c18c7af8dcc46a3369845d98cc7df4e36acca5f8490 19:44:02 [INFO] fetch 19:44:02 [DEBUG] (1) ton_client::debot::dengine: switching to 0 19:44:02 [DEBUG] (1) tonos_cli::debot::callbacks: switched to ctx 0 19:44:02 [DEBUG] (1) ton_client::debot::dengine: run_action: start 19:44:02 [DEBUG] (1) ton_client::debot::dengine: run_debot_external start, args: {} 19:44:02 [DEBUG] (1) ton_client::debot::dengine: running start, addr 0:5225bff6b13f40518f523c18c7af8dcc46a3369845d98cc7df4e36acca5f8490 19:44:02 [INFO] start 19:44:02 [DEBUG] (1) ton_client::debot::dengine: instant_switch = false, state_to = 0 19:44:02 [DEBUG] (1) tonos_cli::debot::callbacks: no more actions, exit loop  Before starting the DeBot, DeBot Browser creates new instance of DEngine with address of DeBot;DEngine downloads DeBot state, queries metadata and list of DInterfaces required by DeBot and returns the list to Browser;Browser must check that it supports all required DInterfaces. If one of interfaces is not supported, Browser must report error to the user (application) and not start the DeBot otherwise Browser must list requested interfaces to user (application);All required interfaces should be approved by user (application);After the list of interfaces is approved, the DeBot Browser starts DeBot using Dengine.start(callback). On every interface call Browser should check permission for DeBot and on success execute it according to isolation requirement if needed. Below you can see DeBot start sequence:  "},{"title":"DInterface specification​","type":1,"pageTitle":"DeBot Specifications","url":"/spec/debot-specifications#dinterface-specification","content":"Every DInterface must be discussed and accepted by DeBot Interface Specifications (DIS) Consortium before it can be used in DeBot. All accepted interfaces are published in DeBot Interface Specifications Consortium. Everybody can suggest new DInterface. Go to repo and follow the instructions. "},{"title":"DInterfaces support in DeBot Browser​","type":1,"pageTitle":"DeBot Specifications","url":"/spec/debot-specifications#dinterfaces-support-in-debot-browser","content":"DeBot Browser can support and implement any or all DInterfaces published in DIS repo depending on browser's capabilities. For example, console browser cannot support external devices like camera, NFC, microphone and so on. Some interfaces required for basic DeBot operation are built into the DEngine itself (SDK, Hex, JsonDeserialize). They are marked as such in their respective readme files in the DeBot Interface Specifications Consortium. "},{"title":"DEngine versioning​","type":1,"pageTitle":"DeBot Specifications","url":"/spec/debot-specifications#dengine-versioning","content":"DEngine as a SDK module should have a version of SDK itself. DIS statuses: Proposed, Accepted, Published. "},{"title":"Example of DInterface​","type":1,"pageTitle":"DeBot Specifications","url":"/spec/debot-specifications#example-of-dinterface","content":"Name\tIDRawInput\t8796536366ee21852db56dccb60bc564598b618c865fc50c8b1ab740bba128e3 "},{"title":"Description​","type":1,"pageTitle":"DeBot Specifications","url":"/spec/debot-specifications#description-1","content":"Allows to get string from user "},{"title":"Functions​","type":1,"pageTitle":"DeBot Specifications","url":"/spec/debot-specifications#functions","content":"Function input arguments: answerId: uint32 — function id of result callbackprompt: bytes — string printed to the user and describing what to enter returns: text: bytes — string entered by user "},{"title":"Declaration in Solidity​","type":1,"pageTitle":"DeBot Specifications","url":"/spec/debot-specifications#declaration-in-solidity","content":"interface IRawInput { function input(uint32 answerId, string prompt) external returns (string value); } Library RawInput { uint256 constant ID_RAWINPUT = 0x8796536366ee21852db56dccb60bc564598b618c865fc50c8b1ab740bba128e3 // Callback Function Prototype function inputResult(uint32 answerId, string prompt) public { address addr = address.makeAddrStd(DEBOT_WC, ID_RAWINPUT); IRawInput(addr).input(answerId, prompt); } }  "},{"title":"Declaration in C++​","type":1,"pageTitle":"DeBot Specifications","url":"/spec/debot-specifications#declaration-in-c","content":"namespace tvm { namespace schema { __interface IRawInput { [[internal, answer_id]] string input(string prompt); };  "},{"title":"Code Example​","type":1,"pageTitle":"DeBot Specifications","url":"/spec/debot-specifications#code-example","content":"Solidity​ pragma solidity &gt;=0.6.0; import &quot;Debot.sol&quot;; import &quot;RawInput.sol&quot;; contract ExampleDebot is Debot, RawInput { function start() public { RawInput.input(tvm.functionId(inputResult), &quot;enter your name:&quot;); RawInput.input(tvm.functionId(inputResult), &quot;enter your wallet address:&quot;); } function inputResult(string text) public override { require(text == &quot;Debot&quot;); } }  Note: C++ DeBot are currently in the state of early development, and not all features all completely defined for them yet. "},{"title":"DeBot Special Features​","type":1,"pageTitle":"DeBot Specifications","url":"/spec/debot-specifications#debot-special-features","content":"DeBot have 3 special features: calling — get-methods of target smart contracts;calling — external functions of target smart contracts onchain;invoking — other DeBot in a local environment. Ordinary Everscale smart contracts cannot use 1st and 2nd features because they cannot produce external inbound messages. But DeBot can, due to the fact that they are executed in DEngine, that allows DeBot to generate these kinds of messages, send them to blockchain and return results to DeBot. In terms of DeBot, all these features are implemented without DInterfaces but in a native way, like two smart contracts communicating with each other — by sending messages directly to target address. But with only one difference — to call a get-method or call a function onchain DeBot must generate external inbound message, while to invoke another DeBot, it should generate an internal message to the invoked DeBot address. DEngine distinguishes between get-methods and onchain calls by examining the sign header of the message. Signed messages (sign: true) are considered onchain calls, while unsigned messages (sign: false) are considered to be get-method calls. "},{"title":"Get-methods​","type":1,"pageTitle":"DeBot Specifications","url":"/spec/debot-specifications#get-methods","content":"Developer Example​ Solidity function showTasks(uint32 index) public view { index = index; optional(uint256) none; ITodo(m_address).getTasks{ abiVer: 2, extMsg: true, sign: false, pubkey: none, time: uint64(now), expire: 0, callbackId: tvm.functionId(showTasks_), onErrorId: tvm.functionId(onError) }(); }  Support in DEngine​ DEngine executes DeBot and checks if it produces external inbound messages. If yes, then DEngine analyzes each message by scanning signature and public key bits in message body to understand if message is for get-method call. If bits are zero DEngine downloads target contract and runs its get-method, then returns results to DeBot by calling its function set in the callbackId or onErrorId (in case of errors) headers of message body. "},{"title":"Onchain function call​","type":1,"pageTitle":"DeBot Specifications","url":"/spec/debot-specifications#onchain-function-call","content":"Developer example​ Solidity IMsig(m_msigAddress).sendTransaction{ abiVer: 2, extMsg: true, sign: true, pubkey: pubkey, time: uint64(now), expire: 0, callbackId: tvm.functionId(waitBeforeDeploy), onErrorId: tvm.functionId(onErrorRepeatCredit) }(m_address, INITIAL_BALANCE, false, 3, empty); }  Support in DEngine​ DEngine executes DeBot and checks if it produces external inbound messages. If there is one, DEngine analyzes if it is onchain call by scanning signature and public key bits in message body. If signature bit is 1 then DEngine does the following things. Downloads target smart contract, signs the message and emulates its transaction locally;Checks if transaction produces outbound internal messages with funds;Requests permission from DeBot Browser to send this message onchain. Request contains information about funds that will be spent if message will be executed onchain and message itself;If DeBot Browser allows to send message, DEngine sends message to blockchain. "},{"title":"Invoking DeBot​","type":1,"pageTitle":"DeBot Specifications","url":"/spec/debot-specifications#invoking-debot","content":"DeBot can call another DeBot by simply sending internal message to it. After DeBot execution DEngine filters all internal messages produced by DeBot with destination addresses with workchain 0. This filter allows to separate DInterface calls (which have 0xDB workchain id) from DeBot invokes. If there are invoke messages, DEngine sends them to Browser through BrowserCallbacks interface. Browser (or user) has to approve the invoke of a new DeBot, at which point Browser creates a new DEngine instance, downloads target DeBot and transfers the message to it. Browsers should generally support a common queue for messages from several DeBot. "},{"title":"Security notes​","type":1,"pageTitle":"DeBot Specifications","url":"/spec/debot-specifications#security-notes","content":"At start browser creates a DEngine instance, and receives DeBot metadata and list of required DInterfaces through DEngine, and checks them for compatibility and security. When DeBot is running, DEngine proxies all DInterface calls (except calls to builtin interfaces supported by engine itself like SDK calls) directly to Browser which must decide to execute or reject them. Get-method calls are always allowed. Executed by DEngine. External function calls must be approved by Browser. Executed by DEngine. Other DeBot calls are always allowed. But executed by Browser which can block invoke if needed. "},{"title":"dePool specification","type":0,"sectionRef":"#","url":"/spec/depool-specification","content":"","keywords":""},{"title":"Background​","type":1,"pageTitle":"dePool specification","url":"/spec/depool-specification#background","content":"It is quite evident that to achieve high-performance properties, a network needs powerful, reliable servers with fast connectivity. At the same time, to achieve sufficient decentralization, these servers have to belong to as many owners as possible. There seems to be a contradiction between these goals. In Proof-of-Work networks, performance is often sacrificed for decentralization. Yet, claims arise that the centralization of Bitcoin, Ethereum etc. mining power is not entirely prevented. Mining Pools centralization remains an issue, as these pools are controlled by particular entities distributing rewards. For example, almost 60% of Bitcoin mining power is concentrated in just 4 pools and around 80% of all mining power originates in China. Just 2 mining pools control 52% of Ethereum hashrate, more than 50% of which originates in China. In Proof-of-Stake, the correlation between network performance and concentration of power (money in this case) is even more apparent, as one does not need to buy, set up, and manage complicated mining farms. It can ultimately be claimed that POS is trading performance for decentralization (look no further than EOS centralization, Steemit network overtaking etc.). It seems that enabling small token holders to participate in network governance is a very important decentralization property. "},{"title":"Motivation​","type":1,"pageTitle":"dePool specification","url":"/spec/depool-specification#motivation","content":"Everscale blockchain needs all newly created blocks to be validated in order to run correctly. For this it relies on special designated nodes called &quot;Validators&quot;, and offers substantial reward for their work. However, becoming a validator requires a substantial cryptocurrency deposit. The required amount might far exceed an individual validator budget. On the other hand, blockchain users with no validating system might be interested in investing in validation duty. This is where the Decentralized Pool (DePool) smart contract comes in. There are two main use cases of DePool: User has no Validator capabilities but some free funds. User can support a third-party Validator and receive rewards.User has Validator capabilities and but doesn't have necessary amount of funds to participate in validator elections and subsequent rewards. "},{"title":"Basic terms​","type":1,"pageTitle":"dePool specification","url":"/spec/depool-specification#basic-terms","content":"DePool — a smart contract that allows other smart contracts to invest stakes into a common pool of funds and after some period of time to receive it back with interest.Elector — a system level smart contract, deployed to masterchain from zero state. Runs validator elections periodically.DePool Proxy (proxy) — a smart contract that delivers messages between DePool and Elector.Participant — a smart contract that invests funds into DePool.Validator — software running blockchain node. Each DePool works with one node only. This node must be a DePool participant.Validator wallet — a smart contract that is used by Validator to send election requests to DePool and receive the Validator reward. Validator wallet should be a Multisig contract with 3 custodians.DePool Helper — a smart contract that stores the address of the actual DePool and works with the Timer contract.Global Validators Set (GVS) — current set of validators chosen in the latest elections.Validation period — period of time for which GVS is elected.Investment round — period of time between Participant investing a stake in DePool and receiving it back (with or without interest).Timer — a smart contract that can call other smart contracts periodically. "},{"title":"Architecture​","type":1,"pageTitle":"dePool specification","url":"/spec/depool-specification#architecture","content":" DePool is designed to receive investment stakes from Participants, allocate the pool funds to a validator in order to participate in elections of the GVS and, after the end of the validation cycle, distribute stakes with certain rewards back to the Participants.DePool is deployed to basechain. But it cannot communicate with Elector directly, because Elector rejects messages from non-masterchain contracts. Thus there are DePool proxies that are deployed to masterchain and deliver messages from DePool to Elector and back. This is done, because DePool is a large and complex contract, and gas and storage fees are 10 times lower in basechain compared to masterchain. Keeping DePool on masterchain would be unreasonably expensive.DePool is open for Participants’ stakes at all times, however, there is a deadline for participation in the upcoming elections. The deadline depends on the timer of the Elector. After the deadline, the incoming stakes will be accumulated for participation in the next elections.DePool distinguishes stakes received before the deadline and after the deadline, therefore it stores information on Participant stakes in separate investment rounds (or rounds), one for every elections, to facilitate subsequent distribution of stakes and rewards. To separate Elector communication, DePool uses 2 proxies: one for even rounds, one for odd.In order to be time-aware, the DePool should be called from time to time. For this purpose the Timer contract is used. DePool Helper asks Timer to call it periodically and transmits every call from Timer to DePool. Interval between calls is chosen according to the elections interval.DePool must be linked to a validator wallet to participate in elections on behalf of the latter. This validator wallet address is specified during DePool deployment and cannot be changed afterwards. When elections start, DePool waits for signed election requests from linked wallet, then attaches round stake to request and transmits it to Elector.Validator can validate many DePools with 1 Validator wallet. Reputation of Validator wallet therefore is available and can be analyzed over time.To ensure that the validator will perform its functions correctly (be always online and not &quot;lie&quot; to other validators), the validator wallet must itself become a Participant and invest in every investment round at least m_validatorAssurance, which is initialized in DePool constructor. This can be achieved with any of the three available types of stakes.When Elector unfreezes validator stakes, DePool returns its stake back with round rewards. Part of the total reward is used to top up the DePool's own balance to a certain value. The rest is distributed as follows: m_validatorRewardFraction% goes to Validator wallet balance. m_participantRewardFraction% is distributed among all Participants in investment round (validator is also participant). m_associationRewardFraction% (can be equal to zero) goes to m_association address.DePool keeps a balance for each Participant and can automatically reinvest Participant's stake into the next investment round if appropriate flag is enabled.Participant can transfer part of its total stake to another Participant's stake inside DePool storage. This function allows for collateralization of the stake to provide liquidity to stake holders. "},{"title":"Special kinds of stakes​","type":1,"pageTitle":"dePool specification","url":"/spec/depool-specification#special-kinds-of-stakes","content":"Along with the basic ordinary stake, that functions according to the rules detailed above, there are 2 types of special stakes: vesting and lock stake. While the entire ordinary stake is invested into the current pooling round (and will thus be reinvested every second round), lock and vesting stakes are split into two equal parts upon reception, which are invested into the current pooling round, and the next round. This way they can be continuously reinvested into both odd and even rounds. "},{"title":"Vesting Stake​","type":1,"pageTitle":"dePool specification","url":"/spec/depool-specification#vesting-stake","content":"Any address can make a vesting stake and define a target participant address (beneficiary) who will own this stake. But not the whole stake is available to the beneficiary at once. Instead it is split into logical parts and the next part of stake becomes available to the participant only when next vesting period is ended. At completion step of every round DePool decides how many vesting parts should be unlocked and subtracted from vesting stake and become available to owner since last unlocking. These funds are added to beneficiary's ordinary stake. Example: address A makes a vesting stake of 120 tons for 1 year with vesting period of 1 month and defines address B as the stake beneficiary. It means that after 1 month 10 tons become available to address B and 110 tons are still locked in the pool. After 1 year vesting stake will be equal to 0 and last 10 tons will become available to owner. Vesting for validator beneficiaries is subject to additional rules: At the end of every withdrawal period, the part of the vesting stake to be released is divided proportionally into 2 parts — for rounds in this period when DePool successfully completed validation and received a reward (without slashing) and for rounds when DePool missed elections or was slashed. The portion of the stake corresponding to the successful rounds is sent to the validator, while the portion corresponding to the failed rounds is returned to the vesting stake owner. For example, if there were 100 rounds within the withdrawal period, and DePool successfully completed 80 of them, missed elections in 5 more and was slashed in the remaining 15, the validator will receive 80% of the unlocked part of the vesting stake, and the stake owner will get back 20% of it. "},{"title":"Lock Stake​","type":1,"pageTitle":"dePool specification","url":"/spec/depool-specification#lock-stake","content":"Any address can make a lock stake, in which it locks its funds in DePool for a defined period, but rewards from this stake will be payed to another target participant (beneficiary). At the end of a period the Lock Stake should be returned to the address which locked it. Example: address A makes a lock stake of 120 tons for 1 year with vesting period of 1 month and defines address B as the stake beneficiary. It means that after 1 month 10 tons become available to address A (as opposed to vesting, where these 10 tons would become available to address B, the beneficiary) and 110 tons are still locked in round. DePool will reinvest the gradually diminishing lock stake for a 1 year and pay rewards to B address. After 1 year DePool will return the remainder of the lock stake to address A. One Participant can be a beneficiary only of one lock and one vesting stake. Once current lock or vesting stake of the participant expires, it can be repeated. When a stake of either of these types is created, it is split equally into two last rounds, which means that the minimal value for such stake is 2 * minStake + fee. "},{"title":"Specification​","type":1,"pageTitle":"dePool specification","url":"/spec/depool-specification#specification","content":""},{"title":"Data Structures​","type":1,"pageTitle":"dePool specification","url":"/spec/depool-specification#data-structures","content":"DePool contract uses library and inheritance from several simple base contacts to separate functionality and facilitate development and debugging of the contract. The core data set stored by DePool is the following: DePoolLib.sol // Describes contract who deposit stakes in DePool pool struct Participant { // Count of rounds in which participant takes a part uint8 roundQty; // Sum of all rewards from completed rounds (for logging) uint64 reward; // count of parts of vesting stakes in the rounds uint8 vestingParts; // count of parts of lock stakes in the rounds uint8 lockParts; // Flag whether to reinvest ordinary stakes and rewards bool reinvest; // Target tons that will be transferred to participant after rounds are completed // After each round this value is decreased uint64 withdrawValue; } // Request for elections from validator wallet. struct Request { // Random query id. uint64 queryId; // Validator's public key that will be used as validator key if validator will win elections. uint256 validatorKey; // current election id. uint32 stakeAt; // Validator's stake factor. uint32 maxFactor; // Validator's address in adnl overlay network. uint256 adnlAddr; // Ed25519 signature of above values. bytes signature; }  DePoolRounds.sol // roundPre0 = m_rounds[m_roundQty - 1] — pre-pooling. Helper round for adding vesting and lock // stakes. When vesting/lock stake is added than stake is // split into two part. And first part invested into pooling // round and second part — pre-pooling. // // round0 = m_rounds[m_roundQty - 2] — pooling // round1 = m_rounds[m_roundQty - 3] — election or validation // round2 = m_rounds[m_roundQty - 4] — validation or investigation // Algo of round rotation: // delete round2 // round1 -&gt; round2 // round0 -&gt; round1 // roundPre0 -&gt; round0 // createNewRound -&gt; roundPre0 mapping(uint64 =&gt; Round) m_rounds; // count of created rounds uint64 m_roundQty = 0;  DePoolBase.sol // Dictionary of participants for rounds mapping (address =&gt; Participant) m_participants; // Address of the validator wallet address m_validatorWallet; // Array of proxies addresses. address[] m_proxies;  DePool.sol // Indicates that pool is closed. Closed pool doesn't accept stakes from other contracts. bool m_poolClosed; // Min stake accepted to the pool in nTon (for gas efficiency reasons): 10 tons is recommended. uint64 m_minStake; // Minimum validator stake in each round uint64 m_validatorAssurance; // % of participant rewards uint8 m_participantRewardFraction; // % of validator rewards uint8 m_validatorRewardFraction; // % of dePool association rewards uint8 m_associationRewardFraction; // Association address address m_association; // Minimum balance uint64 m_minimumBalance;  "},{"title":"DePool Initialization​","type":1,"pageTitle":"dePool specification","url":"/spec/depool-specification#depool-initialization","content":"When deployed, the DePool constructor is called with the following parameters: /// @dev DePool's constructor. /// @param minStake Min stake that participant may have in one round. /// @param validatorAssurance Min validator stake. /// @param proxyCode Code of proxy contract. /// @param validatorWallet Address of validator wallet. /// @param participantRewardFraction % of reward that distributed among participants. constructor( uint64 minStake, uint64 validatorAssurance, TvmCell proxyCode, address validatorWallet, uint8 participantRewardFraction, )  At initialization the variable m_balanceThreshold is set as current DePool account balance — 5 tokens. DePool will replenish its balance from validation rewards to this value every round it receives rewards. "},{"title":"Participant functions​","type":1,"pageTitle":"dePool specification","url":"/spec/depool-specification#participant-functions","content":"DePool stores some participant information in a dictionary (m_participants) where key — Participant's address and value — Participant structure. Functions used by participants perform checks and send receiveAnswer message back to the caller with an error code and a comment in case of failure. If all conditions are met, DePool sends a confirmation message (receiveAnswer with status 0) back to the caller. All functions can be called by internal messages only. addOrdinaryStake(uint64 stake) — allows to make an ordinary stake in the current pooling round. The source address of the message is taken as Participant's address. The Participant's total stake is increased by stake amount. Parameters: stake — value of participant's stake in nanotons. Function checks that: inbound message value is at least (stake + ADD_STAKE_FEE);stake is at least min stake;pool is not closed. Function returns change (part of unused ADD_STAKE_FEE). addVestingStake(uint64 stake, address beneficiary, uint32 withdrawalPeriod, uint32 totalPeriod) — allows to add a vesting stake for another participant (beneficiary). The source address of the message is saved as the vesting stake owner. Parameters: stake — value of participant's stake in nanotons (Note: this value is divided into 2 parts and is added to 2 rounds).beneficiary — address of target participant (beneficiary);withdrawalPeriod — the period in seconds after which the part of the vesting becomes available for beneficiary;totalPeriod — total period of vesting in seconds after which beneficiary becomes owner of the whole stake. Function checks that: DePool is not closed (m_poolClosed ≠ true);beneficiary is an addr_std. It's not zero address. It's not the message sender (not self vesting);inbound msg.value ≥ (m_minStake + ADD_STAKE_FEE);Message value is at least stake + STAKE_FEE;stake / 2 is at least min stake;withdrawalPeriod ≤ totalPeriod;totalPeriod &lt; 18 years;withdrawalPeriod ≠ 0;totalPeriod % withdrawalPeriod = 0;beneficiary doesn't have a vesting stake. addLockStake(uint64 stake, address beneficiary, uint32 withdrawalPeriod, uint32 totalPeriod) — allows to add a stake that will bring rewards to another participant (beneficiary). The source address of the message is saved as the lock stake owner. It has the same parameters and checks as addVestingStake, but it checks that participant doesn't have a lock stake instead of a vesting stake. withdrawFromPoolingRound(uint64 withdrawValue) — allows to remove Participant's stake from the current pooling round. Parameters: withdrawValue — desired amount of stake to be removed. Function checks that: inbound msg.sender address is address of an existing participant. If real ordinary stake is less than withdrawValue, then DePool returns the whole stake from pooling round. If the remaining stake in the pooling round is less than m_minStake, then the whole stake is transferred to Participant. If the remaining total stake of Participant is 0, then it is removed from the m_stakeholders dictionary. withdrawPart(uint64 withdrawValue) — Allows a participant to withdraw some value from DePool. This function withdraws withdrawValue nanotons when rounds are completed. If participant stake becomes less than minStake, then the whole stake is sent to participant. Parameters: withdrawValue — desired amount of stake to be removed. Function checks that: pool is not closed (m_poolClosed ≠ true);inbound msg.sender address is address of an existing participant. If the remaining stake in the round is less than m_minStake, then the whole stake will be transferred to Participant (after completing round). If the remaining total stake of Participant is 0, then it is removed from the m_stakeholders dictionary. 6. withdrawAll() — Set global flag for the participant that indicates to return participant's ordinary stake after completing rounds. Function checks that: pool is not closed (m_poolClosed ≠ true);inbound msg.sender address is address of an existing participant. After transferring all Participant's stake, the Participant will be removed from the m_stakeholders dictionary. cancelWithdrawal() — Cancel effect of calls of functions withdrawAll and withdrawPart. transferStake(address dest, uint64 amount) — allows to move amount of stake from msg.sender Participant to dest Participant inside DePool storage. Parameters: dest — stake beneficiary;amount — stake value transferred to dest in nanotons. Function checks that: pool is not closed (m_poolClosed ≠ true);destination is a non-zero addr_std;msg.sender ≠ dest;neither destination nor msg.sender is the validator wallet;inbound msg.sender address is address of an existing participant;desired amount can be transferred and transfer doesn't leave stake less than m_minStake in any round. In case of success DePool sends back a notification via onTransfer function calling to beneficiary. "},{"title":"Functions of interface DePoolInfoGetter:​","type":1,"pageTitle":"dePool specification","url":"/spec/depool-specification#functions-of-interface-depoolinfogetter","content":"function getLastRoundInfo() public If there is no completed round yet, call callback function receiveDePoolInfo with struct containing default values, else send call with struct containing info about last completed round. // Represent info about last completed round struct LastRoundInfo { uint32 supposedElectedAt; uint8 participantRewardFraction; uint8 validatorRewardFraction; uint32 participantQty; uint64 roundStake; address validatorWallet; uint256 validatorPubkey; uint64 validatorAssurance; }  "},{"title":"Participant callback functions:​","type":1,"pageTitle":"dePool specification","url":"/spec/depool-specification#participant-callback-functions","content":"These functions are called by DePool to send notifications to Participant. receiveAnswer(uint32 errcode, uint64 comment) — function, which is called as an answer from DePool to Participant. Arguments: errcode — error code. List of codes: uint8 constant STATUS_SUCCESS = 0; uint8 constant STATUS_STAKE_TOO_SMALL = 1; uint8 constant STATUS_DEPOOL_CLOSED = 3; uint8 constant STATUS_NO_PARTICIPANT = 6; uint8 constant STATUS_PARTICIPANT_HAVE_ALREADY_VESTING = 9; uint8 constant STATUS_WITHDRAWAL_PERIOD_GREATER_TOTAL_PERIOD = 10; uint8 constant STATUS_TOTAL_PERIOD_MORE_18YEARS = 11; uint8 constant STATUS_WITHDRAWAL_PERIOD_IS_ZERO = 12; uint8 constant STATUS_TOTAL_PERIOD_IS_NOT_DIVED_BY_WITHDRAWAL_PERIOD = 13; uint8 constant STATUS_PERIOD_PAYMENT_IS_ZERO = 14; uint8 constant STATUS_REMAINING_STAKE_LESS_THAN_MINIMAL = 16; uint8 constant STATUS_PARTICIPANT_HAVE_ALREADY_LOCK = 17; uint8 constant STATUS_TRANSFER_AMOUNT_IS_TOO_BIG = 18; uint8 constant STATUS_TRANSFER_SELF = 19; uint8 constant STATUS_TRANSFER_TO_OR_FROM_VALIDATOR = 20; uint8 constant STATUS_FEE_TOO_SMALL = 21; uint8 constant STATUS_INVALID_ADDRESS = 22; uint8 constant STATUS_INVALID_BENEFICIARY = 23; uint8 constant STATUS_NO_ELECTION_ROUND = 24; uint8 constant STATUS_INVALID_ELECTION_ID = 25;  comment — some value attached to error code. onTransfer(address source, uint128 amount) — function, which is called after successful transferStake to inform beneficiary. Arguments: source — address of Participant who made transfer;amount — funds that were transferred. onRoundComplete(uint64 roundId, uint64 reward, uint64 ordinaryStake, uint64 vestingStake, uint64 lockStake, bool reinvest, uint8 reason) — send a notification from DePool to Participant when round is completed: roundId — Id of completed round;reward — Participant's reward in completed round in nanotons;ordinaryStake — ordinary stake in completed round;vestingStake — vesting stake in completed round;lockStake — lock stake in completed round;reinvest — are ordinary stakes automatically reinvested (prolonged)?reason — reason why round is completed (See enum CompletionReason). "},{"title":"DePool owner functions:​","type":1,"pageTitle":"dePool specification","url":"/spec/depool-specification#depool-owner-functions","content":"These functions can be called only by the DePool owner, as they have to be signed with the deploy keypair. terminator() [external msg only] — a method to close DePool. All stakes from all rounds are returned in several phases: a. first of all, stakes from pooling round are returned immediately. b.m_poolClosed = true; c. All other rounds will return stakes after their &quot;completed&quot; step. Important: remaining parts of vesting/lock stakes will be sent to owners of those stakes (not to beneficiaries) setValidatorRewardFraction(uint8 fraction) [external msg only] Sets new validator's reward fraction and calculates new participants' reward fraction. New validator's reward fraction must be less than current one and be not zero. fraction — new validator's reward fraction. "},{"title":"Events​","type":1,"pageTitle":"dePool specification","url":"/spec/depool-specification#events","content":"DePoolClosed() — event emitted when pool is closed by terminator() function.RoundStakeIsAccepted(uint64 queryId, uint32 comment) — event is emitted on accepting stake by elector.RoundStakeIsRejected(uint64 queryId, uint32 comment) — event is emitted on rejecting stake by elector.ProxyHasRejectedTheStake(uint64 queryId) — event is emitted if stake is returned by proxy (IProxy.process_new_stake) because too low balance of proxy contract.ProxyHasRejectedRecoverRequest(uint64 roundId) — event is emitted if stake cannot be returned from elector (IProxy.recover_stake) because too low balance of proxy contract.RoundCompleted(TruncatedRound round) — event is emitted on completing round.StakeSigningRequested(uint32 electionId, address proxy) — Event emitted when round is switched from pooling to election. DePool is waiting for signed election request from validator wallet.TooLowDePoolBalance(uint replenishment) — event emitted when pure DePool's balance becomes too low. replenishment minimal value that must be sent to DePool via receiveFunds function.RewardFractionsChanged(uint8 validator, uint8 participants) — event emitted when contract owner changes reward fractions. validator — validator's reward fraction. participants — participants' reward fraction. "},{"title":"Get-methods​","type":1,"pageTitle":"dePool specification","url":"/spec/depool-specification#get-methods","content":"These get-methods are used for local run. getParticipantInfo(address addr) — returns participant's information about stakes in every rounds;getDePoolInfo() — returns DePool configuration parameters and constants;getParticipants() — return list of all participants;getRounds() — returns information about all rounds.getDePoolBalance() — returns DePool's own balance in nanotokens. The DePool does not store validator public keys or ADNL address, because, according to the official Everscale guide, the Validator generates a new keypair and ADNL for every elections. The contract stores only Validator wallet address. "},{"title":"State update function​","type":1,"pageTitle":"dePool specification","url":"/spec/depool-specification#state-update-function","content":"ticktock() — this function is the &quot;engine&quot; of DePool. This function rotates rounds: creates a new round if necessary and removes an old one. Switches steps of rounds and calls various internal functions if certain conditions are satisfied and so on. ticktock() — does not accept external inbound messages and can be called only from other contracts ticktock returns unspent message value (change) back to caller. "},{"title":"Multi-Round elections​","type":1,"pageTitle":"dePool specification","url":"/spec/depool-specification#multi-round-elections","content":" Every round goes through several steps: &quot;PrePooling&quot; step (RoundStep.PrePooling) — it's an imaginary round introduced to store half of vesting/lock stake from participants. See addVestingStake/addLockStake functions.&quot;Pooling&quot; step (RoundStep.Pooling) — round is ready to accept stakes from Participants. This round receives ordinary, vesting and lock stakes.&quot;waiting for election requests&quot; step (RoundStep.WaitingValidatorRequest) — round is switched to this step when validator elections begin. DePool is waiting for signed election request from validator wallet. See process_new_stake function of Elector to properly generate election request. Important: Validator wallet must also be a Participant and invest at least m_validatorAssurance stake in the round. If it doesn't, round is completed and stakes are reinvested in another round or are returned to participants. &quot;Waiting if stake is accepted by elector&quot; (RoundStep.WaitingIfStakeAccepted) — DePool has received the validator signed election request. DePool has sent the whole round stake to elector through one of its proxies. Now DePool is waiting for elector answer. Note: elector will call DePool's onStakeAccept function if election request is accepted successfully or onStakeReject in case of an error.&quot;waiting for validation start&quot; (RoundStep.WaitingValidationStart) — round stake was accepted by elector. Validator is a candidate. DePool now is waiting for the start of the validation to find out if validator won the elections.&quot;waiting for election result&quot; (RoundStep.WaitingIfValidatorWinElections) — DePool has tried to recover stake in validation period to find out if validator won elections. Waiting for elector answer. Note: If validator won the elections, elector returns no stake. If Validator lost the elections, elector returns the whole stake.&quot;waiting stake unfreeze&quot; (RoundStep.WaitingUnfreeze) — If CompletionReason != Undefined, the round is waiting round rotation to return/reinvest funds because elections were lost. Else validator won elections. DePool is waiting for ending of unfreeze period to recover funds from elector.&quot;waiting for a reward&quot; (RoundStep.WaitingReward) — Unfreeze period has been ended. Request to recover stake has been sent to elector. DePool is waiting for answer from elector.&quot;completing&quot; step (RoundStep.Completing) — DePool receives reward and replenishes its balance from it. Then it returns or reinvests participant's stakes. Also on this step DePool recounts vesting and lock stakes and modifies them if necessary.&quot;completed&quot; (RoundStep.Completed) — round switches to this step after processing all the Participants in the round. In next ticktock this round will be deleted. "},{"title":"Round completion​","type":1,"pageTitle":"dePool specification","url":"/spec/depool-specification#round-completion","content":"When a round switches to &quot;completing&quot; step (completeRound function), the DePool replenishes its balance from received rewards and then starts to cycle through all stakes in the round. If Participant's reinvestment flag is false, DePool sends it back to the Participant, otherwise — adds it to the pooling round. Also DePool sends notification message (onRoundComplete) to Participant. DePool goes through all vesting and lock stakes of the completing round and checks whether a withdrawal period has finished for the current stake. If it has, DePool modifies the stake via transferring part of it to Participants ordinary stake (in case of Vesting) and/or transferring part of the stake back to the owner (in case of Lock or in case of Vesting for validator which was slashed or lost elections over the course of the completed withdrawal period). Remark: if there are 15000 stakes in round, then the contract should split completion to 375 transactions sending 375 completePendingRound messages to itself. All these transactions can fit in 1-2 blocks and the whole operation will take about 5-20 seconds. "},{"title":"DePool decentralization​","type":1,"pageTitle":"dePool specification","url":"/spec/depool-specification#depool-decentralization","content":"No inherent way to replace the contract code (no SETCODE);No inherent way to transfer an arbitrary amount of currency from the DePool;Any contract can call the ticktock() function to update the state of the DePool;No one has special privileges, except for deployer of DePool who can only close DePool and start a procedure of returning all stakes back to Participants;Fees cannot be changed after the contract is deployed;Validator wallet must be a Participant as well to share risks with other Participants. "},{"title":"DePool contract fee​","type":1,"pageTitle":"dePool specification","url":"/spec/depool-specification#depool-contract-fee","content":"Caller of DePool's ticktock function must pay for consumed gas. Unused message value is returned back when ticktock is finished. At the beginning of completing step DePool first takes from the total reward an amount of tokens to replenish it's balance to m_balanceThreshold, and then additionally RET_OR_REINV_FEE * (N + 1), where N is the number of participants, to cover the costs of stake processing. "},{"title":"Links​","type":1,"pageTitle":"dePool specification","url":"/spec/depool-specification#links","content":"DePool contract is available on github. DePool deployment instructions can be found here. "},{"title":"COPYLEFT (TIP-1.1)","type":0,"sectionRef":"#","url":"/standard/TIP-1.1","content":"","keywords":""},{"title":"Introduction​","type":1,"pageTitle":"COPYLEFT (TIP-1.1)","url":"/standard/TIP-1.1#introduction","content":"Many members of our community have asked questions about Everscale code philosophy. Why we call it Free Software? What is a relationship between Everscale and Free Software? What is the difference between Free Software and Open Source? I have decided to combine this with an idea I have regarding gas payment redistribution in TON. You will see below why it is related. The concept of Free Software predates open source. Richard Stallman has started the free-software movement in 1983 with a launch of GNU Project while open-source movement has been derived from Free Software only in 1998. To clarify, the Free Software is not in conflict with Open Source. As explained below it follows all the same principles and the differences seems more ideological. Yet TON project did not have any problem with open-source nature of it software. It is all open sourced. The problem was exactly about the Freedom of people to use it. That is why Everscale is heavily influenced by Free Software movement. Declaration of Decentralisation is, in many ways, inspired by Stallman’s «The GNU Manifesto»1. In «Why Open Source misses the point of Free Software» Stallman writes among other things: «The terms «free software» and «open source» stand for almost the same range of programs. However, they say different things about those programs, based on different values. The free software movement campaigns for freedom for the users of computing; it is a movement for freedom and justice. By contrast, the open source idea values mainly practical advantage and does not campaign for principles. This is why we do not agree with open source, and do not use that term»2. It seems Everscale is in agreement with this line of thought. While all our software is open source it is the Freedom to run the software what has launched this network. Now let’s talk about Copyright and Licensing as they relate to the Free Software in general and Blockchain in particular. Before we start I need to say that blockchain may potentially provide a solution to some of the free software inherited business model problems. We all remember that free in the free software stands for freedom and not for zero price. The ability to get paid for a software should not be based on restrictions imposed by its license. But what it should be based upon then? There are several business models for free software non of which really works. What works is a business model that is not exactly related to the software itself and therefore can not be attributed to it. Such as charging for support or for portions of the software which are closed source. It all seems quite unnatural. It also prevents one of the major points of free software — an open collaboration of the community around software projects. Donald Fischer article title «Open source creators: Red Hat got $34 billion and you got $0. Here’s why»3 is self explanatory. IBM has bought a commercial company that was built on top of many developers’ contribution to its code. Those developers never got any part out of the value they have created. "},{"title":"Aligning the incentives​","type":1,"pageTitle":"COPYLEFT (TIP-1.1)","url":"/standard/TIP-1.1#aligning-the-incentives","content":"Many free and open source software projects struggle to introduce a sustainable business model. This is one of the reasons why most of the open source software contributors work for large corporations. When a venture capital provides funding to a software project it expects multiple return on its capital. With commercial software it is quite straight forward — a company is charging money for its software use and if successful passes profits to its stakeholders. With free software its quite difficult. That is why there are very few (or should we say: not enough) commercially successful open source software companies. Blockchain introduces a unique opportunity for Free Software developers to align their commercial interests with those of users for the benefit of the whole ecosystem. As an Internet of Value protocol, Blockchain has built-in network incentive mechanism — network fees (or gas). To remind: Miners in Proof-Of-Work collect miner rewards and network fees to compensate them for resources spent to secure the network and process transactions. Both security computations and transaction processing are separate resources, thus requiring separate fees. In Proof-Of-Stake Validators commit funds and processing power to secure the network and process transactions (in a form of smart contract execution in TON). For this they also get separate rewards: block rewards in a form of token emission and transaction reward in a form of a fee. Please note, rewards are separated in both cases. We propose to extend the reward model to transaction facilitators. It would be logical to pay part of the fees to the smart contract developer who is initiating the transaction which pays the fee. This will attract both Developers and Users which will increase network usage and total transaction fees for all network participants. "},{"title":"On-chain licensing fees​","type":1,"pageTitle":"COPYLEFT (TIP-1.1)","url":"/standard/TIP-1.1#on-chain-licensing-fees","content":"Somewhat naive mechanism but with the same underlying idea is proposed by Near blockchain. «The developerReward are allocated by per block per account, as they can be efficiently done every time the transaction or receipts is being processed by the contract»4. The problem with this approach lays in the fact that network fees not only pays for resources but also provide an important anti spam mechanism. One can use the developer kick-back to simply lower an attack costs. To mitigate that risk we propose a use of a special Payout Contract. This contract is going to pay the collected Copyleft fees to developers only after certain threshold in both amount of fees and time frame are surpassed. In this respect the Developer motivation is again aligned with the Network security model — it is not practical to break the network where one receives a long term rent. "},{"title":"Some technical details​","type":1,"pageTitle":"COPYLEFT (TIP-1.1)","url":"/standard/TIP-1.1#some-technical-details","content":"Technically we introduce a TVM Opcode FB0A. Contract may include that code together with a License information and address of its developer. Collator will include a reward related to gas fees from these transactions into the block for the address indicated in the TVM instruction in the amount corresponding to the indicated License. The percentage of gas fees depends on the license type such as that the most free software compatible license provides more gas. FB0A - COPYLEFT (n x y - ), looks up for the license rule for ‘n’ in ConfigParam (for example 42) and creates output action to send part of the tokens it collected from gas fees to Payout contract indicated in ConfigParam for address x:y, where x - is 32 bit signed integer for workchain and y is 256 bit unsigned integer for contract address in this workchain. It will not throw any exceptions if n or the address are incorrect. Generally allowed licenses are those supported by Free Software Foundation as described here: https://www.gnu.org/licenses/license-list.html#SoftwareLicenses 2 License types payout GPL-Compatible Free Software Licenses 2 → 30% fees GPL-Incompatible Free Software Licenses → 20% fees To implement we add network config parameter: license fees threshold value Collator check threshold each time the instruction is executed. After threshold is reached collator sends value to Developer Account defined in contract instruction FB0A TVM creates special out action with Developer Account (last call of FB0A matters) If account is been deleted, the executor sends value to Developer Account or to ValueFlow if it is not enough (this case must be checked in Validator) Executor analyzes special out action and counts value then sends message to developer account (payment for transaction gets from value) We add fields to json objects and QServer for SDK Collator and Validator must check fees from ValueFlow with Developer correction "},{"title":"Copyright discussion​","type":1,"pageTitle":"COPYLEFT (TIP-1.1)","url":"/standard/TIP-1.1#copyright-discussion","content":"«What is the proper way to decide copyright policy? If copyright is a bargain made on behalf of the public, it should serve the public interest above all. The government’s duty when selling the public’s freedom is to sell only what it must, and sell it as dearly as possible. At the very least, we should pare back the extent of copyright as much as possible while maintaining a comparable level of publication»5. One important dimension of copyright is its durationAnother dimension of copyright policy is the extent of fair use: some ways of reproducing all or part of a published work that are legally permitted even though it is copyrighted. (c) Richard Stallman Both duration and fair use of copyright is balanced in this proposal by virtue of compensating copyright holder by Payout Contract creating an ongoing reward from the network while at the same time not preventing a forking possibility by other developers who then need to improve the software in a way that will bring new users and create new intensive for the new contributor. So both improvements as well as long term rent (subscription) is provided for developers. The Copyleft spirit is fully supported here as the Fee is collected for developers who facilitates the fees creation in the first place. The freedom to fork is fully executed as well as anyone can fork the code of a smart contract. In the end it is the community of users who chooses which contract to use and the decision is usually based upon the reputation of the code represented by the hash of the code where is no single byte has been changed. Therefore the system is merit-based. Both long term developer’s incentives for original developers and forking is provided. To recap the proposed system is compatible with all four essential freedoms: The freedom to run the program as you wish, for any purpose (freedom 0).The freedom to study how the program works, and change it so it does your computing as you wish (freedom 1). Access to the source code is a precondition for this.The freedom to redistribute copies so you can help others (freedom 2).The freedom to distribute copies of your modified versions to others (freedom 3). By doing this you can give the whole community a chance to benefit from your changes. Access to the source code is a precondition for this. "},{"title":"References​","type":1,"pageTitle":"COPYLEFT (TIP-1.1)","url":"/standard/TIP-1.1#references","content":"The GNU Manifesto↩Why Open Source Misses the Point of Free Software↩Open source creators: Red Hat got $34 billion and you got $0. Here's why↩Economics in a Sharded Blockchain — Section 06 — Developer Business Models↩Misinterpreting Copyright — A Series of Errors↩ "},{"title":"MYCODE (TIP-1.2)","type":0,"sectionRef":"#","url":"/standard/TIP-1.2","content":"MYCODE (TIP-1.2) F82A — MYCODE (- s) — returns the Cell with the current code of the smartcontract. Equivalent to GETPARAM 10. Smartcontract has own code which cell representation can be obtained by this instruction.","keywords":""},{"title":"Fungible Token","type":0,"sectionRef":"#","url":"/standard/TIP-3","content":"","keywords":""},{"title":"Abstract​","type":1,"pageTitle":"Fungible Token","url":"/standard/TIP-3#abstract","content":"The following standard describes the basic idea about distributed fungible token architecture. "},{"title":"Motivation​","type":1,"pageTitle":"Fungible Token","url":"/standard/TIP-3#motivation","content":"The suggested standard differs considerably from Ethereum ERC20 and other smart contract token standards with single registry due to its distributed nature related to Everscale blockchain particularities. Given that Everscale has a storage fee, using an existing ERC20 standard design would cause excessive maintenance costs. Also, ERC20 is somewhat incompatible with the sharding architecture. Therefore, a Distributed Token standard is preferable. The ERC20 sharding implementation (with an idea to simply shard its registry) has drawbacks mainly related to complicated and expansive management. TIP-3 is fully distributed and implies separate storage of each user’s balance. "},{"title":"Architecture​","type":1,"pageTitle":"Fungible Token","url":"/standard/TIP-3#architecture","content":"General information about token is stored in the token root contract. Each token holder has its own instance of token wallet contract. Token transfers SHOULD be implemented in P2P fashion, between sender and receiver token wallets. "},{"title":"Token root​","type":1,"pageTitle":"Fungible Token","url":"/standard/TIP-3#token-root","content":"Token root contract stores the general information about the token, e.g. name, symbol, decimals, token wallet code and so on. "},{"title":"Token wallet​","type":1,"pageTitle":"Fungible Token","url":"/standard/TIP-3#token-wallet","content":"Each token holder has its own instance of token wallet contract. Transfer happens in a decentralized fashion - sender token wallet SHOULD send the specific message to the receiver token wallet. Since token wallets have the same code, it's easy for receiver token wallet to check the correctness of sender token wallet. "},{"title":"References​","type":1,"pageTitle":"Fungible Token","url":"/standard/TIP-3#references","content":"EIP-20: Token StandardEverscale Forum - TIP3Reference implementation by Broxus "},{"title":"Fungible Token Interface (TIP-3.1)","type":0,"sectionRef":"#","url":"/standard/TIP-3.1","content":"","keywords":""},{"title":"Abstract​","type":1,"pageTitle":"Fungible Token Interface (TIP-3.1)","url":"/standard/TIP-3.1#abstract","content":"The following standard allows for the implementation of a standard API for tokens within smart contracts. General information about token is stored in the token root contract. Each token holder has its own instance of token wallet contract. Token transfers SHOULD be implemented in P2P fashion, between sender and receiver token wallets. "},{"title":"Motivation​","type":1,"pageTitle":"Fungible Token Interface (TIP-3.1)","url":"/standard/TIP-3.1#motivation","content":"A standard interface allows any tokens on Everscale to be re-used by other applications: from wallets to decentralized exchanges. "},{"title":"Specification​","type":1,"pageTitle":"Fungible Token Interface (TIP-3.1)","url":"/standard/TIP-3.1#specification","content":"The keywords “MUST”, “MUST NOT”, “REQUIRED”, “SHALL”, “SHALL NOT”, “SHOULD”, “SHOULD NOT”, “RECOMMENDED”, “MAY”, and “OPTIONAL” in this document are to be interpreted as described in RFC 2119. "},{"title":"Notes​","type":1,"pageTitle":"Fungible Token Interface (TIP-3.1)","url":"/standard/TIP-3.1#notes","content":"We choose Standard Interface Detection to expose the interfaces that a TIP3 smart contract supports.This standard does not define the external methods to initiate transfer, mint or burn tokens. Though it defines the methods, which MUST be called on a recipient token wallet or token root during these operations.The rules for a token wallet ownership MUST be defined in a child standards.A -1 offset is added to some function IDs derivations, so the preimage of the hash cannot be known, further reducing the chances of a possible collisions. "},{"title":"Token root​","type":1,"pageTitle":"Fungible Token Interface (TIP-3.1)","url":"/standard/TIP-3.1#token-root","content":"Name​ Returns the name of the token - e.g. &quot;MyToken&quot;. function name() public view responsible returns (string);  Symbol​ Returns the symbol of the token. E.g. “HIX”. function symbol() public view responsible returns (string);  Decimals​ Returns the number of decimals the token uses - e.g. 8, means to divide the token amount by 100000000 to get its user representation. function decimals() public view responsible returns (uint8);  Total supply​ Returns the total token supply. function totalSupply() public view responsible returns (uint128);  Token wallet code​ Returns the token wallet code. function walletCode() public view responsible returns (TvmCell);  Accept tokens burn​ Does not have a standard signature, but has a standard function ID 0x192B51B1 obtained as tvm.functionId('acceptBurn(uint128)') - 1. The uint128 _value parameter MUST be first. The function name and the rest of the parameters are not fixed by this standard and can be reinvented for each substandard. Decreases token total supply by _value. The contract MUST check that the sender is a correct token wallet. Before sending this message, caller token wallet MUST decrease its own balance by _value. If the mint can't be accepted (e.g. invalid sender), this message MUST be bounced. Any function from the following snippet is a valid example: interface TIP3AcceptBurn { function acceptBurn(uint128 _value) functionID(0x192B51B1) public; function acceptBurn2(uint128 _value, uint256 _publicKey, address _owner) functionID(0x192B51B1) public; function acceptBurn3(uint128 _value, TvmCell _meta) functionID(0x192B51B1) public; }  Standard interface detection​ interface TIP3TokenRoot { function acceptBurn(uint128 _value) functionID(0x192B51B1) public view responsible; function name() public view responsible returns (string); function symbol() public view responsible returns (string); function decimals() public view responsible returns (uint8); function totalSupply() public view responsible returns (uint128); function walletCode() public view responsible returns (TvmCell); }  The token root interface ID is 0x4371D8ED. "},{"title":"Token wallet​","type":1,"pageTitle":"Fungible Token Interface (TIP-3.1)","url":"/standard/TIP-3.1#token-wallet","content":"Root​ Returns the token root address. function root() public view responsible returns (address);  Balance​ Returns the token wallet balance. function balance() public view responsible returns (uint128);  Wallet code​ Returns the token wallet code. function walletCode() public view responsible returns (TvmCell);  Accept tokens transfer​ Does not have a standard signature, but has a standard function ID 0x67A0B95F obtained as tvm.functionId('acceptTransfer(uint128)') - 1. The uint128 _value parameter MUST be first. The function name and the rest of the parameters are not fixed by this standard and can be reinvented for each substandard. Increases token wallet balance by _value. The contract MUST check that the sender is a correct token wallet. Before sending this message, caller token wallet MUST decrease its own balance by _value. If the transfer can't be accepted (e.g. invalid sender), this message MUST be bounced. Any function from the following snippet is a valid example: interface TIP3AcceptTransfer { function acceptTransfer(uint128 _value) functionID(0x67A0B95F) external; function acceptTransfer2(uint128 _value, uint256 _publicKey, address _owner) functionID(0x67A0B95F) external; function acceptTransfer3(uint128 _value, TvmCell _meta) functionID(0x67A0B95F) external; }  Accept tokens mint​ Does not have a standard signature, but has a standard function ID 0x4384F298 obtained as tvm.functionId('acceptMint(uint128)') - 1. The uint128 _value parameter MUST be first. The function name and the rest of the parameters are not fixed by this standard and can be reinvented for each substandard. Increases token wallet balance by _value. The contract MUST check that the sender is a correct token root. Before sending this message, token root MUST increase the total supply by _value. If the mint can't be accepted (e.g. invalid sender), this message MUST be bounced. Any function from the following snippet is a valid example: interface TIP3AcceptMint { function acceptMint(uint128 _value) functionID(0x4384F298) external; function acceptMint2(uint128 _value, uint256 _publicKey, address _owner) functionID(0x4384F298) external; function acceptMint3(uint128 _value, TvmCell _meta) functionID(0x4384F298) external; }  On-bounce behaviour​ The acceptTransfer or acceptBurn methods can be bounced, e.g. receiver token wallet has a different code or burning disabled. The token wallet behaviour in these cases should be implemented according to the following rules. Handle acceptTransfer bounce​ Increases token wallet balance according to the value, specified in the bounce body. Handle acceptBurn bounce​ Increases token wallet balance according to the value, specified in the bounce body. Standard interface detection​ interface TIP3TokenWallet { function acceptTransfer(uint128 _value) functionID(0x67A0B95F) external; function acceptMint(uint128 _value) functionID(0x4384F298) external; function root() public view responsible returns (address); function balance() public view responsible returns (uint128); function walletCode() public view responsible returns (TvmCell); }  The token wallet interface ID is 0x4F479FA3. "},{"title":"Non-Fungible Token","type":0,"sectionRef":"#","url":"/standard/TIP-4","content":"","keywords":""},{"title":"Abstract​","type":1,"pageTitle":"Non-Fungible Token","url":"/standard/TIP-4#abstract","content":"The following standard describes the basic idea of distributed non-fungible token architecture. "},{"title":"Motivation​","type":1,"pageTitle":"Non-Fungible Token","url":"/standard/TIP-4#motivation","content":"The suggested standard differs considerably from Ethereum ERC721 and other smart contract token standards with single registry because of its distributed nature related to Everscale blockchain particularities. Given that Everscale has a storage fee, TIP4 is fully distributed and implies separate storage of each NFT. "},{"title":"Architecture​","type":1,"pageTitle":"Non-Fungible Token","url":"/standard/TIP-4#architecture","content":"General information about NFT collection is stored in the NFT collection contract. Each NFT deployed in separate smart contracts and links to NFT collection contract Smart contract architecture based on: Consider asynchronous type of Everscale blockchain. Use callbacks and asynchronous getters;Standardizes one NFT - one smart contract. Gas fee management practicals. Use TIP-6.1 "},{"title":"(Status:Review) Non-Fungible Token (TIP-4.1)​","type":1,"pageTitle":"Non-Fungible Token","url":"/standard/TIP-4#statusreview-non-fungible-token-tip-41","content":"General information about NFT collection and NFT tokens. All NFT must implement TIP-4.1 "},{"title":"(Status:Review) Non-Fungible Token JSON Metadata (TIP-4.2)​","type":1,"pageTitle":"Non-Fungible Token","url":"/standard/TIP-4#statusreview-non-fungible-token-json-metadata-tip-42","content":"General information about NFT metadata. TIP-4.2 is optional, but can be used for displaying NFT on marketplaces, wallets and web. "},{"title":"(Status:Review) On-chain indexes (TIP-4.3)​","type":1,"pageTitle":"Non-Fungible Token","url":"/standard/TIP-4#statusreview-on-chain-indexes-tip-43","content":"On-chain Indexes solves easy and fast searching any data in blockchain. TIP-4.3 is optional, but can be use for find all your NFT with one dApp query. "},{"title":"(Status:Draft) On-chain storage (TIP-4.4)​","type":1,"pageTitle":"Non-Fungible Token","url":"/standard/TIP-4#statusdraft-on-chain-storage-tip-44","content":"Using the Storage contract, you can store NFT-related bytes in blockchain. TIP-4.4 is optional, but can be used for fault tolerance. If off-chain services are unavailable, the user will view NFT-related bytes, because it is stored on-chain. "},{"title":"(Status:Draft) Don't Be Evil NFT licensing (TIP-4.5)​","type":1,"pageTitle":"Non-Fungible Token","url":"/standard/TIP-4#statusdraft-dont-be-evil-nft-licensing-tip-45","content":"The standard adds the support of Can't Be Evil NFT licenses introduced by Andreessen.Horowitz. TIP-4.5 is optional, but can be used for clarifying the legal basis of NFT usage by the owner. "},{"title":"Authors​","type":1,"pageTitle":"Non-Fungible Token","url":"/standard/TIP-4#authors","content":"Author\tCommandAleksand Aleksev\tgrandbazar.io Aleksandr Khramtsov\tbroxus Vladislav Ponomarev\tbroxus Andrey Nedobylskiy\tsvoi.dev Anton Platonov\tcommunity member Nikita\tnumiz.org Oleg Varnov\tnumiz.org Slava Semenchuk\tscalepunks.com "},{"title":"Implementation​","type":1,"pageTitle":"Non-Fungible Token","url":"/standard/TIP-4#implementation","content":"itgold implementation MIT licensed.A library of modular, reusable smart contracts.Samples and tests here "},{"title":"References​","type":1,"pageTitle":"Non-Fungible Token","url":"/standard/TIP-4#references","content":"Ethereum EIP-721Solana v1.2.0TON NFT, TON DATATezos TZIP12 "},{"title":"Internally-owned fungible Token Interface (TIP-3.2)","type":0,"sectionRef":"#","url":"/standard/TIP-3.2","content":"","keywords":""},{"title":"Abstract​","type":1,"pageTitle":"Internally-owned fungible Token Interface (TIP-3.2)","url":"/standard/TIP-3.2#abstract","content":"The following standard describes token, where token wallets are owned internally by any Everscale contract (e.g. multisignature wallet). Any operation, such as burn or transfer, can be initiated with the internal message from the owner contract. "},{"title":"Motivation​","type":1,"pageTitle":"Internally-owned fungible Token Interface (TIP-3.2)","url":"/standard/TIP-3.2#motivation","content":"The TIP-3.1 standard describes the key architecture principles and some common methods for token contracts in the Everscale network. While it does not answer the following questions: How to create token walletHow token wallets are ownedHow to transfer, mint or burn tokensHow the tokens recipient can handle the incoming transfer, etc "},{"title":"Specification​","type":1,"pageTitle":"Internally-owned fungible Token Interface (TIP-3.2)","url":"/standard/TIP-3.2#specification","content":"The keywords “MUST”, “MUST NOT”, “REQUIRED”, “SHALL”, “SHALL NOT”, “SHOULD”, “SHOULD NOT”, “RECOMMENDED”, “MAY”, and “OPTIONAL” in this document are to be interpreted as described in RFC 2119. "},{"title":"Notes​","type":1,"pageTitle":"Internally-owned fungible Token Interface (TIP-3.2)","url":"/standard/TIP-3.2#notes","content":"Zero address is 0:0000000000000000000000000000000000000000000000000000000000000000 "},{"title":"Token root​","type":1,"pageTitle":"Internally-owned fungible Token Interface (TIP-3.2)","url":"/standard/TIP-3.2#token-root","content":"Token wallet address​ Returns token wallet address, owned by owner. MUST NOT deploy token wallet. function walletOf(address owner) external view responsible returns (address);  Deploy token wallet​ Deploys token wallet, owned by owner. Returns token wallet address. function deployWallet( address owner, uint128 deployWalletValue ) external responsible returns (address);  Mint tokens​ Mints amount amount of tokens to the token wallet, owned by recipient. If deployWalletValue is greater than 0, token root MUST deploy token wallet for recipient. Otherwise, it mints tokens without deploying token wallet, which may lead to failed minting. Calls the acceptMint method on the recipient token wallet. If notify is true, than the onAcceptTokensMint callback message will be sent to the recipient. function mint( uint128 amount, address recipient, uint128 deployWalletValue, address remainingGasTo, bool notify, TvmCell payload ) external;  Accept burn​ Accepts burning amount amount of tokens from the token wallet, owned by walletOwner. If callbackTo is zero address, than all the remaining gas is transferred to the remainingGasTo. Otherwise, message with onAcceptTokensBurn callback is sent to the callbackTo address. Decreases the totalSupply by amount. function acceptBurn( uint128 amount, address walletOwner, address remainingGasTo, address callbackTo, TvmCell payload ) external functionID(0x192B51B1);  Callbacks​ Burn callback​ Notifies the contract that the burn was accepted. MUST BE called from the token root. function onAcceptTokensBurn( uint128 amount, address walletOwner, address wallet, address remainingGasTo, TvmCell payload ) external;  "},{"title":"Token wallet​","type":1,"pageTitle":"Internally-owned fungible Token Interface (TIP-3.2)","url":"/standard/TIP-3.2#token-wallet","content":"Owner​ Returns the owner of the token wallet. function owner() external view responsible returns (address);  Balance​ Returns the token balance of the token wallet. function balance() external view responsible returns (uint128);  Transfer tokens to the recipient​ Transfers amount amount of tokens to the token wallet, owned by recipient. Token wallet address is derived automatically. If deployWalletValue is greater than 0, token wallet MUST deploy token wallet for recipient. Calls the acceptTransfer on the recipient token wallet. If notify is true, than the onAcceptTokensTransfer callback message will be sent to the recipient. function transfer( uint128 amount, address recipient, uint128 deployWalletValue, address remainingGasTo, bool notify, TvmCell payload ) external;  Transfer tokens to the token wallet​ Transfers amount amount of tokens to the recipientTokenWallet. Calls the acceptTransfer on the recipientTokenWallet. Decreases the token wallet balance by amount. function transferToWallet( uint128 amount, address recipientTokenWallet, address remainingGasTo, bool notify, TvmCell payload ) external;  Burn tokens by token wallet owner​ Decreases the token wallet balance by amount. function burn( uint128 amount, address remainingGasTo, address callbackTo, TvmCell payload ) external;  Burn token by token root​ Decreases the token wallet balance by amount. function burnByRoot( uint128 amount, address remainingGasTo, address callbackTo, TvmCell payload ) external;  Accept mint​ Accepts incoming mint for amount amount of tokens. MUST be reverted if msg.sender is not root. Increases the token wallet balance by amount. function acceptMint( uint128 amount, address remainingGasTo, bool notify, TvmCell payload ) external functionID(0x4384F298);  Accept transfer​ Accepts incoming transfer for amount amount of tokens from token wallet, owned sender. If notify is false, than the remaining gas MUST be sent to the remainingGasTo. Otherwise, the onAcceptTokensTransfer callback MUST be sent to the token wallet owner with the same remainingGasTo and payload. Increases the token wallet balance by amount. function acceptTransfer( uint128 amount, address sender, address remainingGasTo, bool notify, TvmCell payload ) external functionID(0x67A0B95F);  Callbacks​ Incoming transfer callback​ Notifies token wallet's owner that an incoming transfer was accepted. function onAcceptTokensTransfer( address tokenRoot, uint128 amount, address sender, address senderWallet, address remainingGasTo, TvmCell payload ) external;  Mint callback​ Notifies token wallet's owner that mint was accepted. function onAcceptTokensMint( address tokenRoot, uint128 amount, address remainingGasTo, TvmCell payload ) external;  Bounced transfer callback​ Notifies token wallet's owner that token transfer was bounced. function onBounceTokensTransfer( address tokenRoot, uint128 amount, address revertedFrom ) external;  Bounced burn callback​ Notifies token wallet's owner that burn was bounced. function onBounceTokensBurn( address tokenRoot, uint128 amount ) external;  "},{"title":"Implementation​","type":1,"pageTitle":"Internally-owned fungible Token Interface (TIP-3.2)","url":"/standard/TIP-3.2#implementation","content":"TIP-3.2 implementation by Broxus. Upgradable version is also available. "},{"title":"Non-Fungible Token JSON Metadata (TIP-4.2)","type":0,"sectionRef":"#","url":"/standard/TIP-4.2","content":"","keywords":""},{"title":"Abstract​","type":1,"pageTitle":"Non-Fungible Token JSON Metadata (TIP-4.2)","url":"/standard/TIP-4.2#abstract","content":"Token-specific metadata is stored as a string in smart contract. To facilitate an off-chain working with metadata, it is JSON object. The below metadata structure allows the marketplaces to read and display the details about the assets which your NFTs represent. This standard provides optional JSON fields and contract interface. "},{"title":"Motivation​","type":1,"pageTitle":"Non-Fungible Token JSON Metadata (TIP-4.2)","url":"/standard/TIP-4.2#motivation","content":"A standard fields facilitate displaying of NFT data for: wallets, explorers, marketplaces, etc. "},{"title":"Specification​","type":1,"pageTitle":"Non-Fungible Token JSON Metadata (TIP-4.2)","url":"/standard/TIP-4.2#specification","content":"The keywords “MUST”, “MUST NOT”, “REQUIRED”, “SHALL”, “SHALL NOT”, “SHOULD”, “SHOULD NOT”, “RECOMMENDED”, “MAY”, and “OPTIONAL” in this document are to be interpreted as described in RFC 2119 "},{"title":"JSON metadata​","type":1,"pageTitle":"Non-Fungible Token JSON Metadata (TIP-4.2)","url":"/standard/TIP-4.2#json-metadata","content":"Return the metadata as JSON Every TIP4.2 compliant contract must implement the TIP4_2JSON_Metadata interface and TIP-6.1 interfaces pragma ton-solidity &gt;= 0.58.0; interface TIP4_2JSON_Metadata { /// @notice metadata in JSON format /// @return json The JSON string with metadata function getJson() external view responsible returns (string json); }  NOTE The TIP-6.1 identifier for this interface is 0x24D7D5F5. "},{"title":"TIP4_2JSON_Metadata.getJson()​","type":1,"pageTitle":"Non-Fungible Token JSON Metadata (TIP-4.2)","url":"/standard/TIP-4.2#tip4_2json_metadatagetjson","content":"function getJson() external view responsible returns (string json);  json (string) - The JSON string with metadata The function return metadata as a JSON string. "},{"title":"Empty JSON metadata​","type":1,"pageTitle":"Non-Fungible Token JSON Metadata (TIP-4.2)","url":"/standard/TIP-4.2#empty-json-metadata","content":"Empty JSON metadata is represented as a blank JSON object or an empty string. {}  "},{"title":"JSON metadata type​","type":1,"pageTitle":"Non-Fungible Token JSON Metadata (TIP-4.2)","url":"/standard/TIP-4.2#json-metadata-type","content":"Not empty JSON must have &quot;type&quot; field {&quot;type&quot;:&quot;string&quot;}  Application that read JSON metadata use &quot;type&quot; field for parsing standard or custom JSON fields. "},{"title":"JSON metadata type: \"Basic NFT\"​","type":1,"pageTitle":"Non-Fungible Token JSON Metadata (TIP-4.2)","url":"/standard/TIP-4.2#json-metadata-type-basic-nft","content":"The Basic NFT use for links to files stores in web. JSON fields contain information about item, files and preview info. The Basic NFT describes fields that must be in JSON Field name\ttype\tValue\tDescriptiontype\tstring\t&quot;Basic NFT&quot;\tConstant name for this type name\tstring Name of the object description\tstring Description of the object preview\tobject Object preview preview.source\tstring Link to object. Contains protocol and data source. Delimiter is : preview.mimetype\tstring Mime type of object files\tarray Array of objects. file.source\tstring Link to object. Contains protocol and data source. Delimiter is : file.mimetype\tstring Mime type of object external_url\tstring URL to website "},{"title":"Example​","type":1,"pageTitle":"Non-Fungible Token JSON Metadata (TIP-4.2)","url":"/standard/TIP-4.2#example","content":"{ &quot;type&quot;: &quot;Basic NFT&quot;, &quot;name&quot;: &quot;Sample Name&quot;, &quot;description&quot;: &quot;Hello world!&quot;, &quot;preview&quot;: { &quot;source&quot;: &quot;https://everscale.network/images/Backgrounds/Main/main-hero.png&quot;, &quot;mimetype&quot;: &quot;image/png&quot; }, &quot;files&quot;: [ { &quot;source&quot;: &quot;https://everscale.network/images/Backgrounds/Main/main-hero.png&quot;, &quot;mimetype&quot;: &quot;image/png&quot; } ], &quot;external_url&quot;: &quot;https://everscale.network&quot; }  You can extend Basic NFT type for your custom fields. "},{"title":"JSON metadata type: metaverse.region​","type":1,"pageTitle":"Non-Fungible Token JSON Metadata (TIP-4.2)","url":"/standard/TIP-4.2#json-metadata-type-metaverseregion","content":"The metaverse.region JSON object stores the unique reference to a specific region (bundle of regions) inside a metaverse. Field name\tType\tDescription\tValuetype\tstring\tNFT type\tmetaverse.region version\tstring\tModel version (for future compatibility)\t1.0 meta\tobject\tRegion metadata regions\tarray&lt;object&gt;\tRegion parameters (multi-component regions allowed)\t Example { &quot;type&quot;: &quot;metaverse.region&quot;, &quot;version&quot;: &quot;1.0&quot;, &quot;meta&quot;: { &quot;server&quot;: { &quot;type&quot;: &quot;minecraft&quot;, &quot;url&quot;: &quot;http://10.10.10.10:25565&quot;, &quot;pubkey&quot;: &quot;c843d424bba89625d64fb592975180023e46b499388856fa832e287484adc4aa&quot; }, &quot;signature&quot;: &quot;cc9d3377f78d33a3d2d412d173f2b6e9e6dd06af19749d95032ea7c78eb07d873ddfe0b241a190900422732207dbbdc987b1bbcfd74d56404f0ab0d65d4f930e&quot; }, &quot;regions&quot;: [ { &quot;shape&quot;: &quot;cuboid&quot;, &quot;params&quot;: { &quot;position1&quot;: { &quot;x&quot;: &quot;0&quot;, &quot;y&quot;: &quot;-50&quot;, &quot;z&quot;: &quot;0&quot; }, &quot;position2&quot;: { &quot;x&quot;: &quot;16&quot;, &quot;y&quot;: &quot;200&quot;, &quot;z&quot;: &quot;16&quot; } } } ] }  "},{"title":"Region metadata​","type":1,"pageTitle":"Non-Fungible Token JSON Metadata (TIP-4.2)","url":"/standard/TIP-4.2#region-metadata","content":"This section must contain at least a minimum of the required information about the metaverse server where the region is located. Field name\tType\tDescription\tExample valueserver.type\tstring\tType of metaverse that has issued the NFT token\tminecraft server.url\turi (optional)\tAddress where the server is located. Typically, the URL, from which the server actual metadata like name, description, etc. can be extracted.\t10.10.10.10:25565 server.pubkey\tstring\tPublic key issued by the compatible NFT adapter used to sign the NFT content data signature\tstring\tHEX representation of the signature, generated using ed25519 algorithm based on the contents of regions array content (without the object name) and server private key. Before generation, the base JSON array must be compacted (i.e. all the whitespace and line breaks must be removed). In the example above, it will look as follows: [{&quot;shape&quot;:&quot;cuboid&quot;,&quot;params&quot;:{&quot;position1&quot;:{&quot;x&quot;:&quot;0&quot;,&quot;y&quot;:&quot;-50&quot;,&quot;z&quot;:&quot;0&quot;},&quot;position2&quot;:{&quot;x&quot;:&quot;16&quot;,&quot;y&quot;:&quot;200&quot;,&quot;z&quot;:&quot;16&quot;}}}]\t "},{"title":"Region shape types​","type":1,"pageTitle":"Non-Fungible Token JSON Metadata (TIP-4.2)","url":"/standard/TIP-4.2#region-shape-types","content":"The reference implementation is inspired by Minecraft's Worldedit primitive region models. Type\tDescription\tReference modelcuboid\tBox-shaped region\tLink cylinder\tCylinder-shaped region\tLink sphere\tSpheric-shaped region\tLink polygon2d\t2D-polygonal-shaped region\tLink Cuboid​ Cuboid is the simplest and the most popular shape of a region typically used in most metaverses. It is defined by X, Y and Z coordinates of two points in the space (the order is insignificant), one of which is considered as the start (bottom, minimum) and the other one as the end (top, maximum) of the region. Cuboid object specification​ Field name\tType\tDescription\tValueshape\tstring\tType of shape\tcuboid params.position1\txyz\tFirst vertex of the cuboid params.position2\txyz\tSecond vertex of the cuboid\t Example usage​ { &quot;type&quot;: &quot;metaverse.region&quot;, &quot;version&quot;: &quot;1.0&quot;, &quot;meta&quot;: {}, &quot;regions&quot;: [ { &quot;shape&quot;: &quot;cuboid&quot;, &quot;params&quot;: { &quot;position1&quot;: { &quot;x&quot;: &quot;0&quot;, &quot;y&quot;: &quot;-50&quot;, &quot;z&quot;: &quot;0&quot; }, &quot;position2&quot;: { &quot;x&quot;: &quot;16&quot;, &quot;y&quot;: &quot;200&quot;, &quot;z&quot;: &quot;16&quot; } } } ] }  Cylinder​ Cylinders are commonly used in central areas of large objects (lize plazas, fountains, etc). They are defined by coordinates of basic central point, radius, and height. Cylinder object specification​ Field name\tType\tDescription\tValueshape\tstring\tType of shape\tcylinder params.center\txyz\tBasic central point of the cylinder params.radius\tstring\tRadius of the cylinder (number in string format for maximum compatibility) params.height\tstring\tHeight of the cylinder (number in string format for maximum compatibility) For the avoidance of doubt, the Y coordinate of the opposite cylinder's side is calculated as Y_basic + height\t Example usage​ { &quot;type&quot;: &quot;metaverse.region&quot;, &quot;version&quot;: &quot;1.0&quot;, &quot;meta&quot;: {}, &quot;regions&quot;: [ { &quot;shape&quot;: &quot;cylinder&quot;, &quot;params&quot;: { &quot;center&quot;: { &quot;x&quot;: &quot;0&quot;, &quot;y&quot;: &quot;-50&quot;, &quot;z&quot;: &quot;0&quot; }, &quot;radius&quot;: &quot;16&quot;, &quot;height&quot;: &quot;100&quot; } } ] }  Sphere​ Spheres are typically used as parts of complex objects like sculptures, buildings, etc. Sphere is described by coordinates of central point and radius. Spherical object specification​ Field name\tType\tDescription\tValueshape\tstring\tType of shape\tsphere params.center\txyz\tBasic central point of the sphere params.radius\tstring\tRadius of the sphere (number in string format for maximum compatibility)\t Example usage​ { &quot;type&quot;: &quot;metaverse.region&quot;, &quot;version&quot;: &quot;1.0&quot;, &quot;meta&quot;: {}, &quot;regions&quot;: [ { &quot;shape&quot;: &quot;sphere&quot;, &quot;params&quot;: { &quot;center&quot;: { &quot;x&quot;: &quot;0&quot;, &quot;y&quot;: &quot;-50&quot;, &quot;z&quot;: &quot;0&quot; }, &quot;radius&quot;: &quot;16&quot; } } ] }  2D polygon​ Polygons can represent an arbitrary set of vertices. 2D polygons assume that all vertices lay on the same plane. The whole object can be extended in height. 2D polygon object specification​ Field name\tType\tDescription\tValueshape\tstring\tType of shape\tpolygon2d params.points\tlist&lt;xyz&gt;\tCoordinates of polygon vetices params.height\tstring\tHeight of the object (number in string format for maximum compatibility). For the avoidance of doubt, the Y coordinate of the opposite object's side is calculated as Y_basic + height, where Y_basic is the Y coordinate of the first vertex in the array above.\t Shared models​ XYZ​ Field name\tType\tDescription\tDefault valuex\tstring\tX coordinate\t0 y\tstring\tY coordinate\t0 z\tstring\tZ coordinate\t0 Standard conventions​ Numbers and coordinates interpretation depends on the specific metaverse defined in the meta section of the NFT. For this standard purpose, the following convention is applied: X axis is a horizontal one pointing East;Y axis is a vertical one pointing up;Z is the orthogonal axis pointing south; Numbers are stored as strings to ensure maximum compatibility;Numbers must not use scientific notation. "},{"title":"How to add the new JSON metadata type?​","type":1,"pageTitle":"Non-Fungible Token JSON Metadata (TIP-4.2)","url":"/standard/TIP-4.2#how-to-add-the-new-json-metadata-type","content":"For added new metadata type of TIP-4.2 Create product that use new JSON type.Send PR for change the docs.Explain why it will be in Standard. "},{"title":"References​","type":1,"pageTitle":"Non-Fungible Token JSON Metadata (TIP-4.2)","url":"/standard/TIP-4.2#references","content":"Ethereum EIP-721Solana v1.2.0TON NFT, TON DATATezos TZIP12BNS BEP721 "},{"title":"Non-Fungible Token (TIP-4.1)","type":0,"sectionRef":"#","url":"/standard/TIP-4.1","content":"","keywords":""},{"title":"Abstract​","type":1,"pageTitle":"Non-Fungible Token (TIP-4.1)","url":"/standard/TIP-4.1#abstract","content":"The following standard allows for implementing a standard API for NFTs within smart contracts. General information about NFT collection is stored in the NFT collection contract. Each NFT deployed in separate smart contracts and links to NFT collection contract. This standard provides basic functionality to create, track and transfer NFTs. "},{"title":"Motivation​","type":1,"pageTitle":"Non-Fungible Token (TIP-4.1)","url":"/standard/TIP-4.1#motivation","content":"A standard interface allows any NFT to be re-used by other applications: wallets, explorers, marketplaces, etc. "},{"title":"Specification​","type":1,"pageTitle":"Non-Fungible Token (TIP-4.1)","url":"/standard/TIP-4.1#specification","content":"The keywords “MUST”, “MUST NOT”, “REQUIRED”, “SHALL”, “SHALL NOT”, “SHOULD”, “SHOULD NOT”, “RECOMMENDED”, “MAY”, and “OPTIONAL” in this document are to be interpreted as described in RFC 2119. "},{"title":"Collection​","type":1,"pageTitle":"Non-Fungible Token (TIP-4.1)","url":"/standard/TIP-4.1#collection","content":"The contract represents shared information about NFT collection and logic for creation of NFTs and burn of NFTs. Every TIP4.1 compliant collection contract must implement the TIP4_1Collection interface and TIP-6.1 interfaces pragma ton-solidity &gt;= 0.58.0; interface TIP4_1Collection { /// @notice This event emits when NFTs are created /// @param id Unique NFT id /// @param nft Address NFT contact /// @param owner Address of NFT owner /// @param manager Address of NFT manager /// @param creator Address of creator that initialize mint NFT event NftCreated(uint256 id, address nft, address owner, address manager, address creator); /// @notice This event emits when NFTs are burned /// @param id Unique NFT id /// @param nft Address NFT contact /// @param owner Address of NFT owner when it burned /// @param manager Address of NFT manager when it burned event NftBurned(uint256 id, address nft, address owner, address manager); /// @notice Count active NFTs for this collection /// @return count A count of active NFTs minted by this contract except for burned NFTs function totalSupply() external view responsible returns (uint128 count); /// @notice Returns the NFT code /// @return code Returns the NFT code as TvmCell function nftCode() external view responsible returns (TvmCell code); /// @notice Returns the NFT code hash /// @return codeHash Returns the NFT code hash function nftCodeHash() external view responsible returns (uint256 codeHash); /// @notice Computes NFT address by unique NFT id /// @dev Return unique address for all Ids. You find nothing by address for not a valid NFT /// @param id Unique NFT id /// @return nft Returns address of NFT contract function nftAddress(uint256 id) external view responsible returns (address nft); }  NOTE The TIP-6.1 identifier for this interface is 0x1217AAAB. "},{"title":"TIP4_1Collection.totalSupply()​","type":1,"pageTitle":"Non-Fungible Token (TIP-4.1)","url":"/standard/TIP-4.1#tip4_1collectiontotalsupply","content":"function totalSupply() public view responsible returns (uint128 count);  count (uint128) - A count of active NFTs The function return count of active NFTs. Value increased by one when NFT minted and decreased by one when NFT burned. "},{"title":"TIP4_1Collection.nftCode()​","type":1,"pageTitle":"Non-Fungible Token (TIP-4.1)","url":"/standard/TIP-4.1#tip4_1collectionnftcode","content":"function nftCode() public view responsible returns (TvmCell code);  code (TvmCell) - NFT code NFTs is a smart contract deployed from collection smart contract use nftCode and id. "},{"title":"TIP4_1Collection.nftCodeHash()​","type":1,"pageTitle":"Non-Fungible Token (TIP-4.1)","url":"/standard/TIP-4.1#tip4_1collectionnftcodehash","content":"function nftCodeHash() public view responsible returns (uint256 codeHash);  codeHash (uint256) - NFT codeHash A codeHash allows search all smart contracts using base dApp functionality. "},{"title":"TIP4_1Collection.nftAddress()​","type":1,"pageTitle":"Non-Fungible Token (TIP-4.1)","url":"/standard/TIP-4.1#tip4_1collectionnftaddress","content":"function nftAddress(uint256 id) public view responsible returns (address nft);  id (uint256) - Unique NFT idnft (address) - The NFT address Computes NFT address by unique NFT id. You can check the NFT for availability using base dApp functionality. "},{"title":"Events​","type":1,"pageTitle":"Non-Fungible Token (TIP-4.1)","url":"/standard/TIP-4.1#events","content":"event NftCreated(uint256 id, address nft, address owner, address manager, address creator); event NftBurned(uint256 id, address nft, address owner, address manager);  id (uint256) - Unique NFT idnft (address) - The NFT addressowner (address) - The initial\\last owner of the NFTmanager (address) - The initial\\last manager of the NFTcreator (address) - The initial address who initiate NFT deploy You must emit NftCreated event when NFT minted. You must emit NftBurned event when NFT burned. "},{"title":"Mint and burn NFT​","type":1,"pageTitle":"Non-Fungible Token (TIP-4.1)","url":"/standard/TIP-4.1#mint-and-burn-nft","content":"A function's signature is not included in the specification. See the Events for your responsibilities when creating or burning NFTs. "},{"title":"NFT​","type":1,"pageTitle":"Non-Fungible Token (TIP-4.1)","url":"/standard/TIP-4.1#nft","content":"The contract represents information about current NFT and control logic. Each NFT contains two roles: owner logicmanager logic The owner’s address is the address that owns this NFT. The owner can see NFT in wallets, marketplaces, apps. The owner can use the NFT for authorization, for proof in games etc. Manager address is the address that controls this NFT. Manager can burn NFT, can change the owner or change the manager (transfer the manager role). Owner address and manager address can be same usually. When an NFT is put up for sale, it means that the manager's address is the address of the smart contract with the sell logic. It's same for farming logic or custom logic for use NFT. Good practice is to set a manager address to a new owner address when owner changed. Every TIP4.1 compliant NFT contract must implement the TIP4_1NFT interface and TIP-6.1 interfaces. pragma ton-solidity &gt;= 0.58.0; interface TIP4_1NFT { struct CallbackParams { uint128 value; // ever value will be sent to address TvmCell payload; // custom payload will be proxied to address } /// @notice The event emits when NFT is created /// @dev Emit the event when NFT is ready to use /// @param id Unique NFT id /// @param owner Address of NFT owner /// @param manager Address of NFT manager /// @param collection Address of collection smart contract that mint the NFT event NftCreated(uint256 id, address owner, address manager, address collection); /// @notice The event emits when NFT owner changed /// @param oldOwner Address of NFT owner before owner changed /// @param newOwner Address of new NFT owner event OwnerChanged(address oldOwner, address newOwner); /// @notice The event emits when NFT manager changed /// @param oldManager Address of NFT manager before manager changed /// @param newManager Address of new NFT manager event ManagerChanged(address oldManager, address newManager); /// @param id Unique NFT id /// @param owner Address of NFT owner /// @param manager Address of NFT manager /// @param collection Address of collection smart contract, that mint the NFT event NftBurned(uint256 id, address owner, address manager, address collection); /// @notice NFT info /// @return id Unique NFT id /// @return owner Address of NFT owner /// @return manager Address of NFT manager /// @return collection Address of collection smart contract function getInfo() external view responsible returns(uint256 id, address owner, address manager, address collection); /// @notice Change NFT owner /// @dev Invoked from manager address only /// @dev Emit OwnerChanged /// @param newOwner New owner of NFT /// @param sendGasTo Address to send remaining gas /// @param callbacks Callbacks array to send by addresses. It can be empty function changeOwner(address newOwner, address sendGasTo, mapping(address =&gt; CallbackParams) callbacks) external; /// @notice Change NFT manager /// @dev Invoked from manager address only /// @dev Emit ManagerChanged /// @param newManager New manager of NFT /// @param sendGasTo Address to send remaining gas /// @param callbacks Callbacks array to send by addresses. It can be empty function changeManager(address newManager, address sendGasTo, mapping(address =&gt; CallbackParams) callbacks) external; /// @notice Change NFT owner and manager /// @dev Invoked from manager address only /// @dev Emit OwnerChanged /// @dev Emit ManagerChanged /// @param to New NFT owner and manager /// @param sendGasTo Address to send remaining gas /// @param callbacks Callbacks array to send by addresses. It can be empty function transfer(address to, address sendGasTo, mapping(address =&gt; CallbackParams) callbacks) external; }  NOTE The TIP-6.1 identifier for this interface is 0x78084F7E. "},{"title":"TIP4_1NFT.getInfo()​","type":1,"pageTitle":"Non-Fungible Token (TIP-4.1)","url":"/standard/TIP-4.1#tip4_1nftgetinfo","content":"function getInfo() public view responsible returns(uint256 id, address owner, address manager, address collection);  id (uint256) - Unique NFT idowner (address) - The owner of the NFTmanager (address) - The manager of the NFTcollection (address) - The NFT collection address "},{"title":"TIP4_1NFT.changeOwner()​","type":1,"pageTitle":"Non-Fungible Token (TIP-4.1)","url":"/standard/TIP-4.1#tip4_1nftchangeowner","content":"function changeOwner(address newOwner, address sendGasTo, mapping(address =&gt; CallbackParams) callbacks) external;  newOwner (address) - New owner of NFTsendGasTo (address) - Address to send remaining gas. It sent to all callback addresses, toocallbacks (mapping(address =&gt; CallbackParams)) - Callbacks uses for asynchronous calls to another addresses CallbackParams: Field name\ttype\tDescriptionvalue\tuint128\tEver values that send with callback payload\tTvmCell\tCustom payload will send to address Change NFT owner. You must emit OwnerChanged event when NFT owner changed. The NFT sends callbacks if callbacks not empty. "},{"title":"TIP4_1NFT.changeManager()​","type":1,"pageTitle":"Non-Fungible Token (TIP-4.1)","url":"/standard/TIP-4.1#tip4_1nftchangemanager","content":"function changeManager(address newManager, address sendGasTo, mapping(address =&gt; CallbackParams) callbacks) external;  newManager (address) - New manager of NFTsendGasTo (address) - Address to send remaining gas. It sent to all callback addresses toocallbacks (mapping(address =&gt; CallbackParams)) - Callbacks uses for asynchronous calls to another addresses CallbackParams: Field name\ttype\tDescriptionvalue\tuint128\tEver values that send with callback payload\tTvmCell\tCustom payload will send to address Change NFT manager. You must emit ManagerChanged event when NFT owner changed. The NFT sends callbacks if callbacks not empty. "},{"title":"TIP4_1NFT.transfer()​","type":1,"pageTitle":"Non-Fungible Token (TIP-4.1)","url":"/standard/TIP-4.1#tip4_1nfttransfer","content":"function transfer(address to, address sendGasTo, mapping(address =&gt; CallbackParams) callbacks) external;  to (address) - New NFT owner and managersendGasTo (address) - Address to send remaining gas. It sent to all callback addresses toocallbacks (mapping(address =&gt; CallbackParams)) - Callbacks uses for asynchronous calls to another addresses CallbackParams: Field name\ttype\tDescriptionvalue\tuint128\tEver values that send with callback payload\tTvmCell\tCustom payload will send to address Change NFT manager. You must emit OwnerChanged and ManagerChanged events when NFT owner changed. The NFT sends callbacks if callbacks not empty. "},{"title":"NFT events​","type":1,"pageTitle":"Non-Fungible Token (TIP-4.1)","url":"/standard/TIP-4.1#nft-events","content":"event NftCreated(uint256 id, address owner, address manager, address collection); event OwnerChanged(address oldOwner, address newOwner); event ManagerChanged(address oldManager, address newManager); event NftBurned(uint256 id, address owner, address manager, address collection);  id (uint256) - Unique NFT idowner (address) - The initial\\last owner of the NFTmanager (address) - The initial\\last manager of the NFTcollection (address) - The collection address who initiate NFT deploy You must emit NftCreated event, when NFT created, initialized and ready to use. You must emit OwnerChanged event every time when owner address changed. You must emit ManagerChanged event every time when manager address changed. You must emit NftBurned event when NFT burned. Events emit when NFTs are created, burned or moved to a new owner\\manager. "},{"title":"Mint NFT​","type":1,"pageTitle":"Non-Fungible Token (TIP-4.1)","url":"/standard/TIP-4.1#mint-nft","content":"A function and constructor signature is not included in the specification. The NFT must deploy from collection smart contract. The NFT must emit NftCreated event after NFT deployed and ready to use. See the [NFT events](#NFT events) for your responsibilities when creating NFT. "},{"title":"Burn NFT​","type":1,"pageTitle":"Non-Fungible Token (TIP-4.1)","url":"/standard/TIP-4.1#burn-nft","content":"A function signature is not included in the specification. The NFT must emit NftBurned event before NFT burned. The NFT must send an internal message to collection contract before NFT burned. See the Events for your responsibilities when burning NFT. "},{"title":"ChangeOwner callback processing​","type":1,"pageTitle":"Non-Fungible Token (TIP-4.1)","url":"/standard/TIP-4.1#changeowner-callback-processing","content":"Smart contract that processing callback message must implement. interface INftChangeOwner { struct CallbackParams { uint128 value; // ever value will send to address TvmCell payload; // custom payload will be proxied to address } /// @notice change owner callback processing /// @param id Unique NFT id /// @param manager Address of NFT manager /// @param oldOwner Address of NFT owner before owner changed /// @param newOwner Address of new NFT owner /// @param collection Address of collection smart contract, that mint the NFT /// @param sendGasTo Address to send remaining gas /// @param payload Custom payload function onNftChangeOwner( uint256 id, address manager, address oldOwner, address newOwner, address collection, address sendGasTo, TvmCell payload ) external; }  "},{"title":"ChangeManager callback processing​","type":1,"pageTitle":"Non-Fungible Token (TIP-4.1)","url":"/standard/TIP-4.1#changemanager-callback-processing","content":"Smart contract that processing callback message must implement. interface INftChangeManager { struct CallbackParams { uint128 value; // ever value will send to address TvmCell payload; // custom payload will proxying to address } /// @notice change owner callback processing /// @param id Unique NFT id /// @param owner Address of NFT owner /// @param oldManager Address of NFT manager before manager changed /// @param newManager Address of new NFT manager /// @param collection Address of collection smart contract that mint the NFT /// @param sendGasTo - Address to send remaining gas /// @param payload - Custom payload function onNftChangeManager( uint256 id, address owner, address oldManager, address newManager, address collection, address sendGasTo, TvmCell payload ) external; }  "},{"title":"Transfer callback processing​","type":1,"pageTitle":"Non-Fungible Token (TIP-4.1)","url":"/standard/TIP-4.1#transfer-callback-processing","content":"Smart contract that processing callback message must implement. interface INftTransfer { struct CallbackParams { uint128 value; // ever value will send to address TvmCell payload; // custom payload will proxying to address } /// @notice change owner callback processing /// @param id Unique NFT id /// @param oldOwner Address of NFT owner before transfer /// @param newOwner Address of new NFT owner /// @param oldManager Address of NFT manager before transfer /// @param newManager Address of new NFT manager /// @param collection Address of collection smart contract that mint the NFT /// @param sendGasTo Address to send remaining gas /// @param payload Custom payload function onNftTransfer( uint256 id, address oldOwner, address newOwner, address oldManager, address newManager, address collection, address sendGasTo, TvmCell payload ) external; }  "},{"title":"Visualization​","type":1,"pageTitle":"Non-Fungible Token (TIP-4.1)","url":"/standard/TIP-4.1#visualization","content":""},{"title":"Legend​","type":1,"pageTitle":"Non-Fungible Token (TIP-4.1)","url":"/standard/TIP-4.1#legend","content":" "},{"title":"Collection deployment​","type":1,"pageTitle":"Non-Fungible Token (TIP-4.1)","url":"/standard/TIP-4.1#collection-deployment","content":" "},{"title":"Minting​","type":1,"pageTitle":"Non-Fungible Token (TIP-4.1)","url":"/standard/TIP-4.1#minting","content":" "},{"title":"Burning​","type":1,"pageTitle":"Non-Fungible Token (TIP-4.1)","url":"/standard/TIP-4.1#burning","content":" "},{"title":"Change owner​","type":1,"pageTitle":"Non-Fungible Token (TIP-4.1)","url":"/standard/TIP-4.1#change-owner","content":" "},{"title":"Change manager​","type":1,"pageTitle":"Non-Fungible Token (TIP-4.1)","url":"/standard/TIP-4.1#change-manager","content":" "},{"title":"Example how to use NFT. Put on sell using changeManager()​","type":1,"pageTitle":"Non-Fungible Token (TIP-4.1)","url":"/standard/TIP-4.1#example-how-to-use-nft-put-on-sell-using-changemanager","content":" "},{"title":"Example how to use NFT. Buy using changeOwner()​","type":1,"pageTitle":"Non-Fungible Token (TIP-4.1)","url":"/standard/TIP-4.1#example-how-to-use-nft-buy-using-changeowner","content":" "},{"title":"Example how to use NFT. Put on sell by TIP-3.1 tokens​","type":1,"pageTitle":"Non-Fungible Token (TIP-4.1)","url":"/standard/TIP-4.1#example-how-to-use-nft-put-on-sell-by-tip-31-tokens","content":" "},{"title":"Example how to use NFT. Buy for TIP-3.1 tokens​","type":1,"pageTitle":"Non-Fungible Token (TIP-4.1)","url":"/standard/TIP-4.1#example-how-to-use-nft-buy-for-tip-31-tokens","content":" "},{"title":"References​","type":1,"pageTitle":"Non-Fungible Token (TIP-4.1)","url":"/standard/TIP-4.1#references","content":"Ethereum EIP-721Solana v1.2.0TON NFT, TON DATATezos TZIP12 "},{"title":"Non-Fungible Token On-chain storage (TIP-4.4)","type":0,"sectionRef":"#","url":"/standard/TIP-4.4","content":"","keywords":""},{"title":"Abstract​","type":1,"pageTitle":"Non-Fungible Token On-chain storage (TIP-4.4)","url":"/standard/TIP-4.4#abstract","content":"Using the Storage contract, you can store NFT-related bytes in blockchain "},{"title":"Motivation​","type":1,"pageTitle":"Non-Fungible Token On-chain storage (TIP-4.4)","url":"/standard/TIP-4.4#motivation","content":"Fault tolerance. If off-chain services are unavailable, the user will view NFT-related bytes, because it is stored on-chain. "},{"title":"Specification​","type":1,"pageTitle":"Non-Fungible Token On-chain storage (TIP-4.4)","url":"/standard/TIP-4.4#specification","content":"The keywords “MUST”, “MUST NOT”, “REQUIRED”, “SHALL”, “SHALL NOT”, “SHOULD”, “SHOULD NOT”, “RECOMMENDED”, “MAY”, and “OPTIONAL” in this document are to be interpreted as described in RFC 2119 "},{"title":"Contracts​","type":1,"pageTitle":"Non-Fungible Token On-chain storage (TIP-4.4)","url":"/standard/TIP-4.4#contracts","content":"Collection - TIP4.1 contract that minted token and store Storage contract codeNFT - TIP4.1 contract that store token information and Storage contract addressStorage - contract that store token byte content. Storage is independent. Storage doesn’t store NFT address because NFT contract address can be changed by burning and redeployment from another collection. "},{"title":"Collection​","type":1,"pageTitle":"Non-Fungible Token On-chain storage (TIP-4.4)","url":"/standard/TIP-4.4#collection","content":"Every TIP-4.1 Collection contract must implement TIP4_4Collection pragma ton-solidity &gt;= 0.58.0; interface TIP4_4Collection { function storageCode() external view responsible returns (TvmCell code); function storageCodeHash() external view responsible returns (uint256 codeHash); function resolveStorage(address nft) external view responsible returns (address addr); }  NOTE The TIP-6.1 identifier for this interface is 0x6302A6F8 "},{"title":"TIP4_4Collection.storageCode()​","type":1,"pageTitle":"Non-Fungible Token On-chain storage (TIP-4.4)","url":"/standard/TIP-4.4#tip4_4collectionstoragecode","content":"function storageCode() external view responsible returns (TvmCell code);  code (TvmCell) - storage contract code "},{"title":"TIP4_4Collection.storageCode()​","type":1,"pageTitle":"Non-Fungible Token On-chain storage (TIP-4.4)","url":"/standard/TIP-4.4#tip4_4collectionstoragecode-1","content":"function storageCodeHash() external view responsible returns (uint256 hash);  hash (uint256) - storage contract code hash "},{"title":"TIP4_4Collection.resolveStorage()​","type":1,"pageTitle":"Non-Fungible Token On-chain storage (TIP-4.4)","url":"/standard/TIP-4.4#tip4_4collectionresolvestorage","content":"function resolveStorage(address nft) external view responsible returns (address addr);  nft (address) - token contract addressaddr (address) - storage contract address "},{"title":"NFT​","type":1,"pageTitle":"Non-Fungible Token On-chain storage (TIP-4.4)","url":"/standard/TIP-4.4#nft","content":"Every TIP-4.1 NFT contract must implement TIP4_4NFT pragma ton-solidity &gt;= 0.58.0; interface TIP4_4NFT { function onStorageFillComplete(address gasReceiver) external; function getStorage() external view responsible returns (address addr); }  NOTE The TIP-6.1 identifier for this interface is 0x009DC09A "},{"title":"TIP4_4NFT.onStorageFillComplete()​","type":1,"pageTitle":"Non-Fungible Token On-chain storage (TIP-4.4)","url":"/standard/TIP-4.4#tip4_4nftonstoragefillcomplete","content":"function onStorageFillComplete(address gasReceiver) external;  gasReceiver (address) - address of contract that receive all remaining contract balance then last chunk filled Calling the Storage.fill() on storage contract that fills the last chunk should call TIP4_4NFT.onStorageFillComplete() on token contract "},{"title":"TIP4_4NFT.getStorage()​","type":1,"pageTitle":"Non-Fungible Token On-chain storage (TIP-4.4)","url":"/standard/TIP-4.4#tip4_4nftgetstorage","content":"function getStorage() external view responsible returns (address addr);  addr (address) - storage contract address "},{"title":"Storage​","type":1,"pageTitle":"Non-Fungible Token On-chain storage (TIP-4.4)","url":"/standard/TIP-4.4#storage","content":"Every Storage contract must implement TIP4_4Storage pragma ton-solidity &gt;= 0.58.0; interface TIP4_4Storage { function fill(uint32 id, bytes chunk, address gasReceiver) external; function getInfo() external view responsible returns ( address nft, address collection, string mimeType, mapping(uint32 =&gt; bytes) content, string contentEncoding ); }  NOTE The TIP-6.1 identifier for this interface is 0x204D6296 "},{"title":"TIP4_4Storage.fill()​","type":1,"pageTitle":"Non-Fungible Token On-chain storage (TIP-4.4)","url":"/standard/TIP-4.4#tip4_4storagefill","content":"function fill(uint32 id, bytes chunk, address gasReceiver) external;  id (uint32) - chunk number. From 0 to 4 294 967 295bytes (chunk) - data. Max size of data is limited by external message payload size. Maximum size external message payload size is 16KB at 2022-03-18.gasReceiver (address) - address of contract that receive all remaining contract balance then last chunk filled. "},{"title":"TIP4_4Storage.getInfo()​","type":1,"pageTitle":"Non-Fungible Token On-chain storage (TIP-4.4)","url":"/standard/TIP-4.4#tip4_4storagegetinfo","content":"function getInfo() external view responsible returns ( address nft, address collection, string mimeType, mapping(uint32 =&gt; bytes) chunks, string contentEncoding );  nft (address) - token contract addresscollection (address) - collection token contract addressmimeType (string) - MIME types are defined and standardized in IETF's RFC 6838content (mapping(uint32 =&gt; bytes)) - byte content. Maximum content size is 4 294 967 295 chunks * chunk size. Max size of data is limited by external message payload size. Maximum size external message payload size is 16KB at 2022-03-18 Maximum content size is 4 294 967 295 * 16KB ≈ 69TB at 2022-03-18.contentEncoding (string) - Was it compressed by any algorithm. If it was compressed with zstd contentEncoding need to be zstd, all other need to be like http content encoding "},{"title":"Visualization​","type":1,"pageTitle":"Non-Fungible Token On-chain storage (TIP-4.4)","url":"/standard/TIP-4.4#visualization","content":""},{"title":"Legend​","type":1,"pageTitle":"Non-Fungible Token On-chain storage (TIP-4.4)","url":"/standard/TIP-4.4#legend","content":" "},{"title":"NFT minting with Storage​","type":1,"pageTitle":"Non-Fungible Token On-chain storage (TIP-4.4)","url":"/standard/TIP-4.4#nft-minting-with-storage","content":" "},{"title":"Storage filling​","type":1,"pageTitle":"Non-Fungible Token On-chain storage (TIP-4.4)","url":"/standard/TIP-4.4#storage-filling","content":" "},{"title":"Storage with Index​","type":1,"pageTitle":"Non-Fungible Token On-chain storage (TIP-4.4)","url":"/standard/TIP-4.4#storage-with-index","content":"How to interaction on-chain indexes and Storage contracts "},{"title":"Non-Fungible Token on-chain indexes (TIP-4.3)","type":0,"sectionRef":"#","url":"/standard/TIP-4.3","content":"","keywords":""},{"title":"Abstract​","type":1,"pageTitle":"Non-Fungible Token on-chain indexes (TIP-4.3)","url":"/standard/TIP-4.3#abstract","content":"Using the Index contract code, you can find all your NFT with one dApp query. This makes blockchain application less dependent on different off-chain parsers and indexers On-chain Indexes solves easy and fast searching any data in blockchain. This document shows standard for basic query. Any developer can get an idea of this solution and realize his own on-chain index. "},{"title":"Motivation​","type":1,"pageTitle":"Non-Fungible Token on-chain indexes (TIP-4.3)","url":"/standard/TIP-4.3#motivation","content":"A standard interface allows search all Collection and all NFT by owner using base dApp functionality "},{"title":"Specification​","type":1,"pageTitle":"Non-Fungible Token on-chain indexes (TIP-4.3)","url":"/standard/TIP-4.3#specification","content":"The keywords “MUST”, “MUST NOT”, “REQUIRED”, “SHALL”, “SHALL NOT”, “SHOULD”, “SHOULD NOT”, “RECOMMENDED”, “MAY”, and “OPTIONAL” in this document are to be interpreted as described in RFC 2119 "},{"title":"Contracts​","type":1,"pageTitle":"Non-Fungible Token on-chain indexes (TIP-4.3)","url":"/standard/TIP-4.3#contracts","content":"Collection - TIP4.1 contract that minted tokenNFT - TIP4.1 contract that store token informationIndexBasis - contract, that helps to find all collections by the code hash of whichIndex - contract, that helps to find: All user tokens in current collection using owner address and collection addressAll user tokens in all collections using owner address code of IndexBasis and Index contracts and code hash of contracts is fixed and CANNOT BE CHANGED "},{"title":"IIndexBasis​","type":1,"pageTitle":"Non-Fungible Token on-chain indexes (TIP-4.3)","url":"/standard/TIP-4.3#iindexbasis","content":"pragma ton-solidity &gt;= 0.58.0; interface IIndexBasis { function getInfo() external view responsible returns (address collection); function destruct(address gasReceiver) external; }  "},{"title":"IndexBasis​","type":1,"pageTitle":"Non-Fungible Token on-chain indexes (TIP-4.3)","url":"/standard/TIP-4.3#indexbasis","content":"pragma ton-solidity &gt;= 0.58.0; import 'IIndexBasis.sol'; /** * Errors * 101 - Method for collection only **/ contract IndexBasis is IIndexBasis { address static _collection; modifier onlyCollection() { require(msg.sender == _collection, 101, &quot;Method for collection only&quot;); tvm.accept(); _; } constructor() public onlyCollection {} function getInfo() override public view responsible returns (address collection) { return {value: 0, flag: 64} _collection; } function destruct(address gasReceiver) override public onlyCollection { selfdestruct(gasReceiver); } }  Code hash of IndexBasis compiled by TVMCompiler v0.58.2 and TVM-linker v0.14.51 without salting is 2359f897c9527073b1c95140c670089aa5ab825f5fd1bd453db803fbab47def2 "},{"title":"IIndexBasis.getInfo()​","type":1,"pageTitle":"Non-Fungible Token on-chain indexes (TIP-4.3)","url":"/standard/TIP-4.3#iindexbasisgetinfo","content":"function getInfo() external view responsible returns (address collection);  collection (address) - collection token contract address "},{"title":"IIndexBasis.destruct()​","type":1,"pageTitle":"Non-Fungible Token on-chain indexes (TIP-4.3)","url":"/standard/TIP-4.3#iindexbasisdestruct","content":"function destruct(address gasReceiver) external;  gasReceiver (address) - address of contract that receives all remaining contract balance after selfdestruct() call "},{"title":"IIndex​","type":1,"pageTitle":"Non-Fungible Token on-chain indexes (TIP-4.3)","url":"/standard/TIP-4.3#iindex","content":"pragma ton-solidity &gt;= 0.58.0; interface IIndex { function getInfo() external view responsible returns ( address collection, address owner, address nft ); function destruct(address gasReceiver) external; }  "},{"title":"Index​","type":1,"pageTitle":"Non-Fungible Token on-chain indexes (TIP-4.3)","url":"/standard/TIP-4.3#index","content":"pragma ton-solidity &gt;= 0.58.0; import 'IIndex.sol'; /** * Errors * 101 - Method for NFT only * 102 - Salt doesn't contain any value **/ contract Index is IIndex { address static _nft; address _collection; address _owner; constructor(address collection) public { optional(TvmCell) salt = tvm.codeSalt(tvm.code()); require(salt.hasValue(), 102, &quot;Salt doesn't contain any value&quot;); (, address collection_, address owner) = salt .get() .toSlice() .decode(string, address, address); require(msg.sender == _nft); tvm.accept(); _collection = collection_; _owner = owner; if (collection_.value == 0) { _collection = collection; } } function getInfo() override public view responsible returns ( address collection, address owner, address nft ) { return {value: 0, flag: 64} ( _collection, _owner, _nft ); } function destruct(address gasReceiver) override public { require(msg.sender == _nft, 101, &quot;Method for NFT only&quot;); selfdestruct(gasReceiver); } }  Code hash of Index compiled by TVMCompiler v0.58.2 and TVM-linker v0.14.51 without salting is 61e5f39a693dc133ea8faf3e80fac069250161b0bced3790c20ae234ce6fd866 "},{"title":"Index.getInfo()​","type":1,"pageTitle":"Non-Fungible Token on-chain indexes (TIP-4.3)","url":"/standard/TIP-4.3#indexgetinfo","content":"function getInfo() external view responsible returns ( address collection, address owner, address nft );  collection (address) - collection token contract addressowner (address) - token owner contract addressnft (address) - token contract address "},{"title":"IIndexBasis.destruct()​","type":1,"pageTitle":"Non-Fungible Token on-chain indexes (TIP-4.3)","url":"/standard/TIP-4.3#iindexbasisdestruct-1","content":"function destruct(address gasReceiver) external;  gasReceiver (address) - address of contract that receives all remaining contract balance after selfdestruct() call "},{"title":"Collection​","type":1,"pageTitle":"Non-Fungible Token on-chain indexes (TIP-4.3)","url":"/standard/TIP-4.3#collection","content":"TIP-4.1 Collection contract must implement the TIP4_3Collection interface and TIP-6.1 interfacesTIP-4.1 Collection contract must deploy IndexBasis contract after deployment with code saltTIP-4.1 Collection contract must destuct() IndexBasis contracts before collection destruction "},{"title":"TIP4_3Collection​","type":1,"pageTitle":"Non-Fungible Token on-chain indexes (TIP-4.3)","url":"/standard/TIP-4.3#tip4_3collection","content":"pragma ton-solidity &gt;= 0.58.0; interface TIP4_3Collection { function indexBasisCode() external view responsible returns (TvmCell code); function indexBasisCodeHash() external view responsible returns (uint256 hash); function indexCode() external view responsible returns (TvmCell code); function indexCodeHash() external view responsible returns (uint256 hash); function resolveIndexBasis() external view responsible returns (address indexBasis); }  NOTE The TIP-6.1 identifier for this interface is 0x4387BBFB TIP4_3Collection.indexBasisCode()​ function indexBasisCode() external view responsible returns (TvmCell code);  code (TvmCell) - basis index contract code TIP4_3Collection.indexBasisCodeHash()​ function indexBasisCodeHash() external view responsible returns (uint256 hash);  hash (uint256) - basis index contract code hash TIP4_3Collection.indexCode()​ function indexCode() external view responsible returns (TvmCell code);  code (TvmCell) - index contract code TIP4_3Collection.indexCodeHash()​ function indexCodeHash() external view responsible returns (uint256 hash);  hash (uint256) - index contract code hash TIP4_3Collection.indexBasis()​ function resolveIndexBasis() external view responsible returns (address indexBasis);  indexBasis (address) - basis index contract address "},{"title":"Code salt parameters​","type":1,"pageTitle":"Non-Fungible Token on-chain indexes (TIP-4.3)","url":"/standard/TIP-4.3#code-salt-parameters","content":"stamp (string) - stamp that determine type of index. stamp = &quot;nft&quot;; for all NFT indexes "},{"title":"Example of IndexBasis deployment​","type":1,"pageTitle":"Non-Fungible Token on-chain indexes (TIP-4.3)","url":"/standard/TIP-4.3#example-of-indexbasis-deployment","content":"function deployIndexBasis(TvmCell codeIndex, address collection, uint128 value) private pure { string stamp = &quot;nft&quot;; TvmBuilder salt; salt.store(stamp); TvmCell code = tvm.setCodeSalt(codeIndex, salt.toCell()); TvmCell stateInit = tvm.buildStateInit({ contr: IndexBasis, varInit: {_collection: collection}, code: code }); new IndexBasis{stateInit: stateInit, value: value}(); }  "},{"title":"NFT​","type":1,"pageTitle":"Non-Fungible Token on-chain indexes (TIP-4.3)","url":"/standard/TIP-4.3#nft","content":"TIP-4.1 Collection contract must implement the TIP4_3NFT interface and TIP-6.1 interfacesTIP-4.1 NFT contract must deploy at least two Index contract after deployment with different code salt With zero collection address collection = &quot;0:0000000000000000000000000000000000000000000000000000000000000000&quot; in code saltWith non-zero collection address collection = &quot;0:3bd8…&quot; in code salt TIP-4.1 NFT contract must destuct() Index before NFT burningTIP-4.1 NFT contract must destuct() old Index contacts and deploy new Index contracts if owner changed "},{"title":"TIP4_3NFT​","type":1,"pageTitle":"Non-Fungible Token on-chain indexes (TIP-4.3)","url":"/standard/TIP-4.3#tip4_3nft","content":"pragma ton-solidity &gt;= 0.58.0; interface TIP4_3NFT { function indexCode() external view responsible returns (TvmCell code); function indexCodeHash() external view responsible returns (uint256 hash); function resolveIndex(address collection, address owner) external view responsible returns (address index); }  NOTE The TIP-6.1 identifier for this interface is 0x4DF6250B TIP4_3NFT.indexCode()​ function indexCode() external view responsible returns (TvmCell code);  code (TvmCell) - index contract code TIP4_3NFT.indexCodeHash()​ function indexCodeHash() external view responsible returns (uint256 hash);  hash (uint256) - basis index contract code hash TIP4_3NFT.resolveIndex()​ function resolveIndex(address collection, address owner) external view responsible returns (address index);  collection (address) - collection token contract addressowner (address) - token owner contract addressindex (address) - index contract address "},{"title":"Code salt parameters​","type":1,"pageTitle":"Non-Fungible Token on-chain indexes (TIP-4.3)","url":"/standard/TIP-4.3#code-salt-parameters-1","content":"stamp (string) - stamp that determine type of index. stamp = &quot;nft&quot;; for all NFT indexescollection (address) - collection token contract addressowner (address) - token owner contract address "},{"title":"Example of Index deployment​","type":1,"pageTitle":"Non-Fungible Token on-chain indexes (TIP-4.3)","url":"/standard/TIP-4.3#example-of-index-deployment","content":"function deployIndex(TvmCell codeIndex, address nft, address collection, address owner, uint128 value) private pure { string stamp = &quot;nft&quot;; TvmBuilder salt; salt.store(stamp, collection, owner); TvmCell code = tvm.setCodeSalt(codeIndex, salt.toCell()); TvmCell stateInit = tvm.buildStateInit({ contr: Index, varInit: {_nft: nft}, code: code }); new Index{stateInit: stateInit, value: value}(); }  "},{"title":"Example of dApp query for search by index​","type":1,"pageTitle":"Non-Fungible Token on-chain indexes (TIP-4.3)","url":"/standard/TIP-4.3#example-of-dapp-query-for-search-by-index","content":"query { accounts( filter: { code_hash: { eq: &quot;207dc560c5956de1a2c1479356f8f3ee70a59767db2bf4788b1d61ad42cdad82&quot; } } ){ id } }  Part of response example { &quot;data&quot;: { &quot;accounts&quot;: [ { &quot;id&quot;: &quot;0:000001b0422f6a7069786fa9a27aa7bb8042f58e1df01dfebc51dcb2baa5eeae&quot; }, { &quot;id&quot;: &quot;0:00022772794253c1bf8cb4fa59d6161d574033c13d881f3eea14675b911e61b0&quot; } ] } }  "},{"title":"Source code​","type":1,"pageTitle":"Non-Fungible Token on-chain indexes (TIP-4.3)","url":"/standard/TIP-4.3#source-code","content":"link "},{"title":"Visualization​","type":1,"pageTitle":"Non-Fungible Token on-chain indexes (TIP-4.3)","url":"/standard/TIP-4.3#visualization","content":""},{"title":"Legend​","type":1,"pageTitle":"Non-Fungible Token on-chain indexes (TIP-4.3)","url":"/standard/TIP-4.3#legend","content":" "},{"title":"IndexBasis deployment for Collection​","type":1,"pageTitle":"Non-Fungible Token on-chain indexes (TIP-4.3)","url":"/standard/TIP-4.3#indexbasis-deployment-for-collection","content":" "},{"title":"Index contracts deployment for NFT​","type":1,"pageTitle":"Non-Fungible Token on-chain indexes (TIP-4.3)","url":"/standard/TIP-4.3#index-contracts-deployment-for-nft","content":" "},{"title":"Redeploy Index contracts after changeOwner​","type":1,"pageTitle":"Non-Fungible Token on-chain indexes (TIP-4.3)","url":"/standard/TIP-4.3#redeploy-index-contracts-after-changeowner","content":" "},{"title":"Non-Fungible Licensing (TIP-4.5)","type":0,"sectionRef":"#","url":"/standard/TIP-4.5","content":"","keywords":""},{"title":"Abstract​","type":1,"pageTitle":"Non-Fungible Licensing (TIP-4.5)","url":"/standard/TIP-4.5#abstract","content":"The NFT License Standart is a standard set of functions for retrieving license information. This interface allows external callers to access the license URI and the license name associated with a specific entity. The preferred but not mandatory method of storing license links is using IPFS. A collection of NFT licenses can be obtained via a link. "},{"title":"Motivation​","type":1,"pageTitle":"Non-Fungible Licensing (TIP-4.5)","url":"/standard/TIP-4.5#motivation","content":"This standard was developed based on the previous version of the &quot;CantBeEvil&quot; standard. The new &quot;NFT Licensing&quot; standard offers you more freedom and flexibility in using licenses for your NFT tokens, allowing you to choose any license that reflects your vision and protects your rights, provided that a link to it is provided. "},{"title":"Specification​","type":1,"pageTitle":"Non-Fungible Licensing (TIP-4.5)","url":"/standard/TIP-4.5#specification","content":"The keywords “MUST”, “MUST NOT”, “REQUIRED”, “SHALL”, “SHALL NOT”, “SHOULD”, “SHOULD NOT”, “RECOMMENDED”, “MAY”, and “OPTIONAL” in this document are to be interpreted as described in RFC 2119. "},{"title":"TIP4_5​","type":1,"pageTitle":"Non-Fungible Licensing (TIP-4.5)","url":"/standard/TIP-4.5#tip4_5","content":"pragma ever-solidity &gt;= 0.61.2; interface ITIP4_5 { function getLicenseURI() external view responsible returns (string); function getLicenseName() external view responsible returns (string); }  NOTE The TIP-6.1 identifier for this interface is 0x8A1EB91 (with responsible) and 0x1E4848D4 (without responsible). "},{"title":"TIP4_5.getLicenseURI()​","type":1,"pageTitle":"Non-Fungible Licensing (TIP-4.5)","url":"/standard/TIP-4.5#tip4_5getlicenseuri","content":"function getLicenseURI() external view responsible returns (string);  Returns the license URI. The license URI represents the location or identifier that can be used to access the full details of the license, such as terms and conditions, permissions, and restrictions. "},{"title":"TIP4_5.getLicenseName()​","type":1,"pageTitle":"Non-Fungible Licensing (TIP-4.5)","url":"/standard/TIP-4.5#tip4_5getlicensename","content":"function getLicenseName() external view responsible returns (string);  Returns the name or title of the license. The license name provides a concise and descriptive representation of the license type or category. "},{"title":"Standard Interface Detection","type":0,"sectionRef":"#","url":"/standard/TIP-6","content":"","keywords":""},{"title":"Abstract​","type":1,"pageTitle":"Standard Interface Detection","url":"/standard/TIP-6#abstract","content":"Smart contracts in Everscale can implement a wide variety of functionality - wallets, tokens, exchanges and so on. We need a standard way to determine the type of smart contract without relying on knowledge of its internal structure. "},{"title":"Standard Interface Detection Interface (TIP-6.1)","type":0,"sectionRef":"#","url":"/standard/TIP-6.1","content":"","keywords":""},{"title":"Simple summary​","type":1,"pageTitle":"Standard Interface Detection Interface (TIP-6.1)","url":"/standard/TIP-6.1#simple-summary","content":"Creates a standard method to publish and detect what interfaces a smart contract implements. "},{"title":"Abstract​","type":1,"pageTitle":"Standard Interface Detection Interface (TIP-6.1)","url":"/standard/TIP-6.1#abstract","content":"Herein, we standardize the following: How interfaces are identifiedHow a contract will publish the interfaces it implements "},{"title":"Motivation​","type":1,"pageTitle":"Standard Interface Detection Interface (TIP-6.1)","url":"/standard/TIP-6.1#motivation","content":"For some “standard interfaces” like the token interface, it is sometimes useful to query whether a contract supports the interface and if yes, which version of the interface, in order to adapt the way in which the contract is to be interacted with. This proposal standardizes the concept of interfaces and standardizes the identification (naming) of interfaces. "},{"title":"Specification​","type":1,"pageTitle":"Standard Interface Detection Interface (TIP-6.1)","url":"/standard/TIP-6.1#specification","content":""},{"title":"How interfaces are identified​","type":1,"pageTitle":"Standard Interface Detection Interface (TIP-6.1)","url":"/standard/TIP-6.1#how-interfaces-are-identified","content":"For this standard, an interface is a set of function selectors as defined by the Solidity ABI. This a subset of Solidity’s concept of interfaces and the interface keyword definition which also defines return types, mutability and events. We define the interface identifier as the XOR of all function selectors in the interface. This code example shows how to calculate an interface identifier: Solidity​ interface Solidity101 { function hello() external pure; function world(int) external pure; } contract Selector { function calculateSelector() public view returns (bytes4) { Solidity101 i; return bytes4(tvm.functionId(i.hello) ^ tvm.functionId(i.world)); } }  How a Contract will Publish the Interfaces it Implements​ A contract that is compliant with TIP6.1 shall implement the following interface: Solidity​ interface TIP6 { /// @notice Query if a contract implements an interface /// @param interfaceID The interface identifier, as specified in TIP6.1 /// @dev Interface identification is specified in TIP6.1. /// @return `true` if the contract implements `interfaceID` and /// `interfaceID` is not 0xffffffff, `false` otherwise function supportsInterface(bytes4 interfaceID) external view responsible returns (bool); }  The interface identifier for this interface is 0x3204EC29. You can calculate this by running tvm.functionId('supportsInterface(bytes4)'); or using the Selector contract above. Therefore, the implementing contract will have a supportsInterface function that returns: true when interfaceID is 0x3204EC29 (TIP6.1 interface)false when interfaceID is 0xfffffffftrue for any other interfaceID this contract implementsfalse for any other interfaceID "},{"title":"References​","type":1,"pageTitle":"Standard Interface Detection Interface (TIP-6.1)","url":"/standard/TIP-6.1#references","content":"EIP-165: Standard Interface Detection "},{"title":"What is TIP? (TIP-0)","type":0,"sectionRef":"#","url":"/standard/workflow","content":"What is TIP? (TIP-0) TIP — Trustless Improvement Proposal (TIPs) describe standards for the Everscale blockchain. They may include anything that the community considers in need of improvement or standardization. That can be specifications for core protocol, description of interfaces, smart contract standards and so on. I propose a more relaxed structure more closely resembling Bitcoin BIPs but with quite different proccess (see below). Each TIP should have the following parts (which are heavily copy-pasted from BIP requirements): Preamble — Headers containing metadata about the TIP;Abstract — A short (~200 word) description of the technical issue being addressed;Copyright — The TIP must be explicitly licensed under acceptable copyright terms;Specification — The technical specification should describe the syntax and semantics of any new feature;The specification should be detailed enough to allow competing, interoperable implementations;Motivation — The motivation is critical for TIPs that want to change the Everscale protocol. It should clearly explain why the existing protocol is inadequate to address the problem that the TIP solves;Rationale — The rationale fleshes out the specification by describing what motivated the design and why particular design decisions were made. It should describe alternate designs that were considered and related work. The rationale should provide evidence of consensus within the community and discuss important objections or concerns raised during discussion;Backwards compatibility — All TIPs that introduce backwards incompatibilities must include a section describing these incompatibilities and their severity. The TIP must explain how the author proposes to deal with these incompatibilities; Each TIP should pass the following process of acceptance: Proposal → Discussion → Community Voting → Reference Implementations Contest → Final TIP with Reference Implementations Reference implementation — The reference implementation must be completed before any TIP is given status Final, but it need not be completed before the TIP is accepted. It is better to finish the specification and rationale first and reach consensus on it before writing code. The final implementation must include test code and documentation appropriate for the Everscale protocol.","keywords":""},{"title":"Run Validator","type":0,"sectionRef":"#","url":"/validate","content":"","keywords":""},{"title":"Delegator​","type":1,"pageTitle":"Run Validator","url":"/validate#delegator","content":"Delegators play a big role in the decentralization of the network. They greatly contribute to network security by the means of allocating their stakes to validators. To add, they also direct the Elector's algorithm to validators that should proceed with validation in the next round. This enables well-regarded validators with low stakes to accumulate funds in their pools and subsequently become validators.  Due to the fact that Everscale is a proof of stake blockchain, any participant with enough EVER tokens can become a validator. That’s even if they haven't been nominated by other participants. Validators part the rewards with delegators in accordance with their share of EVER tokens. Although, it should be mentioned that they also share the risks. Thus, if a particular validator node is offline during validation, it is punished by having its stake slashed. Consequently, the delegator's stake may as well be reduced. After having gone through the essentials of validation on Everscale, let’s now move to practice. "},{"title":"How to run a validator node​","type":1,"pageTitle":"Run Validator","url":"/validate#how-to-run-a-validator-node","content":"tip Sufficient Linux engineering skills are required in order to manage, secure, and maintain nodes. Running a Validator node is much harder than executing a validator binary. Running a validator node is a consequential task. Therefore, to ensure the stability of your node, you should use highly efficient hardware. Below, we provide the hardware requirements we consider best fit: Operating system: Ubuntu 22.04CPU: 12x cores Intel Skylake or a newer CPU. Higher base CPU frequency is preferred over the core count. RAM: 64GB; Network: 300Mbps with a strong internet connection. In case of connection issues, it could lead to the disconnection of the validator.Storage: 50GB SSD storage for the operating system; 500GB of NVMe for validator internal database with the ability to add additional space to allow for the growth of the blockchain. Cloud providers: Google Cloud, Amazon AWS, Microsoft Azure, OVH. Also, for the node to work properly, configure the cloud firewall to accept incoming traffic on UDP/30000 port. tip Please be informed that the node will consume around 6TB of incoming traffic each month. "},{"title":"Node setup​","type":1,"pageTitle":"Run Validator","url":"/validate#node-setup","content":"caution Always check any scripts you are running Prepare the server for node setup 1.1. Create a user and group for running the Validator node, and create all necessary folder structures VALIDATOR_USER=&quot;validator&quot; VALIDATOR_GROUP=&quot;validator&quot; sudo groupadd $VALIDATOR_GROUP sudo useradd $VALIDATOR_USER -m -s /bin/bash -g $VALIDATOR_GROUP -G sudo # Mount sudo mkdir -p /var/ever/rnode/ sudo chown $VALIDATOR_USER:$VALIDATOR_GROUP /var/ever/rnode/  1.2. Check if the NTP service is UP and running systemctl status systemd-timesyncd  Your system should show that the service is up and running. If not - please refer to the documentation ● systemd-timesyncd.service - Network Time Synchronization Loaded: loaded (/lib/systemd/system/systemd-timesyncd.service; enabled; preset: enabled) Active: active (running)  caution If the system clock is out of sync (even by a small amount), the blocks which the Validator produces, may not be accepted by the network. Create firewall rules to allow ADNL communications sudo ufw allow 30000/UDP  Install dependencies sudo apt update sudo apt install -y git libssl-dev pkg-config build-essential libzstd-dev libclang-dev libgoogle-perftools-dev  Switch to the validator user sudo su validator  4.1 Install rust  curl https://sh.rustup.rs -sSf | sh source &quot;$HOME/.cargo/env&quot;  Build a Validator node  cargo install --locked --git https://github.com/broxus/nodekeeper  # Optionally configure root directory: # export NODEKEEPER_ROOT=/var/nodekeeper # # Or explicitly specify it as a param, e.g.: # nodekeeper --root /var/nodekeeper init # Configure node nodekeeper init sudo $(which nodekeeper) init systemd  Here choose the user for the validator. DON'T RUN Validator service as a root user! [0/2] Preparing services ? Select the user from which the service will work › ❯ validator root  Setup Validator and create wallets Compile and init node nodekeeper init  Choose &quot;other&quot; network [0/2] Preparing configs ✔ Create root directory? (/home/validator/.nodekeeper) · yes ? Select network › Everscale mainnet Everscale testnet ❯ other  Provide global config URL (Contact Everscale core team) ✔ Select network · other ? Config URL ›  [0/2] Preparing configs ✔ Create root directory? (/home/validator/.nodekeeper) · yes ✔ Select network · other ✔ Config URL ·&lt;hidden&gt; ✔ Node config doesn't have control server entry. Create? · yes ✔ Control server listen address · localhost ✔ Specify control port · 31000 ✔ Enter public ip · 164.92.106.127 ✔ Specify server ADNL port · 30000 ✔ Specify node DB path · /var/ever/rnode [1/2] Preparing binary  The node would be compiled, Select the mode of your node: ? Select validator type › ❯ Single DePool  Create a new seed phrase or import existing [0/2] Creating validator wallet ❯ Generate new keys Import seed  6.1 Define the desired stake per round. Notice you will need an amount of tokens 2*(stake per round)+10 Leave &quot;stake factor (ratio between maximum available stake on the network and your stake) to 3 as it is standard in the Everscale network ✔ Stake per round (EVER) · 10000 ✔ Stake factor · 3 [2/2] Validator configured successfully. Great! Validator wallet address: Required validator wallet balance: 20010 EVER • 10 EVER, maintenance balance • 2 x 20010 EVER, stakes for each round Make sure you back up your keys: /home/validator/.nodekeeper/keys/vld.keys.json  info Make sure you back up your keys after the initial configuration! All keys are stored at $HOME/.nodekeeper/keys/ Init validator services sudo ~/.cargo/bin/nodekeeper init systemd  caution Service MUST NOT run as the root user [0/2] Preparing services ? Select the user from which the service will work › ❯ validator root  It will create two services: validator-manager - control service that takes part in elections, recovers stake and performs other tasks with the Elector contractvalidator - node itself, managing validation process You can check the status of both services with the following commands: service validator status service validator-manager status  Transfer tokens to the Validator contract Transfer the required amount of tokens to the address generated in the previous step. The Wallet will become active after the first stake Wait until the elections start When elections start, the validator-manager process will automatically stake the desired amount of tokens. You can check the current state of elections using Everscan. info validator-manager adds 1 EVER token for the stake to pay for the transaction fees, and you will be required to add 1 EVER token to the &quot;stake and bonuses recovery&quot; transaction. Due to this, it is adviseable to always keep some additional tokens in the Validator If everything has been setup correctly - you should see your address in the validators list for the next round. "}]